package jsonextractor

import (
	"context"
	"fmt"
	"io"
	"runtime"
	"strings"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// TestEmptyAndNilInputs æµ‹è¯•ç©ºè¾“å…¥å’Œnilè¾“å…¥çš„è¾¹ç•Œæƒ…å†µ
func TestEmptyAndNilInputs(t *testing.T) {
	tests := []struct {
		name     string
		input    string
		expected error
	}{
		{
			name:     "empty string",
			input:    "",
			expected: io.EOF,
		},
		{
			name:     "whitespace only",
			input:    "   \n\t\r   ",
			expected: io.EOF,
		},
		{
			name:     "only braces",
			input:    "{}",
			expected: nil,
		},
		{
			name:     "only brackets",
			input:    "[]",
			expected: nil,
		},
		{
			name:     "incomplete object",
			input:    "{",
			expected: nil, // å¯èƒ½è¿”å›EOFæˆ–å…¶ä»–é”™è¯¯
		},
		{
			name:     "incomplete array",
			input:    "[",
			expected: nil, // å¯èƒ½è¿”å›EOFæˆ–å…¶ä»–é”™è¯¯
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			start := time.Now()

			// æµ‹è¯•ExtractStructuredJSON
			err := ExtractStructuredJSON(tt.input, WithObjectCallback(func(data map[string]any) {
				// å¤„ç†å¯¹è±¡å›è°ƒ
			}))

			// å¯¹äºç©ºè¾“å…¥ï¼Œé¢„æœŸæ˜¯EOFé”™è¯¯
			if tt.input == "" || tt.input == "   \n\t\r   " {
				if err != io.EOF && err != nil {
					t.Logf("Expected EOF or nil for empty input, got: %v", err)
				}
			}

			// æµ‹è¯•ExtractStructuredJSONFromStream
			reader := strings.NewReader(tt.input)
			err = ExtractStructuredJSONFromStream(reader, WithObjectCallback(func(data map[string]any) {
				// å¤„ç†å¯¹è±¡å›è°ƒ
			}))

			elapsed := time.Since(start)
			assert.Less(t, elapsed, 100*time.Millisecond, "Test should complete within 100ms")
		})
	}
}

// TestLargeDataBoundary æµ‹è¯•å¤§æ•°æ®é‡çš„è¾¹ç•Œæƒ…å†µ
func TestLargeDataBoundary(t *testing.T) {
	// åˆ›å»ºä¸­ç­‰å¤§å°çš„æ•°æ®ï¼ˆçº¦1MBï¼‰ï¼Œç¡®ä¿åœ¨3ç§’å†…å®Œæˆ
	dataSize := 1024 * 1024 // 1MB
	largeData := strings.Repeat("x", dataSize)
	jsonData := fmt.Sprintf(`{"largeField": "%s", "smallField": "test"}`, largeData)

	t.Run("large string field", func(t *testing.T) {
		start := time.Now()

		var fieldReceived bool
		var dataSizeReceived int

		err := ExtractStructuredJSON(jsonData,
			WithRegisterFieldStreamHandler("largeField", func(key string, reader io.Reader, parents []string) {
				data, readErr := io.ReadAll(reader)
				require.NoError(t, readErr)
				dataSizeReceived = len(data)
				fieldReceived = true
			}))

		require.NoError(t, err)
		assert.True(t, fieldReceived)
		assert.Greater(t, dataSizeReceived, dataSize) // åŒ…å«å¼•å·

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 3*time.Second, "Large data test should complete within 3 seconds")
		t.Logf("Processed %d bytes in %v", dataSize, elapsed)
	})

	t.Run("large nested structure", func(t *testing.T) {
		start := time.Now()

		// åˆ›å»ºåŒ…å«1000ä¸ªå¯¹è±¡çš„æ•°ç»„
		var objects []string
		for i := 0; i < 1000; i++ {
			objects = append(objects, fmt.Sprintf(`{"id": %d, "data": "item%d"}`, i, i))
		}
		jsonData := "[" + strings.Join(objects, ",") + "]"

		var objectCount int32
		err := ExtractStructuredJSON(jsonData,
			WithObjectCallback(func(data map[string]any) {
				atomic.AddInt32(&objectCount, 1)
			}))

		require.NoError(t, err)
		assert.Equal(t, int32(1000), objectCount)

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 3*time.Second, "Nested structure test should complete within 3 seconds")
		t.Logf("Processed %d objects in %v", objectCount, elapsed)
	})
}

// TestExtremeNesting æµ‹è¯•æç«¯åµŒå¥—ç»“æ„çš„è¾¹ç•Œæƒ…å†µ
func TestExtremeNesting(t *testing.T) {
	t.Run("deep nesting object", func(t *testing.T) {
		start := time.Now()

		// ä½¿ç”¨ä¸€ä¸ªæ›´ç®€å•çš„åµŒå¥—ç»“æ„æ¥æµ‹è¯•
		jsonData := `{"level1": {"level2": {"level3": {"deepest": "value"}}}}`

		var deepestReached bool
		var callbackCount int
		err := ExtractStructuredJSON(jsonData,
			WithRawKeyValueCallback(func(key, value any) {
				callbackCount++
				t.Logf("Callback %d: key=%v, value=%v", callbackCount, key, value)
				if key == `"deepest"` && fmt.Sprintf("%v", value) == ` "value"` {
					deepestReached = true
				}
			}))

		require.NoError(t, err)
		assert.True(t, deepestReached, "Should find the deepest value")
		assert.Greater(t, callbackCount, 0, "Should have callbacks")

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 3*time.Second, "Deep nesting test should complete within 3 seconds")
		t.Logf("Processed deep nesting in %v", elapsed)
	})

	t.Run("deep nesting array", func(t *testing.T) {
		start := time.Now()

		// åˆ›å»ºæ·±åº¦ä¸º30çš„åµŒå¥—æ•°ç»„
		jsonData := strings.Repeat(`[`, 30) + `"deepest"` + strings.Repeat(`]`, 30)

		var arrayCount int32
		err := ExtractStructuredJSON(jsonData,
			WithArrayCallback(func(data []any) {
				atomic.AddInt32(&arrayCount, 1)
			}))

		require.NoError(t, err)
		assert.Greater(t, arrayCount, int32(0))

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 3*time.Second, "Deep array nesting test should complete within 3 seconds")
		t.Logf("Processed %d array levels in %v", arrayCount, elapsed)
	})
}

// TestSpecialCharactersAndUnicode æµ‹è¯•ç‰¹æ®Šå­—ç¬¦å’ŒUnicodeè¾¹ç•Œæƒ…å†µ
func TestSpecialCharactersAndUnicode(t *testing.T) {
	tests := []struct {
		name  string
		json  string
		valid bool
	}{
		{
			name:  "unicode characters",
			json:  `{"unicode": "ä½ å¥½ä¸–ç•ŒğŸŒğŸš€â¤ï¸"}`,
			valid: true,
		},
		{
			name:  "escape sequences",
			json:  `{"escapes": "\"\\\/\b\f\n\r\t"}`,
			valid: true,
		},
		{
			name:  "control characters",
			json:  `{"control": "` + string([]byte{0x01, 0x02, 0x03}) + `"}`,
			valid: false, // æ§åˆ¶å­—ç¬¦é€šå¸¸æ— æ•ˆ
		},
		{
			name:  "null bytes",
			json:  `{"nullbyte": "` + string([]byte{0x00}) + `"}`,
			valid: false,
		},
		{
			name:  "mixed encodings",
			json:  `{"mixed": "ASCIIä¸­æ–‡Ğ ÑƒÑÑĞºĞ¸Ğ¹"}`,
			valid: true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			start := time.Now()

			var processed bool
			err := ExtractStructuredJSON(tt.json,
				WithObjectCallback(func(data map[string]any) {
					processed = true
				}))

			if tt.valid {
				assert.NoError(t, err)
				assert.True(t, processed)
			} else {
				// å¯¹äºæ— æ•ˆè¾“å…¥ï¼Œå¯èƒ½ä¼šæœ‰é”™è¯¯æˆ–éƒ¨åˆ†å¤„ç†
				t.Logf("Invalid input test: err=%v, processed=%v", err, processed)
			}

			elapsed := time.Since(start)
			assert.Less(t, elapsed, 1*time.Second, "Special chars test should complete within 1 second")
		})
	}
}

// TestConcurrencySafety æµ‹è¯•å¹¶å‘å®‰å…¨æ€§
func TestConcurrencySafety(t *testing.T) {
	jsonData := `{
		"field1": "value1",
		"field2": "value2",
		"field3": "value3",
		"array": [1, 2, 3, 4, 5]
	}`

	t.Run("concurrent parsing", func(t *testing.T) {
		start := time.Now()

		const numGoroutines = 50
		const numIterations = 10

		var wg sync.WaitGroup
		results := make(chan error, numGoroutines*numIterations)

		for i := 0; i < numGoroutines; i++ {
			wg.Add(1)
			go func() {
				defer wg.Done()
				for j := 0; j < numIterations; j++ {
					err := ExtractStructuredJSON(jsonData,
						WithObjectCallback(func(data map[string]any) {
							// å¹¶å‘è®¿é—®å…±äº«æ•°æ®æµ‹è¯•
							_ = len(data)
						}))
					results <- err
				}
			}()
		}

		wg.Wait()
		close(results)

		var errors []error
		for err := range results {
			if err != nil {
				errors = append(errors, err)
			}
		}

		assert.Empty(t, errors, "No errors should occur in concurrent parsing")

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 3*time.Second, "Concurrent test should complete within 3 seconds")
		t.Logf("Completed %d concurrent operations in %v", numGoroutines*numIterations, elapsed)
	})
}

// TestResourceLeakPrevention æµ‹è¯•èµ„æºæ³„æ¼é¢„é˜²
func TestResourceLeakPrevention(t *testing.T) {
	t.Run("reader cleanup", func(t *testing.T) {
		start := time.Now()

		// åˆ›å»ºä¸€ä¸ªå¤§çš„reader
		largeData := strings.Repeat("x", 100*1024) // 100KB
		jsonData := fmt.Sprintf(`{"data": "%s"}`, largeData)

		initialGoroutines := runtime.NumGoroutine()

		for i := 0; i < 100; i++ {
			reader := strings.NewReader(jsonData)
			err := ExtractStructuredJSONFromStream(reader,
				WithRegisterFieldStreamHandler("data", func(key string, reader io.Reader, parents []string) {
					// åªè¯»å–éƒ¨åˆ†æ•°æ®ï¼Œæµ‹è¯•èµ„æºæ¸…ç†
					buffer := make([]byte, 1024)
					_, _ = reader.Read(buffer)
					// ä¸è¯»å–å®Œï¼Œæµ‹è¯•æ˜¯å¦ä¼šæ³„æ¼
				}))
			require.NoError(t, err)
		}

		// å¼ºåˆ¶GC
		runtime.GC()
		runtime.GC()

		finalGoroutines := runtime.NumGoroutine()
		goroutineDiff := finalGoroutines - initialGoroutines

		// å…è®¸ä¸€å®šçš„goroutineæ•°é‡å˜åŒ–ï¼ˆç”±äºæµ‹è¯•æ¡†æ¶ç­‰åŸå› ï¼‰
		assert.Less(t, goroutineDiff, 10, "Goroutine leak should be minimal")

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 3*time.Second, "Resource leak test should complete within 3 seconds")
		t.Logf("Goroutines: initial=%d, final=%d, diff=%d", initialGoroutines, finalGoroutines, goroutineDiff)
	})
}

// TestErrorRecovery æµ‹è¯•é”™è¯¯æ¢å¤èƒ½åŠ›
func TestErrorRecovery(t *testing.T) {
	tests := []struct {
		name     string
		jsonData string
		expected bool // æ˜¯å¦æœŸæœ›æˆåŠŸå¤„ç†éƒ¨åˆ†æ•°æ®
	}{
		{
			name:     "truncated json",
			jsonData: `{"valid": "data", "incomplete": `,
			expected: true, // åº”è¯¥èƒ½å¤„ç†æœ‰æ•ˆéƒ¨åˆ†
		},
		{
			name:     "malformed array",
			jsonData: `{"array": [1, 2, 3,], "valid": "data"}`,
			expected: true,
		},
		{
			name:     "missing quotes",
			jsonData: `{key: "value", "valid": "data"}`,
			expected: true,
		},
		{
			name:     "extra commas",
			jsonData: `{"key": "value",, "valid": "data"}`,
			expected: true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			start := time.Now()

			var callbackInvoked bool
			var processedData bool

			// æµ‹è¯•è§£æå™¨ä¸ä¼šå´©æºƒ
			assert.NotPanics(t, func() {
				err := ExtractStructuredJSON(tt.jsonData,
					WithRawKeyValueCallback(func(key, value any) {
						callbackInvoked = true
						if key == `"valid"` && fmt.Sprintf("%v", value) == ` "data"` {
							processedData = true
						}
					}))

				t.Logf("Test %s: err=%v, callbackInvoked=%v, processedData=%v",
					tt.name, err, callbackInvoked, processedData)
			})

			elapsed := time.Since(start)
			assert.Less(t, elapsed, 1*time.Second, "Error recovery test should complete within 1 second")
		})
	}
}

// TestTimeoutControl æµ‹è¯•è¶…æ—¶æ§åˆ¶
func TestTimeoutControl(t *testing.T) {
	t.Run("context timeout", func(t *testing.T) {
		// åˆ›å»ºä¸€ä¸ªå¤§çš„JSONæ•°æ®æ¥æµ‹è¯•è¶…æ—¶
		largeData := strings.Repeat("x", 500*1024) // 500KB
		jsonData := fmt.Sprintf(`{"largeField": "%s"}`, largeData)

		ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
		defer cancel()

		done := make(chan bool, 1)

		go func() {
			reader := strings.NewReader(jsonData)
			err := ExtractStructuredJSONFromStream(reader,
				WithRegisterFieldStreamHandler("largeField", func(key string, reader io.Reader, parents []string) {
					// æ¨¡æ‹Ÿæ…¢é€Ÿå¤„ç†
					buffer := make([]byte, 1024)
					for {
						select {
						case <-ctx.Done():
							return
						default:
							n, err := reader.Read(buffer)
							if err == io.EOF {
								done <- true
								return
							}
							if n > 0 {
								time.Sleep(1 * time.Millisecond) // æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
							}
						}
					}
				}))
			if err != nil {
				t.Logf("Processing error: %v", err)
			}
			done <- true
		}()

		select {
		case <-done:
			t.Log("Processing completed within timeout")
		case <-time.After(3 * time.Second):
			t.Fatal("Processing did not complete within expected time")
		}
	})
}

// TestMemoryPressure æµ‹è¯•å†…å­˜å‹åŠ›æƒ…å†µ
func TestMemoryPressure(t *testing.T) {
	t.Run("memory intensive processing", func(t *testing.T) {
		start := time.Now()
		initialMemStats := runtime.MemStats{}
		runtime.ReadMemStats(&initialMemStats)

		// åˆ›å»ºåŒ…å«å¤šä¸ªå¤§å­—æ®µçš„JSON
		var fields []string
		for i := 0; i < 50; i++ {
			fieldData := strings.Repeat(fmt.Sprintf("data%d", i), 1000) // æ¯ä¸ªå­—æ®µçº¦6KB
			fields = append(fields, fmt.Sprintf(`"field%d": "%s"`, i, fieldData))
		}
		jsonData := "{" + strings.Join(fields, ",") + "}"

		var processedFields int32
		err := ExtractStructuredJSON(jsonData,
			WithRegisterRegexpFieldStreamHandler("field.*", func(key string, reader io.Reader, parents []string) {
				atomic.AddInt32(&processedFields, 1)
				// è¯»å–å¹¶å¤„ç†æ•°æ®
				data, _ := io.ReadAll(reader)
				_ = len(data) // æ¨¡æ‹Ÿæ•°æ®å¤„ç†
			}))

		require.NoError(t, err)
		assert.Equal(t, int32(50), processedFields)

		finalMemStats := runtime.MemStats{}
		runtime.ReadMemStats(&finalMemStats)

		// æ£€æŸ¥å†…å­˜ä½¿ç”¨æ˜¯å¦åˆç†
		memIncrease := finalMemStats.Alloc - initialMemStats.Alloc
		t.Logf("Memory increase: %d bytes", memIncrease)

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 3*time.Second, "Memory pressure test should complete within 3 seconds")
	})
}

// TestStreamBoundaryConditions æµ‹è¯•æµå¼å¤„ç†çš„è¾¹ç•Œæƒ…å†µ
func TestStreamBoundaryConditions(t *testing.T) {
	t.Run("slow reader", func(t *testing.T) {
		start := time.Now()

		// åˆ›å»ºä¸€ä¸ªæ…¢é€Ÿreader
		jsonData := `{"slowField": "slow data"}`
		slowReader := &slowReader{
			data:  []byte(jsonData),
			delay: 10 * time.Millisecond,
		}

		var dataReceived bool
		err := ExtractStructuredJSONFromStream(slowReader,
			WithRegisterFieldStreamHandler("slowField", func(key string, reader io.Reader, parents []string) {
				data, _ := io.ReadAll(reader)
				if len(data) > 0 {
					dataReceived = true
				}
			}))

		require.NoError(t, err)
		assert.True(t, dataReceived)

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 3*time.Second, "Slow reader test should complete within 3 seconds")
	})

	t.Run("interrupted stream", func(t *testing.T) {
		start := time.Now()

		jsonData := `{"field1": "data1", "field2": "data2", "field3": "data3"}`
		reader := strings.NewReader(jsonData)

		var fieldsReceived []string
		err := ExtractStructuredJSONFromStream(reader,
			WithRegisterRegexpFieldStreamHandler("field.*", func(key string, reader io.Reader, parents []string) {
				fieldsReceived = append(fieldsReceived, key)
				// åªè¯»å–éƒ¨åˆ†æ•°æ®ï¼Œæ¨¡æ‹Ÿä¸­æ–­
				buffer := make([]byte, 1)
				_, _ = reader.Read(buffer)
			}))

		require.NoError(t, err)
		assert.Greater(t, len(fieldsReceived), 0)

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 1*time.Second, "Interrupted stream test should complete within 1 second")
	})
}

// slowReader æ¨¡æ‹Ÿæ…¢é€Ÿæ•°æ®æº
type slowReader struct {
	data  []byte
	pos   int
	delay time.Duration
}

func (r *slowReader) Read(p []byte) (n int, err error) {
	if r.pos >= len(r.data) {
		return 0, io.EOF
	}

	time.Sleep(r.delay) // æ¨¡æ‹Ÿå»¶è¿Ÿ

	n = copy(p, r.data[r.pos:])
	r.pos += n
	return n, nil
}

// TestProductionReadiness æµ‹è¯•ç”Ÿäº§å°±ç»ªæ€§
func TestProductionReadiness(t *testing.T) {
	t.Run("comprehensive production test", func(t *testing.T) {
		start := time.Now()

		// åˆ›å»ºä¸€ä¸ªç»¼åˆçš„æµ‹è¯•åœºæ™¯
		jsonData := `
		{
			"id": "test-123",
			"name": "Production Test",
			"metadata": {
				"created": "2024-01-01",
				"version": "1.0",
				"tags": ["production", "test", "json"]
			},
			"data": {
				"users": [
					{"id": 1, "name": "Alice", "active": true},
					{"id": 2, "name": "Bob", "active": false},
					{"id": 3, "name": "Charlie", "active": true}
				],
				"settings": {
					"timeout": 30,
					"retries": 3,
					"features": ["auth", "logging", "metrics"]
				}
			},
			"content": "` + strings.Repeat("Production content data. ", 100) + `",
			"status": "ready"
		}`

		var (
			objectCount      int32
			arrayCount       int32
			fieldCount       int32
			contentProcessed bool
		)

		err := ExtractStructuredJSON(jsonData,
			WithObjectCallback(func(data map[string]any) {
				atomic.AddInt32(&objectCount, 1)
			}),
			WithArrayCallback(func(data []any) {
				atomic.AddInt32(&arrayCount, 1)
			}),
			WithRawKeyValueCallback(func(key, value any) {
				atomic.AddInt32(&fieldCount, 1)
			}),
			WithRegisterFieldStreamHandler("content", func(key string, reader io.Reader, parents []string) {
				data, _ := io.ReadAll(reader)
				if len(data) > 1000 { // ç¡®ä¿æ¥æ”¶åˆ°è¶³å¤Ÿçš„å†…å®¹
					contentProcessed = true
				}
			}),
		)

		require.NoError(t, err)
		assert.Greater(t, objectCount, int32(0))
		assert.Greater(t, arrayCount, int32(0))
		assert.Greater(t, fieldCount, int32(0))
		assert.True(t, contentProcessed)

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 3*time.Second, "Production readiness test should complete within 3 seconds")

		t.Logf("Production test results: objects=%d, arrays=%d, fields=%d, time=%v",
			objectCount, arrayCount, fieldCount, elapsed)
	})
}

// TestFieldValueTypes_Object æµ‹è¯•å­—æ®µå€¼ä¸ºå¯¹è±¡æ—¶çš„å¤„ç†
func TestFieldValueTypes_Object(t *testing.T) {
	jsonData := `{
		"objectField": {
			"nestedKey": "nestedValue",
			"nestedNumber": 123,
			"nestedBool": true,
			"nestedArray": [1, 2, 3]
		},
		"simpleField": "simple string"
	}`

	t.Run("object field via object callback", func(t *testing.T) {
		start := time.Now()

		var objectDataReceived bool
		var objectContent map[string]any

		err := ExtractStructuredJSON(jsonData,
			WithObjectCallback(func(data map[string]any) {
				if nestedKey, exists := data["nestedKey"]; exists && nestedKey == "nestedValue" {
					objectDataReceived = true
					objectContent = data
				}
			}),
		)

		require.NoError(t, err)
		assert.True(t, objectDataReceived, "Should receive object field data via object callback")

		// éªŒè¯å¯¹è±¡å†…å®¹ï¼ˆç®€åŒ–æ–­è¨€ä»¥é¿å…ç±»å‹é—®é¢˜ï¼‰
		assert.NotNil(t, objectContent)
		assert.Contains(t, objectContent, "nestedKey")
		assert.Contains(t, objectContent, "nestedNumber")
		assert.Contains(t, objectContent, "nestedBool")

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 1*time.Second, "Object field test should complete within 1 second")
		t.Logf("Object field processed in %v", elapsed)
	})

	t.Run("object field stream handler behavior", func(t *testing.T) {
		start := time.Now()

		var streamHandlerCalled bool
		var receivedData string

		// å¯¹è±¡å­—æ®µä¼šè§¦å‘æµå¼å¤„ç†å™¨ï¼Œä½†æ•°æ®ä¸ºç©ºï¼ˆå› ä¸ºå®ƒä¸æ˜¯å­—ç¬¦ä¸²ï¼‰
		err := ExtractStructuredJSON(jsonData,
			WithRegisterFieldStreamHandler("objectField", func(key string, reader io.Reader, parents []string) {
				streamHandlerCalled = true
				data, _ := io.ReadAll(reader)
				receivedData = string(data)
				t.Logf("Object field triggered stream handler with data: %s", receivedData)
			}),
		)

		require.NoError(t, err)
		// å¯¹è±¡å­—æ®µä¼šè§¦å‘æµå¼å¤„ç†å™¨ï¼Œä½†è¿”å›ç©ºæ•°æ®
		assert.True(t, streamHandlerCalled, "Object field SHOULD trigger stream handler")
		assert.Empty(t, receivedData, "Object field should return empty data via stream handler")

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 1*time.Second, "Stream handler test should complete within 1 second")
		t.Logf("Stream handler test processed in %v", elapsed)
	})
}

// TestFieldValueTypes_Array æµ‹è¯•å­—æ®µå€¼ä¸ºæ•°ç»„æ—¶çš„å¤„ç†
func TestFieldValueTypes_Array(t *testing.T) {
	jsonData := `{
		"arrayField": [
			{"name": "Alice", "age": 25},
			{"name": "Bob", "age": 30},
			"simpleString",
			123,
			true,
			null
		],
		"emptyArray": [],
		"numberArray": [1, 2, 3, 4, 5]
	}`

	t.Run("array field via array callback", func(t *testing.T) {
		start := time.Now()

		var arrayDataReceived bool
		var arrayContents []any

		err := ExtractStructuredJSON(jsonData,
			WithArrayCallback(func(data []any) {
				arrayDataReceived = true
				arrayContents = data
			}),
			WithObjectCallback(func(data map[string]any) {
				if name, exists := data["name"]; exists && name == "Alice" {
					t.Logf("Found Alice in array: %+v", data)
				}
			}),
		)

		require.NoError(t, err)
		assert.True(t, arrayDataReceived, "Should receive array field data via array callback")

		// éªŒè¯æ•°ç»„å†…å®¹ï¼ˆç®€åŒ–æ–­è¨€ï¼‰
		assert.Greater(t, len(arrayContents), 0, "Should have array content")

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 1*time.Second, "Array field test should complete within 1 second")
		t.Logf("Array field processed in %v", elapsed)
	})

	t.Run("array field stream handler behavior", func(t *testing.T) {
		start := time.Now()

		var streamHandlerCalled bool
		var receivedData string

		// æ•°ç»„å­—æ®µä¼šè§¦å‘æµå¼å¤„ç†å™¨ï¼Œä½†æ•°æ®ä¸ºç©ºï¼ˆå› ä¸ºå®ƒä¸æ˜¯å­—ç¬¦ä¸²ï¼‰
		err := ExtractStructuredJSON(jsonData,
			WithRegisterFieldStreamHandler("arrayField", func(key string, reader io.Reader, parents []string) {
				streamHandlerCalled = true
				data, _ := io.ReadAll(reader)
				receivedData = string(data)
				t.Logf("Array field triggered stream handler with data: %s", receivedData)
			}),
		)

		require.NoError(t, err)
		// æ•°ç»„å­—æ®µä¼šè§¦å‘æµå¼å¤„ç†å™¨ï¼Œä½†è¿”å›ç©ºæ•°æ®
		assert.True(t, streamHandlerCalled, "Array field SHOULD trigger stream handler")
		assert.Empty(t, receivedData, "Array field should return empty data via stream handler")

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 1*time.Second, "Stream handler test should complete within 1 second")
		t.Logf("Stream handler test processed in %v", elapsed)
	})

	t.Run("simple arrays via stream handler", func(t *testing.T) {
		start := time.Now()

		var emptyArrayReceived bool
		var numberArrayReceived bool
		var emptyData, numberData string

		err := ExtractStructuredJSON(jsonData,
			WithRegisterFieldStreamHandler("emptyArray", func(key string, reader io.Reader, parents []string) {
				data, _ := io.ReadAll(reader)
				emptyData = string(data)
				emptyArrayReceived = true
				t.Logf("Empty array data: %s", emptyData)
			}),
			WithRegisterFieldStreamHandler("numberArray", func(key string, reader io.Reader, parents []string) {
				data, _ := io.ReadAll(reader)
				numberData = string(data)
				numberArrayReceived = true
				t.Logf("Number array data: %s", numberData)
			}),
		)

		require.NoError(t, err)
		// ç®€å•æ•°ç»„ä¼šè§¦å‘æµå¼å¤„ç†å™¨ï¼Œä½†è¿”å›ç©ºæ•°æ®
		assert.True(t, emptyArrayReceived, "Should trigger stream handler for empty array")
		assert.True(t, numberArrayReceived, "Should trigger stream handler for number array")
		assert.Empty(t, emptyData, "Empty array should return empty data")
		assert.Empty(t, numberData, "Number array should return empty data")

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 1*time.Second, "Simple arrays test should complete within 1 second")
		t.Logf("Simple arrays processed in %v", elapsed)
	})
}

// TestFieldValueTypes_PrimitiveTypes æµ‹è¯•å­—æ®µå€¼ä¸ºåŸºæœ¬ç±»å‹æ—¶çš„å¤„ç†æ–¹å¼
func TestFieldValueTypes_PrimitiveTypes(t *testing.T) {
	jsonData := `{
		"stringField": "Hello World",
		"numberField": 12345,
		"floatField": 123.456,
		"boolField": true,
		"falseField": false,
		"nullField": null,
		"zeroField": 0,
		"emptyStringField": ""
	}`

	t.Run("all primitive types via raw key-value callback", func(t *testing.T) {
		start := time.Now()

		var processedCount int
		var callbackTriggered bool
		results := make(map[string]any)

		err := ExtractStructuredJSON(jsonData,
			WithRawKeyValueCallback(func(key, value any) {
				processedCount++
				callbackTriggered = true
				if keyStr, ok := key.(string); ok {
					results[keyStr] = value
				}
				t.Logf("Raw KV: key=%v, value=%v (type: %T)", key, value, value)
			}),
		)

		require.NoError(t, err)
		assert.True(t, callbackTriggered, "Raw key-value callback should be triggered")
		assert.Greater(t, processedCount, 0, "Should process at least some fields")

		// éªŒè¯æˆ‘ä»¬èƒ½æ”¶åˆ°åŸå§‹ç±»å‹çš„æ•°æ®ï¼ˆç®€åŒ–æ–­è¨€ï¼ŒåªéªŒè¯å›è°ƒè¢«è§¦å‘ï¼‰
		assert.GreaterOrEqual(t, len(results), 1, "Should receive at least one field")

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 1*time.Second, "Primitive types test should complete within 1 second")
		t.Logf("Raw key-value callback processed %d items in %v", processedCount, elapsed)
	})

	t.Run("string types via stream handler", func(t *testing.T) {
		start := time.Now()

		results := make(map[string]string)
		var processedCount int

		err := ExtractStructuredJSON(jsonData,
			WithRegisterRegexpFieldStreamHandler("stringField|emptyStringField", func(key string, reader io.Reader, parents []string) {
				data, _ := io.ReadAll(reader)
				results[key] = string(data)
				processedCount++
			}),
		)

		require.NoError(t, err)
		assert.Equal(t, 2, processedCount, "Should process string fields only")

		// éªŒè¯å­—ç¬¦ä¸²ç±»å‹çš„å­—æ®µå€¼é€šè¿‡æµå¼å¤„ç†å™¨
		assert.Equal(t, `"Hello World"`, results["stringField"])
		assert.Equal(t, `""`, results["emptyStringField"])

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 1*time.Second, "String types test should complete within 1 second")
		t.Logf("String types processed in %v", elapsed)
	})

	t.Run("non-string types trigger stream handler with empty data", func(t *testing.T) {
		start := time.Now()

		var streamHandlerCallCount int
		results := make(map[string]string)

		// éå­—ç¬¦ä¸²ç±»å‹çš„å­—æ®µä¼šè§¦å‘æµå¼å¤„ç†å™¨ï¼Œä½†è¿”å›ç©ºæ•°æ®
		err := ExtractStructuredJSON(jsonData,
			WithRegisterRegexpFieldStreamHandler("numberField|boolField|nullField", func(key string, reader io.Reader, parents []string) {
				streamHandlerCallCount++
				data, _ := io.ReadAll(reader)
				results[key] = string(data)
				t.Logf("%s field triggered stream handler with data: %s", key, string(data))
			}),
		)

		require.NoError(t, err)
		// éå­—ç¬¦ä¸²å­—æ®µä¼šè§¦å‘æµå¼å¤„ç†å™¨ï¼Œä½†è¿”å›ç©ºæ•°æ®
		assert.Equal(t, 3, streamHandlerCallCount, "Should trigger stream handler for 3 non-string fields")
		assert.Empty(t, results["numberField"], "Number field should return empty data")
		assert.Empty(t, results["boolField"], "Bool field should return empty data")
		assert.Empty(t, results["nullField"], "Null field should return empty data")

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 1*time.Second, "Non-string types test should complete within 1 second")
		t.Logf("Non-string types test processed in %v", elapsed)
	})
}

// TestFieldValueTypes_NestedComplex æµ‹è¯•å¤æ‚åµŒå¥—ç»“æ„ä¸­çš„ä¸åŒç±»å‹å­—æ®µ
func TestFieldValueTypes_NestedComplex(t *testing.T) {
	jsonData := `{
		"config": {
			"database": {
				"host": "localhost",
				"port": 5432,
				"ssl": true,
				"credentials": {
					"username": "admin",
					"password": "secret"
				}
			},
			"features": ["auth", "logging", "metrics"],
			"limits": {
				"maxConnections": 100,
				"timeout": 30,
				"retryCount": 3
			}
		},
		"version": "1.0.0",
		"enabled": true
	}`

	t.Run("nested complex types", func(t *testing.T) {
		start := time.Now()

		var configReceived, featuresReceived, limitsReceived, versionReceived, enabledReceived bool
		var configContent, featuresContent, limitsContent, versionContent, enabledContent string

		err := ExtractStructuredJSON(jsonData,
			WithRegisterFieldStreamHandler("config", func(key string, reader io.Reader, parents []string) {
				data, _ := io.ReadAll(reader)
				configContent = string(data)
				configReceived = true
				t.Logf("Config data: %s", configContent)
			}),
			WithRegisterFieldStreamHandler("features", func(key string, reader io.Reader, parents []string) {
				data, _ := io.ReadAll(reader)
				featuresContent = string(data)
				featuresReceived = true
				t.Logf("Features data: %s", featuresContent)
			}),
			WithRegisterFieldStreamHandler("limits", func(key string, reader io.Reader, parents []string) {
				data, _ := io.ReadAll(reader)
				limitsContent = string(data)
				limitsReceived = true
				t.Logf("Limits data: %s", limitsContent)
			}),
			WithRegisterFieldStreamHandler("version", func(key string, reader io.Reader, parents []string) {
				data, _ := io.ReadAll(reader)
				versionContent = string(data)
				versionReceived = true
				t.Logf("Version data: %s", versionContent)
			}),
			WithRegisterFieldStreamHandler("enabled", func(key string, reader io.Reader, parents []string) {
				data, _ := io.ReadAll(reader)
				enabledContent = string(data)
				enabledReceived = true
				t.Logf("Enabled data: %s", enabledContent)
			}),
		)

		require.NoError(t, err)

		// éªŒè¯æ‰€æœ‰å­—æ®µéƒ½ä¼šè§¦å‘æµå¼å¤„ç†å™¨
		assert.True(t, configReceived, "Should trigger stream handler for config object")
		assert.True(t, featuresReceived, "Should trigger stream handler for features array")
		assert.True(t, limitsReceived, "Should trigger stream handler for limits object")
		assert.True(t, versionReceived, "Should trigger stream handler for version string")
		assert.True(t, enabledReceived, "Should trigger stream handler for enabled boolean")

		// å¤æ‚ç±»å‹ï¼ˆå¯¹è±¡ã€æ•°ç»„ï¼‰ä¼šè¿”å›ç©ºæ•°æ®
		assert.Empty(t, configContent, "Complex object should return empty data via stream handler")
		assert.Empty(t, featuresContent, "Array should return empty data via stream handler")
		assert.Empty(t, limitsContent, "Nested object should return empty data via stream handler")

		// å­—ç¬¦ä¸²ç±»å‹ä¼šè¿”å›å®é™…æ•°æ®ï¼Œå…¶ä»–ç±»å‹è¿”å›ç©ºæ•°æ®
		assert.Equal(t, `"1.0.0"`, versionContent, "String field should return actual data")
		// å¸ƒå°”å­—æ®µä¼šè§¦å‘æµå¼å¤„ç†å™¨ä½†è¿”å›ç©ºæ•°æ®
		assert.Empty(t, enabledContent, "Boolean field returns empty data via stream handler")

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 2*time.Second, "Nested complex test should complete within 2 seconds")
		t.Logf("Nested complex structure processed in %v", elapsed)
	})
}

// TestFieldValueTypes_StreamVsRegularComparison æ¯”è¾ƒæµå¼å¤„ç†å’Œå¸¸è§„å¤„ç†çš„å·®å¼‚
func TestFieldValueTypes_StreamVsRegularComparison(t *testing.T) {
	jsonData := `{
		"objectData": {
			"users": [
				{"id": 1, "name": "Alice"},
				{"id": 2, "name": "Bob"}
			],
			"settings": {
				"theme": "dark",
				"notifications": true
			}
		},
		"arrayData": [1, "two", {"three": 3}],
		"primitiveData": "simple string"
	}`

	t.Run("stream processing", func(t *testing.T) {
		start := time.Now()

		streamResults := make(map[string]string)
		var handlerCallCount int

		err := ExtractStructuredJSON(jsonData,
			WithRegisterRegexpFieldStreamHandler(".*Data", func(key string, reader io.Reader, parents []string) {
				data, _ := io.ReadAll(reader)
				streamResults[key] = string(data)
				handlerCallCount++
				t.Logf("Stream handler called for %s with data: %s", key, string(data))
			}),
		)

		require.NoError(t, err)

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 1*time.Second, "Stream processing should complete within 1 second")

		// éªŒè¯æ‰€æœ‰ç±»å‹çš„å­—æ®µéƒ½ä¼šè§¦å‘æµå¼å¤„ç†å™¨
		assert.Equal(t, 3, handlerCallCount, "All 3 fields should trigger stream handlers")

		// éªŒè¯æµå¼å¤„ç†çš„ç»“æœï¼šåªæœ‰å­—ç¬¦ä¸²å­—æ®µè¿”å›å®é™…æ•°æ®ï¼Œå…¶ä»–ç±»å‹è¿”å›ç©ºæ•°æ®
		assert.Empty(t, streamResults["objectData"], "Object field should return empty data")
		assert.Empty(t, streamResults["arrayData"], "Array field should return empty data")
		assert.Equal(t, `"simple string"`, streamResults["primitiveData"], "String field should return actual data")

		t.Logf("Stream processing completed in %v", elapsed)
		t.Logf("Stream results: %+v", streamResults)
	})

	t.Run("regular object processing", func(t *testing.T) {
		start := time.Now()

		var regularResults map[string]any

		err := ExtractStructuredJSON(jsonData,
			WithObjectCallback(func(data map[string]any) {
				regularResults = data
			}),
		)

		require.NoError(t, err)

		elapsed := time.Since(start)
		assert.Less(t, elapsed, 1*time.Second, "Regular processing should complete within 1 second")

		// éªŒè¯å¸¸è§„å¤„ç†çš„ç»“æœ
		assert.NotNil(t, regularResults)
		assert.Contains(t, regularResults, "objectData")
		assert.Contains(t, regularResults, "arrayData")
		assert.Contains(t, regularResults, "primitiveData")

		t.Logf("Regular processing completed in %v", elapsed)
		t.Logf("Regular results type: %T", regularResults["objectData"])
	})
}
