package aireact

import (
	"bytes"
	"context"
	"fmt"
	"sort"
	"strconv"
	"strings"

	"github.com/google/uuid"
	"github.com/yaklang/yaklang/common/ai/aid/aicommon"
	"github.com/yaklang/yaklang/common/ai/aid/aitool"
	"github.com/yaklang/yaklang/common/ai/rag"
	"github.com/yaklang/yaklang/common/chunkmaker"
	"github.com/yaklang/yaklang/common/consts"
	"github.com/yaklang/yaklang/common/log"
	"github.com/yaklang/yaklang/common/schema"
	"github.com/yaklang/yaklang/common/utils"
	"github.com/yaklang/yaklang/common/utils/memedit"
	"github.com/yaklang/yaklang/common/yakgrpc/yakit"
)

func (r *ReAct) EnhanceKnowledgeAnswer(ctx context.Context, userQuery string) (string, error) {
	if utils.IsNil(ctx) {
		ctx = r.config.GetContext()
	}

	currentTask := r.GetCurrentTask()
	enhanceID := uuid.NewString()
	config := r.config

	ekm := config.EnhanceKnowledgeManager

	if ekm == nil {
		log.Errorf("enhanceKnowledgeManager is not configured, but ai choice knowledge enhance answer action, check config! use temp rag knowledge manager")
		ekm = rag.NewRagEnhanceKnowledgeManager()
		ekm.SetEmitter(r.Emitter)
	}

	enhanceData, err := ekm.FetchKnowledge(ctx, userQuery)
	if err != nil {
		return "", utils.Errorf("enhanceKnowledgeManager.FetchKnowledge(%s) failed: %v", userQuery, err)
	}

	// Collect all knowledge items for summary artifact
	var knowledgeList []aicommon.EnhanceKnowledge
	for enhanceDatum := range enhanceData {
		r.EmitKnowledge(enhanceID, enhanceDatum)
		ekm.AppendKnowledge(currentTask.GetId(), enhanceDatum)
		knowledgeList = append(knowledgeList, enhanceDatum)
	}
	knowledgeCount := len(knowledgeList)

	// Save all knowledge to a single artifact file
	if knowledgeCount > 0 {
		r.EmitKnowledgeReferenceArtifact(knowledgeList, userQuery)
	}

	var queryBuf bytes.Buffer
	queryBuf.WriteString(userQuery)

	enhance := r.DumpCurrentEnhanceData()

	// å¦‚æœçŸ¥è¯†æ¡ç›®è¿‡å¤šï¼ˆè¶…è¿‡ 5 æ¡ï¼‰ï¼Œä½¿ç”¨ AI æ™ºèƒ½å‹ç¼©
	// å‚è€ƒ loop_yaklangcode ä¸­çš„ä¸Šä¸‹æ–‡å‹ç¼©æŠ€æœ¯
	if enhance != "" && knowledgeCount > 5 {
		log.Infof("EnhanceKnowledgeAnswer: %d knowledge items found, attempting AI compression", knowledgeCount)
		compressedEnhance := r.compressKnowledgeResults(ctx, enhance, userQuery, 15)
		if len(compressedEnhance) < len(enhance) {
			log.Infof("EnhanceKnowledgeAnswer: compressed from %d to %d chars", len(enhance), len(compressedEnhance))
			enhance = compressedEnhance
		}
	}

	if enhance != "" {
		enhancePayload, err := utils.RenderTemplate(`<|ENHANCE_DATA_{{ .Nonce }}|>
{{ .EnhanceData }}
<|ENHANCE_DATA_{{ .Nonce }}|>
`, map[string]interface{}{
			"Nonce":       nonce(),
			"EnhanceData": enhance,
		})
		if err != nil {
			log.Warnf("enhanceKnowledgeAnswer.DumpCurrentEnhanceData() failed: %v", err)
		}
		if enhancePayload != "" {
			queryBuf.WriteString("\n\n")
			queryBuf.WriteString(enhancePayload)
		}
	}

	// Build reference material content with original query and knowledge data
	referenceMaterial := ""
	if enhance != "" {
		referenceMaterial, _ = utils.RenderTemplate(`<|ORIGINAL_QUERY|>
{{ .OriginalQuery }}
<|ORIGINAL_QUERY_END|>

<|KNOWLEDGE_ENHANCED_DATA|>
{{ .EnhanceData }}
<|KNOWLEDGE_ENHANCED_DATA_END|>

çŸ¥è¯†æ¡ç›®æ•°é‡: {{ .KnowledgeCount }} (å·²é€šè¿‡ AI æ™ºèƒ½ç­›é€‰)
`, map[string]any{
			"OriginalQuery":  userQuery,
			"EnhanceData":    enhance,
			"KnowledgeCount": knowledgeCount,
		})
	}

	// Pass reference material to DirectlyAnswer for emission with stream
	var opts []any
	if referenceMaterial != "" {
		opts = append(opts, WithReferenceMaterial(referenceMaterial, 1))
	}

	finalResult, err := r.DirectlyAnswer(ctx, queryBuf.String(), nil, opts...)
	// Note: DirectlyAnswer already emits the result via stream
	// EmitTextArtifact only saves to file for reference, doesn't show duplicate UI
	if finalResult != "" {
		r.EmitTextArtifact("enhance_directly_answer", finalResult)
	}
	return finalResult, err
}

func (r *ReAct) EnhanceKnowledgeGetRandomN(ctx context.Context, n int, collections ...string) (string, error) {
	if utils.IsNil(ctx) {
		ctx = r.config.GetContext()
	}
	_ = ctx // é¢„ç•™ ctx ä¾›åç»­ä½¿ç”¨

	if n <= 0 {
		n = 10
	}

	db := consts.GetGormProfileDatabase()
	var allEntries []*schema.KnowledgeBaseEntry

	// éå†æ¯ä¸ªçŸ¥è¯†åº“è·å–éšæœºæ¡ç›®
	for _, collectionName := range collections {
		// è·å–çŸ¥è¯†åº“ä¿¡æ¯
		kb, err := yakit.GetKnowledgeBaseByName(db, collectionName)
		if err != nil {
			log.Warnf("failed to get knowledge base %s: %v", collectionName, err)
			continue
		}

		// ä½¿ç”¨éšæœºæ’åºè·å–æ¡ç›®
		var entries []*schema.KnowledgeBaseEntry
		err = db.Model(&schema.KnowledgeBaseEntry{}).
			Where("knowledge_base_id = ?", kb.ID).
			Order("RANDOM()").
			Limit(n).
			Find(&entries).Error
		if err != nil {
			log.Warnf("failed to get random entries from knowledge base %s: %v", collectionName, err)
			continue
		}

		allEntries = append(allEntries, entries...)
	}

	if len(allEntries) == 0 {
		return "", nil
	}

	// æ ¼å¼åŒ–è¾“å‡º
	var result bytes.Buffer
	result.WriteString(fmt.Sprintf("=== çŸ¥è¯†åº“æ ·æœ¬æ•°æ® (å…± %d æ¡) ===\n\n", len(allEntries)))

	for i, entry := range allEntries {
		result.WriteString(fmt.Sprintf("ã€æ¡ç›® %dã€‘\n", i+1))
		result.WriteString(fmt.Sprintf("æ ‡é¢˜: %s\n", entry.KnowledgeTitle))
		if entry.Summary != "" {
			result.WriteString(fmt.Sprintf("æ‘˜è¦: %s\n", entry.Summary))
		}
		if len(entry.Keywords) > 0 {
			result.WriteString(fmt.Sprintf("å…³é”®è¯: %s\n", strings.Join(entry.Keywords, ", ")))
		}
		if entry.KnowledgeType != "" {
			result.WriteString(fmt.Sprintf("ç±»å‹: %s\n", entry.KnowledgeType))
		}
		if entry.KnowledgeDetails != "" {
			result.WriteString(fmt.Sprintf("è¯¦ç»†å†…å®¹: %s\n", entry.KnowledgeDetails))
		}
		result.WriteString("\n")
	}

	return result.String(), nil
}

func (r *ReAct) EnhanceKnowledgeGetter(ctx context.Context, userQuery string, collections ...string) (string, error) {
	if utils.IsNil(ctx) {
		ctx = r.config.GetContext()
	}

	currentTask := r.GetCurrentTask()
	enhanceID := uuid.NewString()
	config := r.config

	ekm := config.EnhanceKnowledgeManager
	if ekm == nil {
		log.Errorf("enhanceKnowledgeManager is not configured, but ai choice knowledge enhance answer action, check config! use temp rag knowledge manager")
		ekm = rag.NewRagEnhanceKnowledgeManager()
		ekm.SetEmitter(r.Emitter)
	}

	enhanceData, err := ekm.FetchKnowledgeWithCollections(ctx, collections, userQuery)
	if err != nil {
		return "", utils.Errorf("enhanceKnowledgeManager.FetchKnowledge(%s) failed: %v", userQuery, err)
	}

	for enhanceDatum := range enhanceData {
		r.EmitKnowledge(enhanceID, enhanceDatum)
		ekm.AppendKnowledge(currentTask.GetId(), enhanceDatum)
	}

	var queryBuf bytes.Buffer
	queryBuf.WriteString(userQuery)

	enhance := r.DumpCurrentEnhanceData()
	if enhance != "" {
		enhancePayload, err := utils.RenderTemplate(`<|ENHANCE_DATA_{{ .Nonce }}|>
{{ .EnhanceData }}
<|ENHANCE_DATA_{{ .Nonce }}|>
`, map[string]interface{}{
			"Nonce":       nonce(),
			"EnhanceData": enhance,
		})
		if err != nil {
			log.Warnf("enhanceKnowledgeAnswer.DumpCurrentEnhanceData() failed: %v", err)
		}
		if enhancePayload != "" {
			queryBuf.WriteString("\n\n")
			queryBuf.WriteString(enhancePayload)
		}
	}

	return enhance, nil
}

// compressKnowledgeResults ä½¿ç”¨ AI æ™ºèƒ½å‹ç¼©çŸ¥è¯†æœç´¢ç»“æœ
// å‚è€ƒ loop_yaklangcode ä¸­çš„ä¸Šä¸‹æ–‡å‹ç¼©æŠ€æœ¯
// å°†é•¿å†…å®¹å¸¦è¡Œå·å±•ç¤ºï¼Œè®© AI ç­›é€‰å‡ºä¸ç”¨æˆ·é—®é¢˜æœ€ç›¸å…³çš„ç‰‡æ®µ
// å¯¹äºè¶…å¤§å†…å®¹ï¼ˆ>30KBï¼‰ï¼Œä½¿ç”¨ chunkmaker åˆ‡ç‰‡ + overlap æŠ€æœ¯åˆ†æ‰¹å¤„ç†
func (r *ReAct) compressKnowledgeResults(ctx context.Context, knowledgeContent string, userQuery string, maxRanges int) string {
	if len(knowledgeContent) == 0 {
		return knowledgeContent
	}

	// å¦‚æœå†…å®¹ä¸å¤Ÿé•¿ï¼Œä¸éœ€è¦å‹ç¼©
	if len(knowledgeContent) < 3000 {
		log.Infof("compressKnowledgeResults: content too short (%d chars), skip compression", len(knowledgeContent))
		return knowledgeContent
	}

	// è®¾ç½®é»˜è®¤å‚æ•°
	if maxRanges <= 0 {
		maxRanges = 15
	}

	// å¯¹äºè¶…å¤§å†…å®¹ï¼ˆ>30KBï¼‰ï¼Œä½¿ç”¨åˆ†ç‰‡å¤„ç†
	const maxChunkSize = 30 * 1024 // 30KB per chunk
	const overlapSize = 2 * 1024   // 2KB overlap

	if len(knowledgeContent) > maxChunkSize {
		log.Infof("compressKnowledgeResults: content too large (%d bytes), using chunked processing", len(knowledgeContent))
		return r.compressKnowledgeResultsChunked(ctx, knowledgeContent, userQuery, maxRanges, maxChunkSize, overlapSize)
	}

	// å¯¹äºè¾ƒå°çš„å†…å®¹ï¼Œç›´æ¥å¤„ç†
	return r.compressKnowledgeResultsSingle(ctx, knowledgeContent, userQuery, maxRanges)
}

// compressKnowledgeResultsChunked ä½¿ç”¨åˆ†ç‰‡æ–¹å¼å¤„ç†è¶…å¤§å†…å®¹
// ä½¿ç”¨ chunkmaker åˆ‡ç‰‡ + overlap é‡å åˆ†ç‰‡ï¼Œç„¶åå¯¹æ¯ä¸ªåˆ†ç‰‡è¿›è¡Œ AI ç­›é€‰
func (r *ReAct) compressKnowledgeResultsChunked(ctx context.Context, knowledgeContent string, userQuery string, maxRanges int, chunkSize int, overlapSize int) string {
	log.Infof("compressKnowledgeResultsChunked: processing %d bytes with chunkSize=%d, overlap=%d", len(knowledgeContent), chunkSize, overlapSize)

	// ä½¿ç”¨ utils.PrefixLinesWithLineNumbersReader å°†å†…å®¹è½¬æ¢ä¸ºå¸¦è¡Œå·çš„ Reader
	// ç„¶åä½¿ç”¨ chunkmaker è¿›è¡Œåˆ†ç‰‡
	numberedReader := utils.PrefixLinesWithLineNumbersReader(strings.NewReader(knowledgeContent))

	// åˆ›å»º TextChunkMakerï¼Œä½¿ç”¨æ¢è¡Œç¬¦ä½œä¸ºåˆ†éš”ç¬¦ä¼˜åŒ–åˆ‡åˆ†
	cm, err := chunkmaker.NewTextChunkMaker(
		numberedReader,
		chunkmaker.WithChunkSize(int64(chunkSize)),
		chunkmaker.WithSeparatorTrigger("\n"), // æŒ‰è¡Œåˆ†éš”ï¼Œé¿å…åˆ‡æ–­è¡Œä¸­é—´
		chunkmaker.WithCtx(ctx),
	)
	if err != nil {
		log.Errorf("compressKnowledgeResultsChunked: failed to create chunkmaker: %v", err)
		// å›é€€åˆ°å•æ¬¡å¤„ç†
		return r.compressKnowledgeResultsSingle(ctx, knowledgeContent, userQuery, maxRanges)
	}
	// æ³¨æ„ï¼šä¸ä½¿ç”¨ defer cm.Close()ï¼Œå› ä¸º for-range ç»“æŸå chunkmaker å†…éƒ¨å·²å…³é—­
	// åªåœ¨æå‰ break æ—¶éœ€è¦è°ƒç”¨ Close

	// æ”¶é›†æ¯ä¸ª chunk çš„ç­›é€‰ç»“æœ
	type ChunkResult struct {
		ChunkIndex int
		Ranges     []RankedRange
	}
	var allChunkResults []ChunkResult

	// å¤„ç†æ¯ä¸ª chunk
	chunkIndex := 0
	stoppedEarly := false
	for chunk := range cm.OutputChannel() {
		// ä½¿ç”¨ DumpWithOverlap è·å–å¸¦é‡å çš„å†…å®¹
		// overlapSize è¡¨ç¤ºä»å‰ä¸€ä¸ª chunk è·å–çš„é‡å å­—èŠ‚æ•°
		chunkContentWithOverlap := chunk.DumpWithOverlap(overlapSize)

		// è·å– chunk çš„åŸå§‹å†…å®¹ï¼ˆä¸å¸¦ overlapï¼‰ç”¨äºæå–è¡Œå·èŒƒå›´
		chunkData := string(chunk.Data())

		// ä»å¸¦è¡Œå·çš„å†…å®¹ä¸­æå–èµ·å§‹å’Œç»“æŸè¡Œå·
		startLine, endLine := extractLineNumberRange(chunkData)

		// æ‰“å° chunk å†…å®¹æ‘˜è¦æ—¥å¿—
		chunkPreview := utils.ShrinkString(chunkData, 200)
		log.Infof("compressKnowledgeResultsChunked: chunk %d preview:\n%s", chunkIndex, chunkPreview)

		log.Infof("compressKnowledgeResultsChunked: processing chunk %d (lines %d-%d, size=%d bytes, overlap=%d bytes)",
			chunkIndex, startLine, endLine, len(chunkData), len(chunkContentWithOverlap)-len(chunkData))

		// å¯¹å½“å‰ chunk è¿›è¡Œ AI ç­›é€‰
		// ä¼ å…¥å¸¦ overlap çš„å®Œæ•´å†…å®¹ï¼Œè®© AI ç†è§£ä¸Šä¸‹æ–‡
		chunkRanges := r.compressKnowledgeChunk(ctx, chunkContentWithOverlap, "", userQuery, maxRanges/2+1, startLine, endLine)

		if len(chunkRanges) > 0 {
			allChunkResults = append(allChunkResults, ChunkResult{
				ChunkIndex: chunkIndex,
				Ranges:     chunkRanges,
			})
		}

		log.Infof("compressKnowledgeResultsChunked: chunk %d extracted %d ranges", chunkIndex, len(chunkRanges))

		chunkIndex++

		// é˜²æ­¢å¤„ç†è¿‡å¤š chunk
		if chunkIndex > 20 {
			log.Warnf("compressKnowledgeResultsChunked: too many chunks (%d), stopping early", chunkIndex)
			stoppedEarly = true
			break
		}
	}

	// åªæœ‰åœ¨æå‰åœæ­¢æ—¶æ‰éœ€è¦å…³é—­ï¼ˆæ­£å¸¸å¾ªç¯ç»“æŸå channel å·²ç»å…³é—­ï¼‰
	if stoppedEarly {
		// chunkmaker åœ¨ break åä¸éœ€è¦å†è°ƒç”¨ Closeï¼Œchannel å…³é—­å³å¯
		// ä½†æ¶ˆè´¹å®Œå‰©ä½™çš„ channel å†…å®¹ä»¥é¿å…é˜»å¡
		go func() {
			for range cm.OutputChannel() {
				// drain remaining chunks
			}
		}()
	}

	// åˆå¹¶æ‰€æœ‰ chunk çš„ç»“æœ
	var allRanges []RankedRange
	for _, cr := range allChunkResults {
		allRanges = append(allRanges, cr.Ranges...)
	}

	if len(allRanges) == 0 {
		log.Warnf("compressKnowledgeResultsChunked: no valid ranges extracted from any chunk")
		// è¿”å›æˆªæ–­çš„åŸå§‹å†…å®¹
		if len(knowledgeContent) > 50000 {
			return knowledgeContent[:50000] + "\n\n[... å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­ ...]"
		}
		return knowledgeContent
	}

	// æŒ‰ rank æ’åº
	sort.Slice(allRanges, func(i, j int) bool {
		return allRanges[i].Rank < allRanges[j].Rank
	})

	// é™åˆ¶æœ€ç»ˆç»“æœæ•°é‡
	if len(allRanges) > maxRanges {
		allRanges = allRanges[:maxRanges]
	}

	// å»é‡ï¼ˆåŸºäºè¡ŒèŒƒå›´é‡å ï¼‰
	allRanges = deduplicateRanges(allRanges)

	// ä»åŸå§‹å†…å®¹ä¸­æå–æœ€ç»ˆç»“æœ
	resultEditor := memedit.NewMemEditor(knowledgeContent)
	var result strings.Builder
	result.WriteString(fmt.Sprintf("ã€AI æ™ºèƒ½ç­›é€‰ã€‘ä» %d å­—èŠ‚å†…å®¹ä¸­æå–çš„ %d ä¸ªæœ€ç›¸å…³çŸ¥è¯†ç‰‡æ®µï¼š\n\n", len(knowledgeContent), len(allRanges)))

	totalExtracted := 0
	maxTotalLines := 200

	for i, item := range allRanges {
		text := resultEditor.GetTextFromPositionInt(item.StartLine, 1, item.EndLine, 1)
		if text == "" {
			continue
		}

		lineCount := strings.Count(text, "\n") + 1
		if totalExtracted+lineCount > maxTotalLines {
			result.WriteString(fmt.Sprintf("\n[... å·²è¾¾åˆ° %d è¡Œé™åˆ¶ï¼Œå‰©ä½™ %d ä¸ªç‰‡æ®µæœªå±•ç¤º ...]\n", maxTotalLines, len(allRanges)-i))
			break
		}

		result.WriteString(fmt.Sprintf("=== [%d] ç›¸å…³æ€§æ’åº: %d (è¡Œ %d-%d) ===\n", i+1, item.Rank, item.StartLine, item.EndLine))
		if item.Reason != "" {
			result.WriteString(fmt.Sprintf("ç›¸å…³æ€§è¯´æ˜: %s\n", item.Reason))
		}
		result.WriteString(text)
		result.WriteString("\n\n")

		totalExtracted += lineCount
	}

	finalResult := result.String()

	log.Infof("compressKnowledgeResultsChunked: compressed from %d chars to %d chars, %d ranges from %d chunks",
		len(knowledgeContent), len(finalResult), len(allRanges), len(allChunkResults))

	return finalResult
}

// extractLineNumberRange ä»å¸¦è¡Œå·çš„å†…å®¹ä¸­æå–èµ·å§‹å’Œç»“æŸè¡Œå·
// å†…å®¹æ ¼å¼ç±»ä¼¼: "  1 | content\n  2 | content\n..."
func extractLineNumberRange(content string) (startLine int, endLine int) {
	lines := strings.Split(content, "\n")
	startLine = 0
	endLine = 0

	for _, line := range lines {
		if line == "" {
			continue
		}
		// æŸ¥æ‰¾è¡Œå·ï¼ˆæ ¼å¼: "æ•°å­— | å†…å®¹" æˆ– "æ•°å­—|å†…å®¹"ï¼‰
		parts := strings.SplitN(line, "|", 2)
		if len(parts) >= 1 {
			numStr := strings.TrimSpace(parts[0])
			if num, err := strconv.Atoi(numStr); err == nil {
				if startLine == 0 {
					startLine = num
				}
				endLine = num
			}
		}
	}

	if startLine == 0 {
		startLine = 1
	}
	if endLine == 0 {
		endLine = startLine
	}

	return startLine, endLine
}

// RankedRange è¡¨ç¤ºä¸€ä¸ªå¸¦æ’åçš„è¡ŒèŒƒå›´
type RankedRange struct {
	Range     string
	StartLine int
	EndLine   int
	Rank      int
	Reason    string
	Text      string
}

// deduplicateRanges å»é™¤é‡å çš„èŒƒå›´
func deduplicateRanges(ranges []RankedRange) []RankedRange {
	if len(ranges) <= 1 {
		return ranges
	}

	var result []RankedRange
	for _, r := range ranges {
		overlaps := false
		for _, existing := range result {
			// æ£€æŸ¥æ˜¯å¦é‡å 
			if r.StartLine <= existing.EndLine && r.EndLine >= existing.StartLine {
				overlaps = true
				break
			}
		}
		if !overlaps {
			result = append(result, r)
		}
	}
	return result
}

// compressKnowledgeChunk å¯¹å•ä¸ª chunk è¿›è¡Œ AI ç­›é€‰
func (r *ReAct) compressKnowledgeChunk(ctx context.Context, chunkContentWithLineNum string, overlapContext string, userQuery string, maxRanges int, chunkStartLine int, chunkEndLine int) []RankedRange {
	dNonce := utils.RandStringBytes(4)
	minLines := 3
	maxLines := 20

	var overlapSection string
	if overlapContext != "" {
		overlapSection = fmt.Sprintf(`<|OVERLAP_CONTEXT_{{ .nonce }}|>
%s
<|OVERLAP_CONTEXT_END_{{ .nonce }}|>

`, overlapContext)
	}

	promptTemplate := `<|USER_QUERY_{{ .nonce }}|>
{{ .userQuery }}
<|USER_QUERY_END_{{ .nonce }}|>

` + overlapSection + `<|KNOWLEDGE_CHUNK_{{ .nonce }}|>
å½“å‰å¤„ç†åˆ†ç‰‡: è¡Œ {{ .chunkStart }} - {{ .chunkEnd }}
{{ .samples }}
<|KNOWLEDGE_CHUNK_END_{{ .nonce }}|>

<|INSTRUCT_{{ .nonce }}|>
ã€æ™ºèƒ½çŸ¥è¯†ç­›é€‰ã€‘è¯·ä»å½“å‰åˆ†ç‰‡ä¸­æå–ä¸ç”¨æˆ·é—®é¢˜æœ€ç›¸å…³çš„çŸ¥è¯†ç‰‡æ®µã€‚

ã€æ ¸å¿ƒä»»åŠ¡ã€‘
ä»ä¸Šè¿°å¸¦è¡Œå·çš„çŸ¥è¯†å†…å®¹ä¸­ï¼Œæå–ä¸ç”¨æˆ·é—®é¢˜ç›´æ¥ç›¸å…³çš„ç‰‡æ®µã€‚

ã€è¾“å‡ºè¦æ±‚ã€‘
1. æœ€å¤šæå– %d ä¸ªç‰‡æ®µ
2. æ¯ä¸ªç‰‡æ®µ %d-%d è¡Œ
3. ä½¿ç”¨åŸå§‹è¡Œå·ï¼ˆç¬¬ä¸€åˆ—æ•°å­—ï¼‰
4. æŒ‰ç›¸å…³æ€§æ’åºï¼ˆ1æœ€ç›¸å…³ï¼‰

ã€è¯„åˆ¤æ ‡å‡†ã€‘
- rank 1-3: ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜
- rank 4-7: ç›¸å…³èƒŒæ™¯/æŠ€æœ¯ç»†èŠ‚
- rank 8+: è¡¥å……æ€§ä¿¡æ¯

è¯·è¾“å‡º ranges æ•°ç»„ã€‚
<|INSTRUCT_END_{{ .nonce }}|>
`

	materials, err := utils.RenderTemplate(fmt.Sprintf(promptTemplate, maxRanges, minLines, maxLines), map[string]any{
		"nonce":      dNonce,
		"samples":    chunkContentWithLineNum,
		"userQuery":  userQuery,
		"chunkStart": chunkStartLine,
		"chunkEnd":   chunkEndLine,
	})

	if err != nil {
		log.Errorf("compressKnowledgeChunk: template render failed: %v", err)
		return nil
	}

	forgeResult, err := aicommon.InvokeLiteForge(
		materials,
		aicommon.WithContext(ctx),
		aicommon.WithLiteForgeOutputSchemaFromAIToolOptions(
			aitool.WithStructArrayParam(
				"ranges",
				[]aitool.PropertyOption{
					aitool.WithParam_Description("æŒ‰ç›¸å…³æ€§æ’åºçš„çŸ¥è¯†ç‰‡æ®µèŒƒå›´æ•°ç»„"),
				},
				nil,
				aitool.WithStringParam("range", aitool.WithParam_Description("åŸå§‹è¡ŒèŒƒå›´ï¼Œæ ¼å¼: start-end")),
				aitool.WithIntegerParam("rank", aitool.WithParam_Description("ç›¸å…³æ€§æ’åºï¼Œ1æœ€ç›¸å…³")),
				aitool.WithStringParam("relevance_reason", aitool.WithParam_Description("ç›¸å…³æ€§è¯´æ˜")),
			),
		),
	)

	if err != nil {
		log.Errorf("compressKnowledgeChunk: LiteForge failed: %v", err)
		return nil
	}

	if forgeResult == nil {
		return nil
	}

	rangeItems := forgeResult.GetInvokeParamsArray("ranges")
	var results []RankedRange

	for _, item := range rangeItems {
		rangeStr := item.GetString("range")
		rank := item.GetInt("rank")
		reason := item.GetString("relevance_reason")

		if rangeStr == "" {
			continue
		}

		parts := strings.Split(rangeStr, "-")
		if len(parts) != 2 {
			continue
		}

		startLine, err1 := strconv.Atoi(strings.TrimSpace(parts[0]))
		endLine, err2 := strconv.Atoi(strings.TrimSpace(parts[1]))

		if err1 != nil || err2 != nil || startLine <= 0 || endLine < startLine {
			continue
		}

		results = append(results, RankedRange{
			Range:     rangeStr,
			StartLine: startLine,
			EndLine:   endLine,
			Rank:      int(rank),
			Reason:    reason,
		})
	}

	return results
}

// compressKnowledgeResultsSingle å¯¹è¾ƒå°çš„å†…å®¹ç›´æ¥è¿›è¡Œå‹ç¼©ï¼ˆä¸åˆ†ç‰‡ï¼‰
func (r *ReAct) compressKnowledgeResultsSingle(ctx context.Context, knowledgeContent string, userQuery string, maxRanges int) string {
	resultEditor := memedit.NewMemEditor(knowledgeContent)
	dNonce := utils.RandStringBytes(4)

	minLines := 5
	maxLines := 30

	promptTemplate := `<|USER_QUERY_{{ .nonce }}|>
{{ .userQuery }}
<|USER_QUERY_END_{{ .nonce }}|>

<|KNOWLEDGE_RESULTS_{{ .nonce }}|>
{{ .samples }}
<|KNOWLEDGE_RESULTS_END_{{ .nonce }}|>

<|INSTRUCT_{{ .nonce }}|>
ã€æ™ºèƒ½çŸ¥è¯†ç­›é€‰ä¸æ’åºã€‘

è¯·ä¸¥æ ¼æ ¹æ®ç”¨æˆ·é—®é¢˜ä»ä¸Šè¿°çŸ¥è¯†æœç´¢ç»“æœä¸­æå–æœ€æœ‰ä»·å€¼çš„çŸ¥è¯†ç‰‡æ®µï¼ŒæŒ‰ç›¸å…³æ€§æ’åºï¼š

ã€æ ¸å¿ƒåŸåˆ™ã€‘
- å¿…é¡»ä¸ç”¨æˆ·é—®é¢˜ç›´æ¥ç›¸å…³
- è¿‡æ»¤æ‰æ‰€æœ‰æ— å…³çš„çŸ¥è¯†ç‰‡æ®µ
- ä¼˜å…ˆé€‰æ‹©èƒ½ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„çŸ¥è¯†
- ä¿ç•™å®Œæ•´çš„çŸ¥è¯†æ¡ç›®ï¼Œé¿å…æˆªæ–­

ã€æå–è¦æ±‚ã€‘
1. æœ€å¤šæå– %d ä¸ªçŸ¥è¯†ç‰‡æ®µ
2. æ¯ä¸ªç‰‡æ®µ %d-%d è¡Œï¼Œç¡®ä¿ä¸Šä¸‹æ–‡å®Œæ•´
3. æŒ‰ç›¸å…³æ€§ä»é«˜åˆ°ä½æ’åºï¼ˆrank: 1æœ€ç›¸å…³ï¼Œæ•°å­—è¶Šå¤§è¶Šä¸ç›¸å…³ï¼‰
4. ä¸¥æ ¼è¿‡æ»¤ä¸ç”¨æˆ·é—®é¢˜æ— å…³çš„çŸ¥è¯†

ã€ç›¸å…³æ€§è¯„åˆ¤æ ‡å‡†ã€‘ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
ğŸ”¥ æœ€é«˜ç›¸å…³ (rank 1-3)ï¼š
- ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„çŸ¥è¯†
- åŒ…å«ç”¨æˆ·é—®é¢˜ä¸­æåˆ°çš„å…³é”®å®ä½“/æ¦‚å¿µ
- æä¾›å…·ä½“è§£å†³æ–¹æ¡ˆæˆ–æ“ä½œæ­¥éª¤

â­ é«˜åº¦ç›¸å…³ (rank 4-7)ï¼š
- ä¸ç”¨æˆ·é—®é¢˜é¢†åŸŸç›¸å…³çš„çŸ¥è¯†
- æä¾›èƒŒæ™¯ä¿¡æ¯æˆ–ç›¸å…³æ¦‚å¿µè§£é‡Š
- åŒ…å«ç›¸å…³çš„æŠ€æœ¯ç»†èŠ‚æˆ–é…ç½®

ğŸ“ ä¸€èˆ¬ç›¸å…³ (rank 8-15)ï¼š
- å¯èƒ½å¯¹ç†è§£é—®é¢˜æœ‰å¸®åŠ©çš„çŸ¥è¯†
- æä¾›è¡¥å……æ€§ä¿¡æ¯
- ç›¸å…³ä½†ä¸ç›´æ¥å›ç­”é—®é¢˜

ã€è¾“å‡ºæ ¼å¼ã€‘
è¿”å›JSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
{
  "range": "start-end", 
  "rank": æ•°å­—(1-15),
  "relevance_reason": "ä¸ç”¨æˆ·é—®é¢˜çš„ç›¸å…³æ€§è¯´æ˜"
}

ã€ä¸¥æ ¼è¦æ±‚ã€‘
- æ€»å†…å®¹æ§åˆ¶åœ¨åˆç†èŒƒå›´å†…
- é¿å…é‡å¤æˆ–é«˜åº¦ç›¸ä¼¼çš„çŸ¥è¯†ç‰‡æ®µ
- ä¼˜å…ˆé€‰æ‹©ä¿¡æ¯å¯†åº¦é«˜çš„çŸ¥è¯†
- ç¡®ä¿æ¯ä¸ªç‰‡æ®µéƒ½å¯¹å›ç­”ç”¨æˆ·é—®é¢˜æœ‰ä»·å€¼

è¯·æŒ‰ç›¸å…³æ€§æ’åºè¾“å‡ºrangesæ•°ç»„ã€‚
<|INSTRUCT_END_{{ .nonce }}|>
`

	materials, err := utils.RenderTemplate(fmt.Sprintf(promptTemplate, maxRanges, minLines, maxLines), map[string]any{
		"nonce":     dNonce,
		"samples":   utils.PrefixLinesWithLineNumbers(knowledgeContent),
		"userQuery": userQuery,
	})

	if err != nil {
		log.Errorf("compressKnowledgeResultsSingle: template render failed: %v", err)
		return knowledgeContent
	}

	forgeResult, err := aicommon.InvokeLiteForge(
		materials,
		aicommon.WithContext(ctx),
		aicommon.WithLiteForgeOutputSchemaFromAIToolOptions(
			aitool.WithStructArrayParam(
				"ranges",
				[]aitool.PropertyOption{
					aitool.WithParam_Description("æŒ‰ç›¸å…³æ€§æ’åºçš„çŸ¥è¯†ç‰‡æ®µèŒƒå›´æ•°ç»„"),
				},
				nil,
				aitool.WithStringParam("range", aitool.WithParam_Description("è¡ŒèŒƒå›´ï¼Œæ ¼å¼: start-endï¼Œä¾‹å¦‚ 18-45")),
				aitool.WithIntegerParam("rank", aitool.WithParam_Description("ç›¸å…³æ€§æ’åºï¼Œ1æœ€ç›¸å…³ï¼Œæ•°å­—è¶Šå¤§è¶Šä¸ç›¸å…³")),
				aitool.WithStringParam("relevance_reason", aitool.WithParam_Description("ä¸ç”¨æˆ·é—®é¢˜çš„ç›¸å…³æ€§è¯´æ˜")),
			),
		),
	)

	if err != nil {
		log.Errorf("compressKnowledgeResultsSingle: LiteForge failed: %v", err)
		return knowledgeContent
	}

	if forgeResult == nil {
		log.Warnf("compressKnowledgeResultsSingle: forge result is nil")
		return knowledgeContent
	}

	rangeItems := forgeResult.GetInvokeParamsArray("ranges")

	if len(rangeItems) == 0 {
		log.Warnf("compressKnowledgeResultsSingle: no ranges extracted")
		return knowledgeContent
	}

	var rankedRanges []RankedRange
	totalLines := 0
	maxTotalLines := 150

	for _, item := range rangeItems {
		rangeStr := item.GetString("range")
		rank := item.GetInt("rank")
		reason := item.GetString("relevance_reason")

		if rangeStr == "" {
			continue
		}

		parts := strings.Split(rangeStr, "-")
		if len(parts) != 2 {
			log.Warnf("compressKnowledgeResultsSingle: invalid range format: %s", rangeStr)
			continue
		}

		startLine, err1 := strconv.Atoi(strings.TrimSpace(parts[0]))
		endLine, err2 := strconv.Atoi(strings.TrimSpace(parts[1]))

		if err1 != nil || err2 != nil {
			log.Errorf("compressKnowledgeResultsSingle: parse range failed: %s, errors: %v, %v", rangeStr, err1, err2)
			continue
		}

		if startLine <= 0 || endLine < startLine {
			log.Warnf("compressKnowledgeResultsSingle: invalid range values: %s (start=%d, end=%d)", rangeStr, startLine, endLine)
			continue
		}

		text := resultEditor.GetTextFromPositionInt(startLine, 1, endLine, 1)
		if text == "" {
			log.Warnf("compressKnowledgeResultsSingle: empty text for range: %s", rangeStr)
			continue
		}

		lineCount := strings.Count(text, "\n") + 1
		if totalLines+lineCount > maxTotalLines {
			log.Warnf("compressKnowledgeResultsSingle: would exceed %d lines limit, stopping at range: %s", maxTotalLines, rangeStr)
			break
		}

		rankedRanges = append(rankedRanges, RankedRange{
			Range:     rangeStr,
			StartLine: startLine,
			EndLine:   endLine,
			Rank:      int(rank),
			Reason:    reason,
			Text:      text,
		})

		totalLines += lineCount
	}

	if len(rankedRanges) == 0 {
		log.Warnf("compressKnowledgeResultsSingle: no valid ranges extracted")
		return knowledgeContent
	}

	sort.Slice(rankedRanges, func(i, j int) bool {
		return rankedRanges[i].Rank < rankedRanges[j].Rank
	})

	var result strings.Builder
	result.WriteString("ã€AI æ™ºèƒ½ç­›é€‰ã€‘æŒ‰ç›¸å…³æ€§æ’åºçš„çŸ¥è¯†ç‰‡æ®µï¼š\n\n")

	for i, item := range rankedRanges {
		result.WriteString(fmt.Sprintf("=== [%d] ç›¸å…³æ€§æ’åº: %d ===\n", i+1, item.Rank))
		if item.Reason != "" {
			result.WriteString(fmt.Sprintf("ç›¸å…³æ€§è¯´æ˜: %s\n", item.Reason))
		}
		result.WriteString(item.Text)
		result.WriteString("\n\n")
	}

	finalResult := result.String()

	log.Infof("compressKnowledgeResultsSingle: compressed from %d chars to %d chars, %d ranges extracted",
		len(knowledgeContent), len(finalResult), len(rankedRanges))

	return finalResult
}
