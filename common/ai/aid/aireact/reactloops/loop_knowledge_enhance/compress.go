package loop_knowledge_enhance

import (
	"context"
	"fmt"
	"sort"
	"strconv"
	"strings"

	"github.com/yaklang/yaklang/common/ai/aid/aicommon"
	"github.com/yaklang/yaklang/common/ai/aid/aireact/reactloops"
	"github.com/yaklang/yaklang/common/ai/aid/aitool"
	"github.com/yaklang/yaklang/common/log"
	"github.com/yaklang/yaklang/common/utils"
	"github.com/yaklang/yaklang/common/utils/memedit"
)

// ScoredRange represents a line range with relevance score
type ScoredRange struct {
	Range     string
	StartLine int
	EndLine   int
	Score     float64 // ç›¸å…³æ€§è¯„åˆ†ï¼Œ0.0-1.0ï¼Œè¶Šé«˜è¶Šç›¸å…³
	Text      string
}

// deduplicateScoredRanges removes overlapping ranges, keeping higher scored ones
func deduplicateScoredRanges(ranges []ScoredRange) []ScoredRange {
	if len(ranges) <= 1 {
		return ranges
	}

	var result []ScoredRange
	for _, r := range ranges {
		overlaps := false
		for _, existing := range result {
			// Check for overlap
			if r.StartLine <= existing.EndLine && r.EndLine >= existing.StartLine {
				overlaps = true
				break
			}
		}
		if !overlaps {
			result = append(result, r)
		}
	}
	return result
}

// compressKnowledgeResultsWithScore compresses knowledge content using AI with 0.0-1.0 scoring
// Reference: invoke_enhance_knowlege_answer.go
func compressKnowledgeResultsWithScore(
	resultStr string,
	userQuery string,
	invoker aicommon.AIInvokeRuntime,
	loop *reactloops.ReActLoop,
	maxBytes int,
) string {
	if len(resultStr) == 0 {
		return resultStr
	}

	// Skip compression for small content (< 3KB)
	if len(resultStr) < 3000 {
		log.Infof("compressKnowledgeResultsWithScore: content too short (%d chars), skip compression", len(resultStr))
		return resultStr
	}

	// Set default maxBytes
	if maxBytes <= 0 {
		maxBytes = 10 * 1024 // 10KB default
	}

	// For large content (>40KB), use chunked processing
	const maxChunkSize = 40 * 1024 // 40KB per chunk
	const overlapLines = 20        // 20 lines overlap
	const maxChunks = 10           // max 10 chunks

	ctx := invoker.GetConfig().GetContext()
	if loop != nil && loop.GetCurrentTask() != nil && !utils.IsNil(loop.GetCurrentTask().GetContext()) {
		ctx = loop.GetCurrentTask().GetContext()
	}

	if len(resultStr) > maxChunkSize {
		log.Infof("compressKnowledgeResultsWithScore: content too large (%d bytes), using chunked processing", len(resultStr))
		return compressKnowledgeResultsChunkedWithScore(ctx, resultStr, userQuery, invoker, loop, maxBytes, maxChunkSize, overlapLines, maxChunks)
	}

	// For smaller content, use single compression
	return compressKnowledgeResultsSingleWithScore(ctx, resultStr, userQuery, invoker, loop, maxBytes)
}

// compressKnowledgeResultsSingleWithScore handles compression for content < 40KB
func compressKnowledgeResultsSingleWithScore(
	ctx context.Context,
	knowledgeContent string,
	userQuery string,
	invoker aicommon.AIInvokeRuntime,
	loop *reactloops.ReActLoop,
	maxBytes int,
) string {
	resultEditor := memedit.NewMemEditor(knowledgeContent)
	dNonce := utils.RandStringBytes(4)

	minLines := 5
	maxLines := 30
	maxRanges := 15

	promptTemplate := `<|USER_QUERY_{{ .nonce }}|>
{{ .userQuery }}
<|USER_QUERY_END_{{ .nonce }}|>

<|KNOWLEDGE_RESULTS_{{ .nonce }}|>
{{ .samples }}
<|KNOWLEDGE_RESULTS_END_{{ .nonce }}|>

<|INSTRUCT_{{ .nonce }}|>
ã€æ™ºèƒ½çŸ¥è¯†ç­›é€‰ä¸æ’åºã€‘

è¯·ä¸¥æ ¼æ ¹æ®ç”¨æˆ·é—®é¢˜ä»ä¸Šè¿°çŸ¥è¯†æœç´¢ç»“æœä¸­æå–æœ€æœ‰ä»·å€¼çš„çŸ¥è¯†ç‰‡æ®µï¼ŒæŒ‰ç›¸å…³æ€§è¯„åˆ†æ’åºï¼š

ã€æ ¸å¿ƒåŸåˆ™ã€‘
- å¿…é¡»ä¸ç”¨æˆ·é—®é¢˜ç›´æ¥ç›¸å…³
- è¿‡æ»¤æ‰æ‰€æœ‰æ— å…³çš„çŸ¥è¯†ç‰‡æ®µ
- ä¼˜å…ˆé€‰æ‹©èƒ½ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„çŸ¥è¯†
- ä¿ç•™å®Œæ•´çš„çŸ¥è¯†æ¡ç›®ï¼Œé¿å…æˆªæ–­

ã€æå–è¦æ±‚ã€‘
1. æœ€å¤šæå– %d ä¸ªçŸ¥è¯†ç‰‡æ®µ
2. æ¯ä¸ªç‰‡æ®µ %d-%d è¡Œï¼Œç¡®ä¿ä¸Šä¸‹æ–‡å®Œæ•´
3. ç»™å‡º 0.0-1.0 çš„ç›¸å…³æ€§è¯„åˆ†ï¼ˆscoreï¼‰ï¼Œè¶Šé«˜è¶Šç›¸å…³
4. ä¸¥æ ¼è¿‡æ»¤ä¸ç”¨æˆ·é—®é¢˜æ— å…³çš„çŸ¥è¯†

ã€è¯„åˆ†æ ‡å‡†ã€‘
ğŸ”¥ é«˜åº¦ç›¸å…³ (0.8-1.0)ï¼š
- ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„çŸ¥è¯†
- åŒ…å«ç”¨æˆ·é—®é¢˜ä¸­æåˆ°çš„å…³é”®å®ä½“/æ¦‚å¿µ
- æä¾›å…·ä½“è§£å†³æ–¹æ¡ˆæˆ–æ“ä½œæ­¥éª¤

â­ è¾ƒé«˜ç›¸å…³ (0.6-0.8)ï¼š
- ä¸ç”¨æˆ·é—®é¢˜é¢†åŸŸç›¸å…³çš„çŸ¥è¯†
- æä¾›èƒŒæ™¯ä¿¡æ¯æˆ–ç›¸å…³æ¦‚å¿µè§£é‡Š
- åŒ…å«ç›¸å…³çš„æŠ€æœ¯ç»†èŠ‚æˆ–é…ç½®

ğŸ“ ä¸€èˆ¬ç›¸å…³ (0.4-0.6)ï¼š
- å¯èƒ½å¯¹ç†è§£é—®é¢˜æœ‰å¸®åŠ©çš„çŸ¥è¯†
- æä¾›è¡¥å……æ€§ä¿¡æ¯
- ç›¸å…³ä½†ä¸ç›´æ¥å›ç­”é—®é¢˜

âŒ å¼±ç›¸å…³ (0.0-0.4)ï¼šä¸è¾“å‡º

ã€è¾“å‡ºæ ¼å¼ã€‘
è¿”å›JSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
{
  "range": "start-end", 
  "score": 0.0-1.0çš„å°æ•°
}

è¯·æŒ‰ç›¸å…³æ€§è¯„åˆ†ä»é«˜åˆ°ä½è¾“å‡ºrangesæ•°ç»„ã€‚
<|INSTRUCT_END_{{ .nonce }}|>
`

	materials, err := utils.RenderTemplate(fmt.Sprintf(promptTemplate, maxRanges, minLines, maxLines), map[string]any{
		"nonce":     dNonce,
		"samples":   utils.PrefixLinesWithLineNumbers(knowledgeContent),
		"userQuery": userQuery,
	})

	if err != nil {
		log.Errorf("compressKnowledgeResultsSingleWithScore: template render failed: %v", err)
		return knowledgeContent
	}

	// Create pipe for streaming output
	pr, pw := utils.NewPipe()

	// Get task index for emit
	var taskIndex string
	if loop != nil && loop.GetCurrentTask() != nil {
		taskIndex = loop.GetCurrentTask().GetIndex()
	}

	// Start streaming output with unified nodeId
	if loop != nil {
		loop.GetEmitter().EmitDefaultStreamEvent(
			"knowledge-compress",
			pr,
			taskIndex,
		)
	}

	forgeResult, err := invoker.InvokeLiteForge(
		ctx,
		"knowledge-compress",
		materials,
		[]aitool.ToolOption{
			aitool.WithStructArrayParam(
				"ranges",
				[]aitool.PropertyOption{
					aitool.WithParam_Description("æŒ‰ç›¸å…³æ€§è¯„åˆ†æ’åºçš„çŸ¥è¯†ç‰‡æ®µèŒƒå›´æ•°ç»„"),
				},
				nil,
				aitool.WithStringParam("range", aitool.WithParam_Description("è¡ŒèŒƒå›´ï¼Œæ ¼å¼: start-endï¼Œä¾‹å¦‚ 18-45")),
				aitool.WithNumberParam("score", aitool.WithParam_Description("ç›¸å…³æ€§è¯„åˆ†ï¼Œ0.0-1.0ï¼Œè¶Šé«˜è¶Šç›¸å…³")),
			),
		},
	)

	if err != nil {
		log.Errorf("compressKnowledgeResultsSingleWithScore: LiteForge failed: %v", err)
		pw.Close()
		return knowledgeContent
	}

	if forgeResult == nil {
		log.Warnf("compressKnowledgeResultsSingleWithScore: forge result is nil")
		pw.Close()
		return knowledgeContent
	}

	rangeItems := forgeResult.GetInvokeParamsArray("ranges")

	if len(rangeItems) == 0 {
		log.Warnf("compressKnowledgeResultsSingleWithScore: no ranges extracted")
		pw.Close()
		return knowledgeContent
	}

	var scoredRanges []ScoredRange

	for _, item := range rangeItems {
		rangeStr := item.GetString("range")
		score := item.GetFloat("score")

		if rangeStr == "" {
			continue
		}

		// Filter out low score items (< 0.4)
		if score < 0.4 {
			continue
		}

		parts := strings.Split(rangeStr, "-")
		if len(parts) != 2 {
			log.Warnf("compressKnowledgeResultsSingleWithScore: invalid range format: %s", rangeStr)
			continue
		}

		startLine, err1 := strconv.Atoi(strings.TrimSpace(parts[0]))
		endLine, err2 := strconv.Atoi(strings.TrimSpace(parts[1]))

		if err1 != nil || err2 != nil {
			log.Errorf("compressKnowledgeResultsSingleWithScore: parse range failed: %s, errors: %v, %v", rangeStr, err1, err2)
			continue
		}

		if startLine <= 0 || endLine < startLine {
			log.Warnf("compressKnowledgeResultsSingleWithScore: invalid range values: %s (start=%d, end=%d)", rangeStr, startLine, endLine)
			continue
		}

		text := resultEditor.GetTextFromPositionInt(startLine, 1, endLine, 1)
		if text == "" {
			log.Warnf("compressKnowledgeResultsSingleWithScore: empty text for range: %s", rangeStr)
			continue
		}

		// Write to stream: ç‰‡æ®µï¼š[Score: 0.x] startLine-endLine
		pw.WriteString(fmt.Sprintf("ç‰‡æ®µï¼š[Score: %.2f] %d-%d\n", score, startLine, endLine))

		scoredRanges = append(scoredRanges, ScoredRange{
			Range:     rangeStr,
			StartLine: startLine,
			EndLine:   endLine,
			Score:     score,
			Text:      text,
		})
	}

	pw.Close()

	if len(scoredRanges) == 0 {
		log.Warnf("compressKnowledgeResultsSingleWithScore: no valid ranges extracted")
		return knowledgeContent
	}

	// Sort by score descending (higher score = more relevant)
	sort.Slice(scoredRanges, func(i, j int) bool {
		return scoredRanges[i].Score > scoredRanges[j].Score
	})

	var result strings.Builder
	result.WriteString("ã€AI æ™ºèƒ½ç­›é€‰ã€‘æŒ‰ç›¸å…³æ€§è¯„åˆ†æ’åºçš„çŸ¥è¯†ç‰‡æ®µï¼š\n\n")

	currentBytes := 0
	for i, item := range scoredRanges {
		if currentBytes+len(item.Text) > maxBytes {
			log.Infof("compressKnowledgeResultsSingleWithScore: reached %d bytes limit, stopping at %d ranges", maxBytes, i)
			break
		}
		result.WriteString(fmt.Sprintf("=== [%d] Score: %.2f ===\n", i+1, item.Score))
		result.WriteString(item.Text)
		result.WriteString("\n\n")
		currentBytes += len(item.Text)
	}

	finalResult := result.String()

	log.Infof("compressKnowledgeResultsSingleWithScore: compressed from %d chars to %d chars (%d bytes), %d ranges extracted",
		len(knowledgeContent), len(finalResult), currentBytes, len(scoredRanges))

	return finalResult
}

// compressKnowledgeResultsChunkedWithScore handles compression for content > 40KB using chunked processing
func compressKnowledgeResultsChunkedWithScore(
	ctx context.Context,
	knowledgeContent string,
	userQuery string,
	invoker aicommon.AIInvokeRuntime,
	loop *reactloops.ReActLoop,
	maxBytes int,
	chunkSize int,
	overlapLines int,
	maxChunks int,
) string {
	// Step 1: Split by lines
	originalLines := strings.Split(knowledgeContent, "\n")
	totalLines := len(originalLines)

	log.Infof("compressKnowledgeResultsChunkedWithScore: processing %d bytes, %d lines, chunkSize=%d, overlapLines=%d, maxChunks=%d",
		len(knowledgeContent), totalLines, chunkSize, overlapLines, maxChunks)

	// Step 2: Calculate lines per chunk
	avgLineLen := len(knowledgeContent)/totalLines + 10
	linesPerChunk := chunkSize / avgLineLen
	if linesPerChunk < 50 {
		linesPerChunk = 50
	}

	// Adjust to ensure not exceeding maxChunks
	effectiveLinesPerChunk := linesPerChunk - overlapLines
	if effectiveLinesPerChunk <= 0 {
		effectiveLinesPerChunk = linesPerChunk / 2
	}
	estimatedChunks := (totalLines + effectiveLinesPerChunk - 1) / effectiveLinesPerChunk
	if estimatedChunks > maxChunks {
		effectiveLinesPerChunk = (totalLines + maxChunks - 1) / maxChunks
		linesPerChunk = effectiveLinesPerChunk + overlapLines
		log.Infof("compressKnowledgeResultsChunkedWithScore: adjusted linesPerChunk to %d to limit chunks to %d", linesPerChunk, maxChunks)
	}

	// Step 3: Process chunks
	var allScoredRanges []ScoredRange

	chunkIndex := 0
	for startLineIdx := 0; startLineIdx < totalLines && chunkIndex < maxChunks; chunkIndex++ {
		startLine := startLineIdx + 1
		endLineIdx := startLineIdx + linesPerChunk
		if endLineIdx > totalLines {
			endLineIdx = totalLines
		}
		endLine := endLineIdx

		chunkLines := originalLines[startLineIdx:endLineIdx]

		// Build chunk content with line numbers
		var chunkBuilder strings.Builder
		for i, line := range chunkLines {
			lineNum := startLineIdx + i + 1
			chunkBuilder.WriteString(fmt.Sprintf("%d | %s\n", lineNum, line))
		}
		chunkContent := chunkBuilder.String()

		// Add overlap context
		var chunkWithOverlap string
		if startLineIdx > 0 && overlapLines > 0 {
			overlapStartIdx := startLineIdx - overlapLines
			if overlapStartIdx < 0 {
				overlapStartIdx = 0
			}
			overlapLinesContent := originalLines[overlapStartIdx:startLineIdx]
			var overlapBuilder strings.Builder
			overlapBuilder.WriteString("--- [ä¸Šä¸‹æ–‡å¼€å§‹] ---\n")
			for i, line := range overlapLinesContent {
				lineNum := overlapStartIdx + i + 1
				overlapBuilder.WriteString(fmt.Sprintf("%d | %s\n", lineNum, line))
			}
			overlapBuilder.WriteString("--- [ä¸Šä¸‹æ–‡ç»“æŸ] ---\n\n")
			chunkWithOverlap = overlapBuilder.String() + chunkContent
		} else {
			chunkWithOverlap = chunkContent
		}

		// Process chunk
		chunkRanges := compressKnowledgeChunkWithScore(ctx, chunkWithOverlap, userQuery, invoker, loop, startLine, endLine)

		if len(chunkRanges) > 0 {
			allScoredRanges = append(allScoredRanges, chunkRanges...)
			log.Infof("compressKnowledgeResultsChunkedWithScore: chunk %d extracted %d ranges", chunkIndex+1, len(chunkRanges))
		}

		// Move to next chunk
		startLineIdx = endLineIdx - overlapLines
		if startLineIdx < 0 {
			startLineIdx = 0
		}
		if startLineIdx <= (endLineIdx - linesPerChunk) {
			startLineIdx = endLineIdx
		}
	}

	log.Infof("compressKnowledgeResultsChunkedWithScore: processed %d chunks total", chunkIndex)

	if len(allScoredRanges) == 0 {
		log.Warnf("compressKnowledgeResultsChunkedWithScore: no valid ranges extracted from any chunk")
		if len(knowledgeContent) > 50000 {
			return knowledgeContent[:50000] + "\n\n[... å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­ ...]"
		}
		return knowledgeContent
	}

	// Sort by score descending
	sort.Slice(allScoredRanges, func(i, j int) bool {
		return allScoredRanges[i].Score > allScoredRanges[j].Score
	})

	// Deduplicate
	allScoredRanges = deduplicateScoredRanges(allScoredRanges)

	// Extract final results
	resultEditor := memedit.NewMemEditor(knowledgeContent)
	var result strings.Builder
	result.WriteString(fmt.Sprintf("ã€AI æ™ºèƒ½ç­›é€‰ã€‘ä» %d å­—èŠ‚å†…å®¹ä¸­æå–çš„ %d ä¸ªæœ€ç›¸å…³çŸ¥è¯†ç‰‡æ®µï¼š\n\n", len(knowledgeContent), len(allScoredRanges)))

	totalExtractedBytes := 0

	for i, item := range allScoredRanges {
		text := resultEditor.GetTextFromPositionInt(item.StartLine, 1, item.EndLine, 1)
		if text == "" {
			continue
		}

		textBytes := len(text)
		if totalExtractedBytes+textBytes > maxBytes {
			result.WriteString(fmt.Sprintf("\n[... å·²è¾¾åˆ° %d å­—èŠ‚é™åˆ¶ï¼Œå‰©ä½™ %d ä¸ªç‰‡æ®µæœªå±•ç¤º ...]\n", maxBytes, len(allScoredRanges)-i))
			break
		}

		result.WriteString(fmt.Sprintf("=== [%d] Score: %.2f (è¡Œ %d-%d) ===\n", i+1, item.Score, item.StartLine, item.EndLine))
		result.WriteString(text)
		result.WriteString("\n\n")

		totalExtractedBytes += textBytes
	}

	finalResult := result.String()

	log.Infof("compressKnowledgeResultsChunkedWithScore: compressed from %d chars to %d chars (%d bytes), %d ranges",
		len(knowledgeContent), len(finalResult), totalExtractedBytes, len(allScoredRanges))

	return finalResult
}

// compressKnowledgeChunkWithScore processes a single chunk for AI filtering
func compressKnowledgeChunkWithScore(
	ctx context.Context,
	chunkContentWithLineNum string,
	userQuery string,
	invoker aicommon.AIInvokeRuntime,
	loop *reactloops.ReActLoop,
	chunkStartLine int,
	chunkEndLine int,
) []ScoredRange {
	dNonce := utils.RandStringBytes(4)
	minLines := 3
	maxLines := 20
	maxRanges := 8

	promptTemplate := `<|USER_QUERY_{{ .nonce }}|>
{{ .userQuery }}
<|USER_QUERY_END_{{ .nonce }}|>

<|KNOWLEDGE_CHUNK_{{ .nonce }}|>
å½“å‰å¤„ç†åˆ†ç‰‡: è¡Œ {{ .chunkStart }} - {{ .chunkEnd }}
{{ .samples }}
<|KNOWLEDGE_CHUNK_END_{{ .nonce }}|>

<|INSTRUCT_{{ .nonce }}|>
ã€æ™ºèƒ½çŸ¥è¯†ç­›é€‰ã€‘è¯·ä»å½“å‰åˆ†ç‰‡ä¸­æå–ä¸ç”¨æˆ·é—®é¢˜æœ€ç›¸å…³çš„çŸ¥è¯†ç‰‡æ®µã€‚

ã€æ ¸å¿ƒä»»åŠ¡ã€‘
ä»ä¸Šè¿°å¸¦è¡Œå·çš„çŸ¥è¯†å†…å®¹ä¸­ï¼Œæå–ä¸ç”¨æˆ·é—®é¢˜ç›´æ¥ç›¸å…³çš„ç‰‡æ®µã€‚

ã€è¾“å‡ºè¦æ±‚ã€‘
1. æœ€å¤šæå– %d ä¸ªç‰‡æ®µ
2. æ¯ä¸ªç‰‡æ®µ %d-%d è¡Œ
3. ä½¿ç”¨åŸå§‹è¡Œå·ï¼ˆç¬¬ä¸€åˆ—æ•°å­—ï¼‰
4. ç»™å‡º 0.0-1.0 çš„ç›¸å…³æ€§è¯„åˆ†ï¼ˆscoreï¼‰ï¼Œè¶Šé«˜è¶Šç›¸å…³

ã€è¯„åˆ†æ ‡å‡†ã€‘
- 0.8-1.0: ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„æ ¸å¿ƒå†…å®¹
- 0.6-0.8: ç›¸å…³èƒŒæ™¯/æŠ€æœ¯ç»†èŠ‚
- 0.4-0.6: è¡¥å……æ€§ä¿¡æ¯
- 0.0-0.4: å¼±ç›¸å…³æˆ–æ— å…³å†…å®¹ï¼ˆä¸è¾“å‡ºï¼‰

è¯·è¾“å‡º ranges æ•°ç»„ã€‚
<|INSTRUCT_END_{{ .nonce }}|>
`

	materials, err := utils.RenderTemplate(fmt.Sprintf(promptTemplate, maxRanges, minLines, maxLines), map[string]any{
		"nonce":      dNonce,
		"samples":    chunkContentWithLineNum,
		"userQuery":  userQuery,
		"chunkStart": chunkStartLine,
		"chunkEnd":   chunkEndLine,
	})

	if err != nil {
		log.Errorf("compressKnowledgeChunkWithScore: template render failed: %v", err)
		return nil
	}

	// Create pipe for streaming output
	pr, pw := utils.NewPipe()

	// Get task index for emit
	var taskIndex string
	if loop != nil && loop.GetCurrentTask() != nil {
		taskIndex = loop.GetCurrentTask().GetIndex()
	}

	// Start streaming output with unified nodeId
	if loop != nil {
		loop.GetEmitter().EmitDefaultStreamEvent(
			"knowledge-compress",
			pr,
			taskIndex,
		)
	}

	forgeResult, err := invoker.InvokeLiteForge(
		ctx,
		"knowledge-compress",
		materials,
		[]aitool.ToolOption{
			aitool.WithStructArrayParam(
				"ranges",
				[]aitool.PropertyOption{
					aitool.WithParam_Description("æŒ‰ç›¸å…³æ€§è¯„åˆ†æ’åºçš„çŸ¥è¯†ç‰‡æ®µèŒƒå›´æ•°ç»„"),
				},
				nil,
				aitool.WithStringParam("range", aitool.WithParam_Description("åŸå§‹è¡ŒèŒƒå›´ï¼Œæ ¼å¼: start-end")),
				aitool.WithNumberParam("score", aitool.WithParam_Description("ç›¸å…³æ€§è¯„åˆ†ï¼Œ0.0-1.0ï¼Œè¶Šé«˜è¶Šç›¸å…³")),
			),
		},
	)

	if err != nil {
		log.Errorf("compressKnowledgeChunkWithScore: LiteForge failed: %v", err)
		pw.Close()
		return nil
	}

	if forgeResult == nil {
		pw.Close()
		return nil
	}

	rangeItems := forgeResult.GetInvokeParamsArray("ranges")
	var results []ScoredRange

	for _, item := range rangeItems {
		rangeStr := item.GetString("range")
		score := item.GetFloat("score")

		if rangeStr == "" {
			continue
		}

		// Filter out low score items (< 0.4)
		if score < 0.4 {
			continue
		}

		parts := strings.Split(rangeStr, "-")
		if len(parts) != 2 {
			continue
		}

		startLine, err1 := strconv.Atoi(strings.TrimSpace(parts[0]))
		endLine, err2 := strconv.Atoi(strings.TrimSpace(parts[1]))

		if err1 != nil || err2 != nil || startLine <= 0 || endLine < startLine {
			continue
		}

		// Write to stream
		pw.WriteString(fmt.Sprintf("ç‰‡æ®µï¼š[Score: %.2f] %d-%d\n", score, startLine, endLine))

		results = append(results, ScoredRange{
			Range:     rangeStr,
			StartLine: startLine,
			EndLine:   endLine,
			Score:     score,
		})
	}

	pw.Close()
	return results
}
