package loop_knowledge_enhance

import (
	"context"
	"fmt"
	"sort"
	"strconv"
	"strings"
	"sync"

	"github.com/yaklang/yaklang/common/ai/aid"
	"github.com/yaklang/yaklang/common/ai/aid/aicommon"
	"github.com/yaklang/yaklang/common/ai/aid/aireact/reactloops"
	"github.com/yaklang/yaklang/common/ai/aid/aitool"
	"github.com/yaklang/yaklang/common/aireducer"
	"github.com/yaklang/yaklang/common/chunkmaker"
	"github.com/yaklang/yaklang/common/log"
	"github.com/yaklang/yaklang/common/utils"
	"github.com/yaklang/yaklang/common/utils/memedit"
)

// ScoredRange represents a line range with relevance score
type ScoredRange struct {
	Range     string
	StartLine int
	EndLine   int
	Score     float64 // ç›¸å…³æ€§è¯„åˆ†ï¼Œ0.0-1.0ï¼Œè¶Šé«˜è¶Šç›¸å…³
	Text      string
}

// deduplicateScoredRanges removes overlapping ranges, keeping higher scored ones
func deduplicateScoredRanges(ranges []ScoredRange) []ScoredRange {
	if len(ranges) <= 1 {
		return ranges
	}

	var result []ScoredRange
	for _, r := range ranges {
		overlaps := false
		for _, existing := range result {
			// Check for overlap
			if r.StartLine <= existing.EndLine && r.EndLine >= existing.StartLine {
				overlaps = true
				break
			}
		}
		if !overlaps {
			result = append(result, r)
		}
	}
	return result
}

// compressKnowledgeResultsWithScore compresses knowledge content using AI with 0.0-1.0 scoring
// Reference: invoke_enhance_knowlege_answer.go
func compressKnowledgeResultsWithScore(
	resultStr string,
	userQuery string,
	invoker aicommon.AIInvokeRuntime,
	loop *reactloops.ReActLoop,
	maxBytes int,
) string {
	if len(resultStr) == 0 {
		return resultStr
	}

	// Skip compression for small content (< 5KB)
	if len(resultStr) < 5000 {
		log.Infof("compressKnowledgeResultsWithScore: content too short (%d chars), skip compression", len(resultStr))
		return resultStr
	}

	// Set default maxBytes
	if maxBytes <= 0 {
		maxBytes = 10 * 1024 // 10KB default
	}

	// For large content (>40KB), use chunked processing
	const maxChunkSize = 40 * 1024 // 40KB per chunk
	const overlapLines = 20        // 20 lines overlap
	const maxChunks = 10           // max 10 chunks

	ctx := invoker.GetConfig().GetContext()
	if loop != nil && loop.GetCurrentTask() != nil && !utils.IsNil(loop.GetCurrentTask().GetContext()) {
		ctx = loop.GetCurrentTask().GetContext()
	}

	if len(resultStr) > maxChunkSize {
		log.Infof("compressKnowledgeResultsWithScore: content too large (%d bytes), using chunked processing", len(resultStr))
		return compressKnowledgeResultsChunkedWithScore(ctx, resultStr, userQuery, invoker, loop, maxBytes, maxChunkSize, overlapLines, maxChunks)
	}

	// For smaller content, use single compression
	log.Info("start to directly compress knowledge results with score")
	return compressKnowledgeResultsSingleWithScore(ctx, resultStr, userQuery, invoker, loop, maxBytes)
}

// compressKnowledgeResultsSingleWithScore handles compression for content < 40KB
func compressKnowledgeResultsSingleWithScore(
	ctx context.Context,
	knowledgeContent string,
	userQuery string,
	invoker aicommon.AIInvokeRuntime,
	loop *reactloops.ReActLoop,
	maxBytes int,
) string {
	resultEditor := memedit.NewMemEditor(knowledgeContent)
	dNonce := utils.RandStringBytes(4)

	minLines := 5
	maxLines := 30
	maxRanges := 15

	promptTemplate := `<|USER_QUERY_{{ .nonce }}|>
{{ .userQuery }}
<|USER_QUERY_END_{{ .nonce }}|>

<|KNOWLEDGE_RESULTS_{{ .nonce }}|>
{{ .samples }}
<|KNOWLEDGE_RESULTS_END_{{ .nonce }}|>

<|INSTRUCT_{{ .nonce }}|>
ã€æ™ºèƒ½çŸ¥è¯†ç­›é€‰ä¸æ’åºã€‘

è¯·ä¸¥æ ¼æ ¹æ®ç”¨æˆ·é—®é¢˜ä»ä¸Šè¿°çŸ¥è¯†æœç´¢ç»“æœä¸­æå–æœ€æœ‰ä»·å€¼çš„çŸ¥è¯†ç‰‡æ®µï¼ŒæŒ‰ç›¸å…³æ€§è¯„åˆ†æ’åºï¼š

ã€æ ¸å¿ƒåŸåˆ™ã€‘
- å¿…é¡»ä¸ç”¨æˆ·é—®é¢˜ç›´æ¥ç›¸å…³
- è¿‡æ»¤æ‰æ‰€æœ‰æ— å…³çš„çŸ¥è¯†ç‰‡æ®µ
- ä¼˜å…ˆé€‰æ‹©èƒ½ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„çŸ¥è¯†
- ä¿ç•™å®Œæ•´çš„çŸ¥è¯†æ¡ç›®ï¼Œé¿å…æˆªæ–­

ã€æå–è¦æ±‚ã€‘
1. æœ€å¤šæå– %d ä¸ªçŸ¥è¯†ç‰‡æ®µ
2. æ¯ä¸ªç‰‡æ®µ %d-%d è¡Œï¼Œç¡®ä¿ä¸Šä¸‹æ–‡å®Œæ•´
3. ç»™å‡º 0.0-1.0 çš„ç›¸å…³æ€§è¯„åˆ†ï¼ˆscoreï¼‰ï¼Œè¶Šé«˜è¶Šç›¸å…³
4. ä¸¥æ ¼è¿‡æ»¤ä¸ç”¨æˆ·é—®é¢˜æ— å…³çš„çŸ¥è¯†

ã€è¯„åˆ†æ ‡å‡†ã€‘
ğŸ”¥ é«˜åº¦ç›¸å…³ (0.8-1.0)ï¼š
- ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„çŸ¥è¯†
- åŒ…å«ç”¨æˆ·é—®é¢˜ä¸­æåˆ°çš„å…³é”®å®ä½“/æ¦‚å¿µ
- æä¾›å…·ä½“è§£å†³æ–¹æ¡ˆæˆ–æ“ä½œæ­¥éª¤

â­ è¾ƒé«˜ç›¸å…³ (0.6-0.8)ï¼š
- ä¸ç”¨æˆ·é—®é¢˜é¢†åŸŸç›¸å…³çš„çŸ¥è¯†
- æä¾›èƒŒæ™¯ä¿¡æ¯æˆ–ç›¸å…³æ¦‚å¿µè§£é‡Š
- åŒ…å«ç›¸å…³çš„æŠ€æœ¯ç»†èŠ‚æˆ–é…ç½®

ğŸ“ ä¸€èˆ¬ç›¸å…³ (0.4-0.6)ï¼š
- å¯èƒ½å¯¹ç†è§£é—®é¢˜æœ‰å¸®åŠ©çš„çŸ¥è¯†
- æä¾›è¡¥å……æ€§ä¿¡æ¯
- ç›¸å…³ä½†ä¸ç›´æ¥å›ç­”é—®é¢˜

âŒ å¼±ç›¸å…³ (0.0-0.4)ï¼šä¸è¾“å‡º

è¯·æŒ‰ç›¸å…³æ€§è¯„åˆ†ä»é«˜åˆ°ä½è¾“å‡ºrangesæ•°ç»„ã€‚
<|INSTRUCT_END_{{ .nonce }}|>
`

	materials, err := utils.RenderTemplate(fmt.Sprintf(promptTemplate, maxRanges, minLines, maxLines), map[string]any{
		"nonce":     dNonce,
		"samples":   utils.PrefixLinesWithLineNumbers(knowledgeContent),
		"userQuery": userQuery,
	})

	if err != nil {
		log.Errorf("compressKnowledgeResultsSingleWithScore: template render failed: %v", err)
		return knowledgeContent
	}

	// Create pipe for streaming output
	pr, pw := utils.NewPipe()

	// Get task index for emit
	var taskIndex string
	if loop != nil && loop.GetCurrentTask() != nil {
		taskIndex = loop.GetCurrentTask().GetIndex()
	}

	// Start streaming output with unified nodeId
	if loop != nil {
		loop.GetEmitter().EmitDefaultStreamEvent(
			"knowledge-compress",
			pr,
			taskIndex,
		)
	}

	forgeResult, err := invoker.InvokeLiteForge(
		ctx,
		"knowledge-compress",
		materials,
		[]aitool.ToolOption{
			aitool.WithStringParam(
				"reason",
				aitool.WithParam_Description("è§£é‡Šè¿™ä¹ˆåšçš„è¡Œä¸ºå’Œç†ç”±ï¼Œå¦‚æœä½ è®¤ä¸ºæä¾›çŸ¥è¯†å¢å¼ºææ–™ä¸ç”¨æˆ·éœ€æ±‚æ— å…³ï¼Œè¯´â€œæ— æ³•ä»çŸ¥è¯†åº“ä¸­æŒ‘é€‰å‡ºä¸ç”¨æˆ·éœ€æ±‚ç›¸å…³çš„çŸ¥è¯†ç‰‡æ®µâ€ï¼Œå¦‚æœä½ èƒ½æŒ‘é€‰å‡ºä¸ç”¨æˆ·éœ€æ±‚ç›¸å…³çš„çŸ¥è¯†ç‰‡æ®µï¼Œè¯´â€œå·²æ‰¾åˆ°ä¸ç”¨æˆ·éœ€æ±‚ç›¸å…³çš„çŸ¥è¯†ç‰‡æ®µï¼Œè¯·æŸ¥çœ‹æå–å‡ºçš„çŸ¥è¯†å¢å¼ºå†…å®¹â€ï¼Œæ­¤æ—¶ ranges å­—æ®µå†…å®¹å¿…é¡»ä¸ä¸ºç©º"),
			),
			aitool.WithStructArrayParam(
				"ranges",
				[]aitool.PropertyOption{
					aitool.WithParam_Description("æŒ‰ç›¸å…³æ€§è¯„åˆ†æ’åºçš„çŸ¥è¯†ç‰‡æ®µèŒƒå›´æ•°ç»„"),
				},
				nil,
				aitool.WithStringParam("range", aitool.WithParam_Description("è¡ŒèŒƒå›´ï¼Œæ ¼å¼: start-endï¼Œä¾‹å¦‚ 18-45")),
				aitool.WithNumberParam("score", aitool.WithParam_Description("ç›¸å…³æ€§è¯„åˆ†ï¼Œ0.0-1.0ï¼Œè¶Šé«˜è¶Šç›¸å…³")),
			),
		},
		aicommon.WithGeneralConfigStreamableFieldWithNodeId("knowledge-compress", "reason"),
		// aicommon.WithGeneralConfigStreamableFieldWithNodeId("knowledge-compress", "ranges"),
	)

	reason := forgeResult.GetString("reason")
	if reason == "" {
		log.Info("compress reason: no reason provided, checking prompt or materials")
	} else {
		log.Infof("compress reason: %v", reason)
		pw.WriteString(reason)
		pw.WriteString(" ")
	}

	if err != nil {
		log.Errorf("compressKnowledgeResultsSingleWithScore: LiteForge failed: %v", err)
		pw.Close()
		return knowledgeContent
	}

	if forgeResult == nil {
		log.Warnf("compressKnowledgeResultsSingleWithScore: forge result is nil")
		pw.Close()
		return knowledgeContent
	}
	forgeResult.WaitStream(ctx)

	rangeItems := forgeResult.GetInvokeParamsArray("ranges")
	if len(rangeItems) == 0 {
		results := forgeResult.GetAnyToString("ranges")
		if results != "" {
			log.Infof("compressKnowledgeResultsSingleWithScore: ranges extracted: %v", results)
		} else {
			log.Errorf("format error or no ranges provided, check #ranges: %#v", results)
		}
		log.Warnf("compressKnowledgeResultsSingleWithScore: no ranges extracted")
		pw.Close()

		if reason != "" {
			return ""
		}
		return knowledgeContent
	}

	var scoredRanges []ScoredRange

	for _, item := range rangeItems {
		rangeStr := item.GetString("range")
		score := item.GetFloat("score")

		if rangeStr == "" {
			continue
		}

		// Filter out low score items (< 0.4)
		if score < 0.4 {
			continue
		}

		parts := strings.Split(rangeStr, "-")
		if len(parts) != 2 {
			log.Warnf("compressKnowledgeResultsSingleWithScore: invalid range format: %s", rangeStr)
			continue
		}

		startLine, err1 := strconv.Atoi(strings.TrimSpace(parts[0]))
		endLine, err2 := strconv.Atoi(strings.TrimSpace(parts[1]))

		if err1 != nil || err2 != nil {
			log.Errorf("compressKnowledgeResultsSingleWithScore: parse range failed: %s, errors: %v, %v", rangeStr, err1, err2)
			continue
		}

		if startLine <= 0 || endLine < startLine {
			log.Warnf("compressKnowledgeResultsSingleWithScore: invalid range values: %s (start=%d, end=%d)", rangeStr, startLine, endLine)
			continue
		}

		text := resultEditor.GetTextFromPositionInt(startLine, 1, endLine, 1)
		if text == "" {
			log.Warnf("compressKnowledgeResultsSingleWithScore: empty text for range: %s", rangeStr)
			continue
		}

		// Write to stream: ç‰‡æ®µï¼š[Score: 0.x] startLine-endLine
		pw.WriteString(fmt.Sprintf("ç‰‡æ®µï¼š[Score: %.2f] %d-%d\n", score, startLine, endLine))

		scoredRanges = append(scoredRanges, ScoredRange{
			Range:     rangeStr,
			StartLine: startLine,
			EndLine:   endLine,
			Score:     score,
			Text:      text,
		})
	}

	pw.Close()

	if len(scoredRanges) == 0 {
		log.Warnf("compressKnowledgeResultsSingleWithScore: no valid ranges extracted")
		return knowledgeContent
	}

	// Sort by score descending (higher score = more relevant)
	sort.Slice(scoredRanges, func(i, j int) bool {
		return scoredRanges[i].Score > scoredRanges[j].Score
	})

	var result strings.Builder
	result.WriteString("ã€AI æ™ºèƒ½ç­›é€‰ã€‘æŒ‰ç›¸å…³æ€§è¯„åˆ†æ’åºçš„çŸ¥è¯†ç‰‡æ®µï¼š\n\n")

	currentBytes := 0
	for i, item := range scoredRanges {
		if currentBytes+len(item.Text) > maxBytes {
			log.Infof("compressKnowledgeResultsSingleWithScore: reached %d bytes limit, stopping at %d ranges", maxBytes, i)
			break
		}
		result.WriteString(fmt.Sprintf("=== [%d] Score: %.2f ===\n", i+1, item.Score))
		result.WriteString(item.Text)
		result.WriteString("\n\n")
		currentBytes += len(item.Text)
	}

	finalResult := result.String()

	log.Infof("compressKnowledgeResultsSingleWithScore: compressed from %d chars to %d chars (%d bytes), %d ranges extracted",
		len(knowledgeContent), len(finalResult), currentBytes, len(scoredRanges))

	return finalResult
}

// compressKnowledgeResultsChunkedWithScore handles compression for content > 40KB using chunked processing
// Refactored to use aireducer for cleaner chunking logic
func compressKnowledgeResultsChunkedWithScore(
	ctx context.Context,
	knowledgeContent string,
	userQuery string,
	invoker aicommon.AIInvokeRuntime,
	loop *reactloops.ReActLoop,
	maxBytes int,
	chunkSize int,
	overlapLines int,
	maxChunks int,
) string {
	// Calculate lines per chunk based on average line length
	lines := strings.Split(knowledgeContent, "\n")
	totalLines := len(lines)
	avgLineLen := len(knowledgeContent)/totalLines + 10
	linesPerChunk := chunkSize / avgLineLen
	if linesPerChunk < 50 {
		linesPerChunk = 50
	}

	log.Infof("compressKnowledgeResultsChunkedWithScore: processing %d bytes, %d lines, linesPerChunk=%d, maxChunks=%d",
		len(knowledgeContent), totalLines, linesPerChunk, maxChunks)

	// Use aireducer for chunking
	var allScoredRanges []ScoredRange
	var mu sync.Mutex
	chunkIndex := 0

	reducer, err := aireducer.NewReducerFromString(
		knowledgeContent,
		aireducer.WithContext(ctx),
		aireducer.WithLines(linesPerChunk),        // æŒ‰è¡Œæ•°åˆ†å—
		aireducer.WithEnableLineNumber(true),      // è‡ªåŠ¨æ·»åŠ è¡Œå·ï¼Œæ ¼å¼ï¼šN | content
		aireducer.WithChunkSize(int64(chunkSize)), // å—å¤§å°ç¡¬é™åˆ¶
		aireducer.WithReducerCallback(func(config *aireducer.Config, memory *aid.PromptContextProvider, chunk chunkmaker.Chunk) error {
			if chunkIndex >= maxChunks {
				return nil // è¶…å‡ºæœ€å¤§å—æ•°ï¼Œè·³è¿‡
			}
			currentChunkIndex := chunkIndex
			chunkIndex++

			chunkData := string(chunk.Data())
			if chunkData == "" {
				return nil
			}

			// è·å–å½“å‰ chunk çš„è¡ŒèŒƒå›´ï¼ˆä» chunk æ•°æ®ä¸­è§£æç¬¬ä¸€è¡Œå’Œæœ€åä¸€è¡Œçš„è¡Œå·ï¼‰
			chunkStartLine, chunkEndLine := extractLineRangeFromChunk(chunkData)

			log.Infof("compressKnowledgeResultsChunkedWithScore: processing chunk %d (lines %d-%d, size=%d bytes)",
				currentChunkIndex+1, chunkStartLine, chunkEndLine, len(chunkData))

			// å¯¹å½“å‰ chunk è¿›è¡Œ AI ç­›é€‰
			chunkRanges := compressKnowledgeChunkWithScore(
				ctx, chunkData, userQuery, invoker, loop, chunkStartLine, chunkEndLine)

			if len(chunkRanges) > 0 {
				mu.Lock()
				allScoredRanges = append(allScoredRanges, chunkRanges...)
				mu.Unlock()
				log.Infof("compressKnowledgeResultsChunkedWithScore: chunk %d extracted %d ranges", currentChunkIndex+1, len(chunkRanges))
			}

			return nil
		}),
	)

	if err != nil {
		log.Errorf("compressKnowledgeResultsChunkedWithScore: failed to create reducer: %v", err)
		// é™çº§åˆ°åŸå§‹å†…å®¹
		if len(knowledgeContent) > 50000 {
			return knowledgeContent[:50000] + "\n\n[... å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­ ...]"
		}
		return knowledgeContent
	}

	if err := reducer.Run(); err != nil {
		log.Errorf("compressKnowledgeResultsChunkedWithScore: reducer run failed: %v", err)
		if len(knowledgeContent) > 50000 {
			return knowledgeContent[:50000] + "\n\n[... å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­ ...]"
		}
		return knowledgeContent
	}

	log.Infof("compressKnowledgeResultsChunkedWithScore: processed %d chunks total", chunkIndex)

	if len(allScoredRanges) == 0 {
		log.Warnf("compressKnowledgeResultsChunkedWithScore: no valid ranges extracted from any chunk")
		if len(knowledgeContent) > 50000 {
			return knowledgeContent[:50000] + "\n\n[... å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­ ...]"
		}
		return knowledgeContent
	}

	// Sort by score descending
	sort.Slice(allScoredRanges, func(i, j int) bool {
		return allScoredRanges[i].Score > allScoredRanges[j].Score
	})

	// Deduplicate
	allScoredRanges = deduplicateScoredRanges(allScoredRanges)

	// Extract final results
	resultEditor := memedit.NewMemEditor(knowledgeContent)
	var result strings.Builder
	result.WriteString(fmt.Sprintf("ã€AI æ™ºèƒ½ç­›é€‰ã€‘ä» %d å­—èŠ‚å†…å®¹ä¸­æå–çš„ %d ä¸ªæœ€ç›¸å…³çŸ¥è¯†ç‰‡æ®µï¼š\n\n", len(knowledgeContent), len(allScoredRanges)))

	totalExtractedBytes := 0

	for i, item := range allScoredRanges {
		text := resultEditor.GetTextFromPositionInt(item.StartLine, 1, item.EndLine, 1)
		if text == "" {
			continue
		}

		textBytes := len(text)
		if totalExtractedBytes+textBytes > maxBytes {
			result.WriteString(fmt.Sprintf("\n[... å·²è¾¾åˆ° %d å­—èŠ‚é™åˆ¶ï¼Œå‰©ä½™ %d ä¸ªç‰‡æ®µæœªå±•ç¤º ...]\n", maxBytes, len(allScoredRanges)-i))
			break
		}

		result.WriteString(fmt.Sprintf("=== [%d] Score: %.2f (è¡Œ %d-%d) ===\n", i+1, item.Score, item.StartLine, item.EndLine))
		result.WriteString(text)
		result.WriteString("\n\n")

		totalExtractedBytes += textBytes
	}

	finalResult := result.String()

	log.Infof("compressKnowledgeResultsChunkedWithScore: compressed from %d chars to %d chars (%d bytes), %d ranges",
		len(knowledgeContent), len(finalResult), totalExtractedBytes, len(allScoredRanges))

	return finalResult
}

// extractLineRangeFromChunk extracts the first and last line numbers from a chunk
// The chunk content has line number format: "N | content"
func extractLineRangeFromChunk(chunkData string) (startLine, endLine int) {
	lines := strings.Split(chunkData, "\n")
	startLine = 1
	endLine = 1

	// Parse first line
	if len(lines) > 0 {
		firstLine := strings.TrimSpace(lines[0])
		if idx := strings.Index(firstLine, " |"); idx > 0 {
			if num, err := strconv.Atoi(strings.TrimSpace(firstLine[:idx])); err == nil && num > 0 {
				startLine = num
			}
		}
	}

	// Parse last non-empty line
	for i := len(lines) - 1; i >= 0; i-- {
		line := strings.TrimSpace(lines[i])
		if line == "" {
			continue
		}
		if idx := strings.Index(line, " |"); idx > 0 {
			if num, err := strconv.Atoi(strings.TrimSpace(line[:idx])); err == nil && num > 0 {
				endLine = num
				break
			}
		}
	}

	if endLine < startLine {
		endLine = startLine
	}

	return startLine, endLine
}

// compressKnowledgeChunkWithScore processes a single chunk for AI filtering
func compressKnowledgeChunkWithScore(
	ctx context.Context,
	chunkContentWithLineNum string,
	userQuery string,
	invoker aicommon.AIInvokeRuntime,
	loop *reactloops.ReActLoop,
	chunkStartLine int,
	chunkEndLine int,
) []ScoredRange {
	dNonce := utils.RandStringBytes(4)
	minLines := 3
	maxLines := 20
	maxRanges := 8

	promptTemplate := `<|USER_QUERY_{{ .nonce }}|>
{{ .userQuery }}
<|USER_QUERY_END_{{ .nonce }}|>

<|KNOWLEDGE_CHUNK_{{ .nonce }}|>
å½“å‰å¤„ç†åˆ†ç‰‡: è¡Œ {{ .chunkStart }} - {{ .chunkEnd }}
{{ .samples }}
<|KNOWLEDGE_CHUNK_END_{{ .nonce }}|>

<|INSTRUCT_{{ .nonce }}|>
ã€æ™ºèƒ½çŸ¥è¯†ç­›é€‰ã€‘è¯·ä»å½“å‰åˆ†ç‰‡ä¸­æå–ä¸ç”¨æˆ·é—®é¢˜æœ€ç›¸å…³çš„çŸ¥è¯†ç‰‡æ®µã€‚

ã€æ ¸å¿ƒä»»åŠ¡ã€‘
ä»ä¸Šè¿°å¸¦è¡Œå·çš„çŸ¥è¯†å†…å®¹ä¸­ï¼Œæå–ä¸ç”¨æˆ·é—®é¢˜ç›´æ¥ç›¸å…³çš„ç‰‡æ®µã€‚

ã€è¾“å‡ºè¦æ±‚ã€‘
1. æœ€å¤šæå– %d ä¸ªç‰‡æ®µ
2. æ¯ä¸ªç‰‡æ®µ %d-%d è¡Œ
3. ä½¿ç”¨åŸå§‹è¡Œå·ï¼ˆç¬¬ä¸€åˆ—æ•°å­—ï¼‰
4. ç»™å‡º 0.0-1.0 çš„ç›¸å…³æ€§è¯„åˆ†ï¼ˆscoreï¼‰ï¼Œè¶Šé«˜è¶Šç›¸å…³

ã€è¯„åˆ†æ ‡å‡†ã€‘
- 0.8-1.0: ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„æ ¸å¿ƒå†…å®¹
- 0.6-0.8: ç›¸å…³èƒŒæ™¯/æŠ€æœ¯ç»†èŠ‚
- 0.4-0.6: è¡¥å……æ€§ä¿¡æ¯
- 0.0-0.4: å¼±ç›¸å…³æˆ–æ— å…³å†…å®¹ï¼ˆä¸è¾“å‡ºï¼‰

è¯·è¾“å‡º ranges æ•°ç»„ã€‚
<|INSTRUCT_END_{{ .nonce }}|>
`

	materials, err := utils.RenderTemplate(fmt.Sprintf(promptTemplate, maxRanges, minLines, maxLines), map[string]any{
		"nonce":      dNonce,
		"samples":    chunkContentWithLineNum,
		"userQuery":  userQuery,
		"chunkStart": chunkStartLine,
		"chunkEnd":   chunkEndLine,
	})

	if err != nil {
		log.Errorf("compressKnowledgeChunkWithScore: template render failed: %v", err)
		return nil
	}

	// Create pipe for streaming output
	pr, pw := utils.NewPipe()

	// Get task index for emit
	var taskIndex string
	if loop != nil && loop.GetCurrentTask() != nil {
		taskIndex = loop.GetCurrentTask().GetIndex()
	}

	// Start streaming output with unified nodeId
	if loop != nil {
		loop.GetEmitter().EmitDefaultStreamEvent(
			"knowledge-compress",
			pr,
			taskIndex,
		)
	}

	forgeResult, err := invoker.InvokeLiteForge(
		ctx,
		"knowledge-compress",
		materials,
		[]aitool.ToolOption{
			aitool.WithStructArrayParam(
				"ranges",
				[]aitool.PropertyOption{
					aitool.WithParam_Description("æŒ‰ç›¸å…³æ€§è¯„åˆ†æ’åºçš„çŸ¥è¯†ç‰‡æ®µèŒƒå›´æ•°ç»„"),
				},
				nil,
				aitool.WithStringParam("range", aitool.WithParam_Description("åŸå§‹è¡ŒèŒƒå›´ï¼Œæ ¼å¼: start-end")),
				aitool.WithNumberParam("score", aitool.WithParam_Description("ç›¸å…³æ€§è¯„åˆ†ï¼Œ0.0-1.0ï¼Œè¶Šé«˜è¶Šç›¸å…³")),
			),
		},
	)

	if err != nil {
		log.Errorf("compressKnowledgeChunkWithScore: LiteForge failed: %v", err)
		pw.Close()
		return nil
	}

	if forgeResult == nil {
		pw.Close()
		return nil
	}

	rangeItems := forgeResult.GetInvokeParamsArray("ranges")
	var results []ScoredRange

	for _, item := range rangeItems {
		rangeStr := item.GetString("range")
		score := item.GetFloat("score")

		if rangeStr == "" {
			continue
		}

		// Filter out low score items (< 0.4)
		if score < 0.4 {
			continue
		}

		parts := strings.Split(rangeStr, "-")
		if len(parts) != 2 {
			continue
		}

		startLine, err1 := strconv.Atoi(strings.TrimSpace(parts[0]))
		endLine, err2 := strconv.Atoi(strings.TrimSpace(parts[1]))

		if err1 != nil || err2 != nil || startLine <= 0 || endLine < startLine {
			continue
		}

		// Write to stream
		pw.WriteString(fmt.Sprintf("ç‰‡æ®µï¼š[Score: %.2f] %d-%d\n", score, startLine, endLine))

		results = append(results, ScoredRange{
			Range:     rangeStr,
			StartLine: startLine,
			EndLine:   endLine,
			Score:     score,
		})
	}

	pw.Close()
	return results
}
