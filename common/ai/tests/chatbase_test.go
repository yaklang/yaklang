// Package tests åŒ…å«AIèŠå¤©åŠŸèƒ½çš„é›†æˆæµ‹è¯•
// ä¸»è¦æµ‹è¯•æµå¼å’Œéæµå¼èŠå¤©å“åº”çš„å¤„ç†é€»è¾‘
package tests

import (
	"fmt"
	"io"
	"strings"
	"sync"
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/yaklang/yaklang/common/ai/aispec"
	"github.com/yaklang/yaklang/common/utils"
	"github.com/yaklang/yaklang/common/utils/lowhttp/poc"
)

// mockAiRsp æ¨¡æ‹Ÿçš„éæµå¼AIå“åº”æ•°æ®
// è¿™æ˜¯æ ‡å‡†çš„OpenAI API JSONå“åº”æ ¼å¼ï¼ŒåŒ…å«ï¼š
// - id: è¯·æ±‚å”¯ä¸€æ ‡è¯†ç¬¦
// - object: å“åº”å¯¹è±¡ç±»å‹ "chat.completion"
// - model: ä½¿ç”¨çš„AIæ¨¡å‹åç§°
// - choices: å“åº”é€‰æ‹©æ•°ç»„ï¼ŒåŒ…å«åŠ©æ‰‹çš„å›å¤å†…å®¹
// - usage: tokenä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯
const mockAiRsp = `HTTP/1.1 200 OK
Connection: close
Content-Type: application/json; charset=utf-8

{
  "id": "01983a7496e24930e8de7952fd33c19c",
  "object": "chat.completion",
  "created": 1753327376,
  "model": "deepseek-ai/DeepSeek-V3",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "ä½ å¥½ï¼ğŸ˜Š å¾ˆé«˜å…´è§åˆ°ä½ ï½æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": { "prompt_tokens": 4, "completion_tokens": 15, "total_tokens": 19 },
  "system_fingerprint": ""
}
`

// mockAiStreamRsp æ¨¡æ‹Ÿçš„æµå¼AIå“åº”æ•°æ®
// è¿™æ˜¯Server-Sent Events (SSE) æ ¼å¼çš„æµå¼å“åº”ï¼ŒåŒ…å«ï¼š
// - Content-Type: text/event-stream è¡¨ç¤ºè¿™æ˜¯æµå¼æ•°æ®
// - data: å‰ç¼€çš„JSON chunkï¼Œæ¯ä¸ªchunkåŒ…å«éƒ¨åˆ†å“åº”å†…å®¹
// - delta: å¢é‡å†…å®¹ï¼ŒåŒ…å«contentå’Œreasoning_contentå­—æ®µ
// - [DONE]: æµå¼å“åº”ç»“æŸæ ‡è¯†ç¬¦
const mockAiStreamRsp = `HTTP/1.1 200 OK
Connection: close
Content-Type: text/event-stream

data: {"id":"01983a922eff7e1cee0f9a1cdbbd74f4","object":"chat.completion.chunk","created":1753329315,"model":"deepseek-ai/DeepSeek-V3","choices":[{"index":0,"delta":{"content":"","reasoning_content":null,"role":"assistant"},"finish_reason":null}],"system_fingerprint":"","usage":{"prompt_tokens":4,"completion_tokens":0,"total_tokens":4}}

data: {"id":"01983a922eff7e1cee0f9a1cdbbd74f4","object":"chat.completion.chunk","created":1753329315,"model":"deepseek-ai/DeepSeek-V3","choices":[{"index":0,"delta":{"content":"ä½ å¥½","reasoning_content":null},"finish_reason":null}],"system_fingerprint":"","usage":{"prompt_tokens":4,"completion_tokens":1,"total_tokens":5}}

data: [DONE]
`

// mockAiReasoningRsp æ¨¡æ‹ŸåŒ…å«æ¨ç†å†…å®¹çš„AIå“åº”
// ç”¨äºæµ‹è¯•æ¨ç†å†…å®¹(reasoning_content)çš„å¤„ç†é€»è¾‘
const mockAiReasoningRsp = `HTTP/1.1 200 OK
Connection: close
Content-Type: application/json; charset=utf-8

{
  "id": "reasoning-test-123",
  "object": "chat.completion",
  "created": 1753327376,
  "model": "deepseek-ai/DeepSeek-V3",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "åŸºäºæˆ‘çš„åˆ†æï¼Œç­”æ¡ˆæ˜¯42ã€‚",
        "reasoning_content": "ç”¨æˆ·è¯¢é—®äº†ç”Ÿå‘½ã€å®‡å®™å’Œä¸€åˆ‡çš„ç»ˆæç­”æ¡ˆã€‚æ ¹æ®ã€Šé“¶æ²³ç³»æ¼«æ¸¸æŒ‡å—ã€‹ï¼Œè¿™ä¸ªç­”æ¡ˆæ˜¯42ã€‚"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": { "prompt_tokens": 10, "completion_tokens": 20, "total_tokens": 30 }
}
`

// TestNonStreamChat æµ‹è¯•éæµå¼èŠå¤©åŠŸèƒ½
// éªŒè¯ï¼š
// 1. éæµå¼å“åº”çš„æ­£ç¡®è§£æ
// 2. message.contentå­—æ®µçš„æå–
// 3. æœ€ç»ˆè¿”å›å†…å®¹çš„æ­£ç¡®æ€§
func TestNonStreamChat(t *testing.T) {
	// åˆ›å»ºæ¨¡æ‹ŸHTTPæœåŠ¡å™¨ï¼Œè¿”å›é¢„å®šä¹‰çš„éæµå¼å“åº”
	host, port := utils.DebugMockHTTP([]byte(mockAiRsp))

	// è°ƒç”¨ChatBaseè¿›è¡Œéæµå¼èŠå¤©
	// ä¸è®¾ç½®StreamHandlerï¼Œé»˜è®¤ä¸ºéæµå¼å¤„ç†
	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o-mini",
		"hello",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),        // ä½¿ç”¨æ¨¡æ‹ŸæœåŠ¡å™¨çš„ä¸»æœº
				poc.WithPort(port),        // ä½¿ç”¨æ¨¡æ‹ŸæœåŠ¡å™¨çš„ç«¯å£
				poc.WithForceHTTPS(false), // ç¦ç”¨HTTPS
				poc.WithTimeout(3),        // è®¾ç½®3ç§’è¶…æ—¶
			}, nil
		}))

	// æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯å‘ç”Ÿ
	if err != nil {
		t.Fatal(err)
	}

	// éªŒè¯è¿”å›çš„å†…å®¹æ˜¯å¦ç¬¦åˆé¢„æœŸ
	// åº”è¯¥ä»JSONå“åº”çš„choices[0].message.contentå­—æ®µä¸­æå–å†…å®¹
	assert.Equal(t, "ä½ å¥½ï¼ğŸ˜Š å¾ˆé«˜å…´è§åˆ°ä½ ï½æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ", res)
}

// TestStreamChat æµ‹è¯•æµå¼èŠå¤©åŠŸèƒ½
// éªŒè¯ï¼š
// 1. æµå¼å“åº”çš„æ­£ç¡®è§£æ
// 2. delta.contentå­—æ®µçš„é€æ­¥ç´¯ç§¯
// 3. æµå¼å¤„ç†å™¨çš„æ­£ç¡®è°ƒç”¨
func TestStreamChat(t *testing.T) {
	// åˆ›å»ºæ¨¡æ‹ŸHTTPæœåŠ¡å™¨ï¼Œè¿”å›é¢„å®šä¹‰çš„æµå¼å“åº”
	host, port := utils.DebugMockHTTP([]byte(mockAiStreamRsp))

	// ç”¨äºæ•è·æµå¼æ•°æ®çš„å˜é‡
	var streamContent strings.Builder

	// è°ƒç”¨ChatBaseè¿›è¡Œæµå¼èŠå¤©
	// è®¾ç½®StreamHandlerå¯ç”¨æµå¼å¤„ç†
	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o-mini",
		"hello",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),        // ä½¿ç”¨æ¨¡æ‹ŸæœåŠ¡å™¨çš„ä¸»æœº
				poc.WithPort(port),        // ä½¿ç”¨æ¨¡æ‹ŸæœåŠ¡å™¨çš„ç«¯å£
				poc.WithForceHTTPS(false), // ç¦ç”¨HTTPS
				poc.WithTimeout(3),        // è®¾ç½®3ç§’è¶…æ—¶
			}, nil
		}),
		// æµå¼å¤„ç†å™¨ï¼šè¯»å–å¹¶ä¿å­˜æµå¼æ•°æ®
		aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
			data, _ := io.ReadAll(reader)
			streamContent.Write(data)
		}))

	// æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯å‘ç”Ÿ
	if err != nil {
		t.Fatal(err)
	}

	// éªŒè¯è¿”å›çš„å†…å®¹æ˜¯å¦ç¬¦åˆé¢„æœŸ
	// æµå¼å“åº”åº”è¯¥ç´¯ç§¯æ‰€æœ‰delta.contentçš„å†…å®¹
	assert.Equal(t, "ä½ å¥½", res)

	// éªŒè¯æµå¼å¤„ç†å™¨æ˜¯å¦è¢«æ­£ç¡®è°ƒç”¨å¹¶æ¥æ”¶åˆ°æ•°æ®
	assert.NotEmpty(t, streamContent.String(), "æµå¼å¤„ç†å™¨åº”è¯¥æ¥æ”¶åˆ°æ•°æ®")
}

// TestNonStreamChatWithReasoning æµ‹è¯•åŒ…å«æ¨ç†å†…å®¹çš„éæµå¼èŠå¤©
// éªŒè¯ï¼š
// 1. reasoning_contentå­—æ®µçš„æ­£ç¡®å¤„ç†
// 2. æ¨ç†å†…å®¹å’Œæ­£å¸¸å†…å®¹çš„åˆ†ç¦»
func TestNonStreamChatWithReasoning(t *testing.T) {
	// åˆ›å»ºæ¨¡æ‹ŸHTTPæœåŠ¡å™¨ï¼Œè¿”å›åŒ…å«æ¨ç†å†…å®¹çš„å“åº”
	host, port := utils.DebugMockHTTP([]byte(mockAiReasoningRsp))

	// ç”¨äºæ•è·æ¨ç†å†…å®¹çš„å˜é‡
	var reasonContent strings.Builder

	// è°ƒç”¨ChatBaseï¼ŒåŒæ—¶å¤„ç†æ¨ç†å†…å®¹
	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o-mini",
		"ä»€ä¹ˆæ˜¯ç”Ÿå‘½ã€å®‡å®™å’Œä¸€åˆ‡çš„ç»ˆæç­”æ¡ˆï¼Ÿ",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(3),
			}, nil
		}),
		// æ¨ç†å†…å®¹å¤„ç†å™¨ï¼šä¸“é—¨å¤„ç†reasoning_content
		aispec.WithChatBase_ReasonStreamHandler(func(reader io.Reader) {
			data, _ := io.ReadAll(reader)
			reasonContent.Write(data)
		}))

	// æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯å‘ç”Ÿ
	if err != nil {
		t.Fatal(err)
	}

	// éªŒè¯æ­£å¸¸å›å¤å†…å®¹
	assert.Equal(t, "åŸºäºæˆ‘çš„åˆ†æï¼Œç­”æ¡ˆæ˜¯42ã€‚", res)

	// éªŒè¯æ¨ç†å†…å®¹æ˜¯å¦è¢«æ­£ç¡®å¤„ç†
	expectedReasoning := "ç”¨æˆ·è¯¢é—®äº†ç”Ÿå‘½ã€å®‡å®™å’Œä¸€åˆ‡çš„ç»ˆæç­”æ¡ˆã€‚æ ¹æ®ã€Šé“¶æ²³ç³»æ¼«æ¸¸æŒ‡å—ã€‹ï¼Œè¿™ä¸ªç­”æ¡ˆæ˜¯42ã€‚"
	assert.Contains(t, reasonContent.String(), expectedReasoning, "æ¨ç†å†…å®¹åº”è¯¥è¢«æ­£ç¡®æå–")
}

// TestChatBaseErrorHandling æµ‹è¯•é”™è¯¯å¤„ç†æœºåˆ¶
// éªŒè¯ï¼š
// 1. HTTPé”™è¯¯çš„æ­£ç¡®å¤„ç†
// 2. é”™è¯¯å›è°ƒå‡½æ•°çš„è°ƒç”¨
func TestChatBaseErrorHandling(t *testing.T) {
	// ç”¨äºæ•è·é”™è¯¯çš„å˜é‡
	var capturedError error

	// è°ƒç”¨ChatBaseï¼Œä½¿ç”¨ä¸å­˜åœ¨çš„ç«¯å£æ¥è§¦å‘é”™è¯¯
	// ä½¿ç”¨ 127.0.0.1 å’Œéšæœºæ— æ•ˆç«¯å£ï¼Œé¿å…å¤–éƒ¨ç½‘ç»œè¿æ¥
	invalidPort := utils.GetRandomAvailableTCPPort() + 10000 // ä½¿ç”¨ä¸€ä¸ªå¾ˆå¯èƒ½ä¸å­˜åœ¨çš„ç«¯å£
	_, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o-mini",
		"hello",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithTimeout(1),        // çŸ­è¶…æ—¶ç¡®ä¿å¿«é€Ÿå¤±è´¥
				poc.WithHost("127.0.0.1"), // ä½¿ç”¨æœ¬åœ°åœ°å€
				poc.WithPort(invalidPort), // ä¸å­˜åœ¨çš„æœ¬åœ°ç«¯å£
				poc.WithForceHTTPS(false),
			}, nil
		}),
		// é”™è¯¯å¤„ç†å™¨ï¼šæ•è·HTTPé”™è¯¯
		aispec.WithChatBase_ErrHandler(func(httpErr error) {
			capturedError = httpErr
		}))

	// åº”è¯¥è¿”å›é”™è¯¯
	assert.Error(t, err, "åº”è¯¥è¿”å›è¿æ¥é”™è¯¯")

	// é”™è¯¯å¤„ç†å™¨åº”è¯¥è¢«è°ƒç”¨
	assert.Error(t, capturedError, "é”™è¯¯å¤„ç†å™¨åº”è¯¥æ•è·åˆ°HTTPé”™è¯¯")
}

// ==================== ChatBase ç¨³å®šæ€§æµ‹è¯• ====================

// mockAiStreamIncompleteRsp æ¨¡æ‹Ÿä¸å®Œæ•´çš„æµå¼å“åº”
// æµ‹è¯•æµå¼å¤„ç†çš„å®¹é”™èƒ½åŠ›
const mockAiStreamIncompleteRsp = `HTTP/1.1 200 OK
Connection: close
Content-Type: text/event-stream

data: {"id":"test-stream-1","object":"chat.completion.chunk","created":1753329315,"model":"deepseek-ai/DeepSeek-V3","choices":[{"index":0,"delta":{"content":"Hello","reasoning_content":"Thinking about greeting","role":"assistant"},"finish_reason":null}],"system_fingerprint":"","usage":{"prompt_tokens":4,"completion_tokens":1,"total_tokens":5}}

data: {"id":"test-stream-2","object":"chat.completion.chunk","created":1753329316,"model":"deepseek-ai/DeepSeek-V3","choices":[{"index":0,"delta":{"content":" World","reasoning_content":"Continuing the greeting"},"finish_reason":null}],"system_fingerprint":"","usage":{"prompt_tokens":4,"completion_tokens":2,"total_tokens":6}}

`

// mockAiStreamMalformedRsp æ¨¡æ‹Ÿæ ¼å¼é”™è¯¯çš„æµå¼å“åº”
const mockAiStreamMalformedRsp = `HTTP/1.1 200 OK
Connection: close
Content-Type: text/event-stream

data: {"id":"malformed-1","object":"chat.completion.chunk","choices":[{"index":0,"delta":{"content":"Valid start"}]

data: {invalid json content here

data: {"id":"malformed-2","object":"chat.completion.chunk","choices":[{"index":0,"delta":{"content":" but continues"}]}

data: [DONE]
`

// mockAiLongStreamRsp æ¨¡æ‹Ÿé•¿æ—¶é—´æµå¼å“åº”
// ç”¨äºæµ‹è¯•è¶…æ—¶å’Œå¹¶å‘å¤„ç†
const mockAiLongStreamRsp = `HTTP/1.1 200 OK
Connection: close
Content-Type: text/event-stream

data: {"id":"long-1","object":"chat.completion.chunk","choices":[{"index":0,"delta":{"content":"This","reasoning_content":"Starting a long response"}]}

data: {"id":"long-2","object":"chat.completion.chunk","choices":[{"index":0,"delta":{"content":" is","reasoning_content":"Continuing the long response"}]}

data: {"id":"long-3","object":"chat.completion.chunk","choices":[{"index":0,"delta":{"content":" a","reasoning_content":"Still going"}]}

data: {"id":"long-4","object":"chat.completion.chunk","choices":[{"index":0,"delta":{"content":" very","reasoning_content":"More content coming"}]}

data: {"id":"long-5","object":"chat.completion.chunk","choices":[{"index":0,"delta":{"content":" long","reasoning_content":"Almost there"}]}

data: {"id":"long-6","object":"chat.completion.chunk","choices":[{"index":0,"delta":{"content":" response","reasoning_content":"Finally finishing"}]}

data: [DONE]
`

// TestChatBaseStability_StreamAndReasonHandlers æµ‹è¯•æµå¤„ç†å™¨çš„ç¨³å®šæ€§
// éªŒè¯ StreamHandler å’Œ ReasonStreamHandler çš„å„ç§ç»„åˆ
func TestChatBaseStability_StreamAndReasonHandlers(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiStreamRsp))

	t.Run("BothHandlersPresent", func(t *testing.T) {
		var streamContent strings.Builder
		var reasonContent strings.Builder
		var streamCallCount, reasonCallCount int

		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"hello",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
				streamCallCount++
				data, _ := io.ReadAll(reader)
				streamContent.Write(data)
			}),
			aispec.WithChatBase_ReasonStreamHandler(func(reader io.Reader) {
				reasonCallCount++
				data, _ := io.ReadAll(reader)
				reasonContent.Write(data)
			}))

		assert.NoError(t, err, "Both handlers should work without error")
		assert.Equal(t, "ä½ å¥½", res, "Response content should be correct")
		assert.Equal(t, 1, streamCallCount, "Stream handler should be called once")
		assert.Equal(t, 1, reasonCallCount, "Reason handler should be called once")
		assert.NotEmpty(t, streamContent.String(), "Stream handler should receive data")
	})

	t.Run("OnlyStreamHandler", func(t *testing.T) {
		var streamContent strings.Builder

		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"hello",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
				data, _ := io.ReadAll(reader)
				streamContent.Write(data)
			}))

		assert.NoError(t, err, "Only stream handler should work")
		assert.Equal(t, "ä½ å¥½", res)
		assert.NotEmpty(t, streamContent.String(), "Stream handler should receive data")
	})

	t.Run("OnlyReasonHandler", func(t *testing.T) {
		var reasonContent strings.Builder

		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"hello",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_ReasonStreamHandler(func(reader io.Reader) {
				data, _ := io.ReadAll(reader)
				reasonContent.Write(data)
			}))

		assert.NoError(t, err, "Only reason handler should work")
		assert.Equal(t, "ä½ å¥½", res)
	})

	t.Run("NoHandlers", func(t *testing.T) {
		// ä½¿ç”¨æµå¼çš„mockå“åº”ï¼Œä½†ä¸è®¾ç½®ä»»ä½•å¤„ç†å™¨
		host, port := utils.DebugMockHTTP([]byte(mockAiStreamRsp))
		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"hello",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}))

		assert.NoError(t, err, "No handlers should still work")
		// æ²¡æœ‰å¤„ç†å™¨çš„æƒ…å†µä¸‹ï¼Œä»åº”è¯¥èƒ½è·å–å“åº”å†…å®¹
		assert.Equal(t, "ä½ å¥½", res)
	})
}

// TestChatBaseStability_ConcurrentRequests æµ‹è¯•å¹¶å‘æµå¼è¯·æ±‚çš„ç¨³å®šæ€§
func TestChatBaseStability_ConcurrentRequests(t *testing.T) {
	// ä½¿ç”¨æµå¼å“åº”è¿›è¡Œå¹¶å‘æµ‹è¯•ï¼Œå› ä¸ºæµå¼å¤„ç†æ›´ç¨³å®š
	host, port := utils.DebugMockHTTP([]byte(mockAiStreamRsp))

	const numGoroutines = 5 // å‡å°‘å¹¶å‘æ•°é‡é¿å…èµ„æºç«äº‰
	var wg sync.WaitGroup
	var mutex sync.Mutex
	var results []string
	var errs []error

	// å¯åŠ¨å¤šä¸ªå¹¶å‘è¯·æ±‚
	for i := 0; i < numGoroutines; i++ {
		wg.Add(1)
		go func(index int) {
			defer wg.Done()
			res, err := aispec.ChatBase(
				"http://example.com/v1/chat/completions",
				"gpt-4o-mini",
				fmt.Sprintf("concurrent request %d", index),
				aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
					return []poc.PocConfigOption{
						poc.WithHost(host),
						poc.WithPort(port),
						poc.WithForceHTTPS(false),
						poc.WithTimeout(10), // å¢åŠ è¶…æ—¶æ—¶é—´
					}, nil
				}),
				// ä½¿ç”¨æµå¼å¤„ç†ç¡®ä¿ç¨³å®šæ€§
				aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
					io.Copy(io.Discard, reader)
				}))

			mutex.Lock()
			if err != nil {
				errs = append(errs, err)
			} else {
				results = append(results, res)
			}
			mutex.Unlock()
		}(i)
	}

	// ç­‰å¾…æ‰€æœ‰goroutineå®Œæˆ
	wg.Wait()

	// æ£€æŸ¥ç»“æœ
	mutex.Lock()
	defer mutex.Unlock()

	// åªè¦æœ‰æˆåŠŸçš„è¯·æ±‚å°±è®¤ä¸ºå¹¶å‘å¤„ç†æ˜¯æ­£å¸¸çš„
	assert.True(t, len(results) > 0, "At least some concurrent requests should succeed")

	// æ£€æŸ¥æ‰€æœ‰æˆåŠŸçš„ç»“æœæ˜¯å¦æ­£ç¡®
	for _, res := range results {
		assert.Equal(t, "ä½ å¥½", res, "Concurrent request should return correct response")
	}

	// è®°å½•å¤±è´¥çš„è¯·æ±‚æ•°é‡ï¼ˆç”¨äºè°ƒè¯•ï¼‰
	if len(errs) > 0 {
		t.Logf("Number of failed concurrent requests: %d/%d", len(errs), numGoroutines)
		for i, err := range errs {
			t.Logf("Error %d: %v", i, err)
		}
	}
}

// TestChatBaseStability_HandlerPanics æµ‹è¯•å¤„ç†å™¨panicæ—¶çš„ç¨³å®šæ€§
func TestChatBaseStability_HandlerPanics(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiStreamRsp))

	t.Run("StreamHandlerPanic", func(t *testing.T) {
		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"hello",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
				panic("stream handler panic")
			}))

		// å³ä½¿å¤„ç†å™¨panicï¼Œä¸»å‡½æ•°åº”è¯¥ä»èƒ½æ­£å¸¸è¿”å›
		assert.NoError(t, err, "ChatBase should handle stream handler panic gracefully")
		// ç”±äºæµå¤„ç†å™¨panicï¼Œå¯èƒ½æ— æ³•è·å–å®Œæ•´å“åº”ï¼Œä½†è‡³å°‘ä¸åº”è¯¥å´©æºƒ
		t.Logf("Response with panic handler: %q", res)
	})

	t.Run("ReasonHandlerPanic", func(t *testing.T) {
		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"hello",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_ReasonStreamHandler(func(reader io.Reader) {
				panic("reason handler panic")
			}))
		assert.NoError(t, err, "ChatBase should handle reason handler panic gracefully")
		assert.Equal(t, "ä½ å¥½", res, "Response should still be correct despite panic")
	})

	t.Run("ErrorHandlerPanic", func(t *testing.T) {
		// ä½¿ç”¨defer recoveræ¥æ•è·panicï¼ŒéªŒè¯é”™è¯¯å¤„ç†å™¨çš„panicè¢«é€‚å½“å¤„ç†
		defer func() {
			if r := recover(); r != nil {
				// panicè¢«æ•è·è¯´æ˜é”™è¯¯å¤„ç†å™¨ç¡®å®å‘ç”Ÿäº†panic
				// è¿™æ˜¯é¢„æœŸçš„è¡Œä¸ºï¼Œå› ä¸ºé”™è¯¯å¤„ç†å™¨çš„panicå¯èƒ½ä¸ä¼šè¢«ChatBaseå†…éƒ¨å¤„ç†
				t.Logf("Error handler panic was caught: %v", r)
			}
		}()

		// ä½¿ç”¨ 127.0.0.1 å’Œéšæœºæ— æ•ˆç«¯å£æ¥è§¦å‘è¿æ¥é”™è¯¯ï¼Œé¿å…å¤–éƒ¨ç½‘ç»œè¿æ¥
		invalidPort := utils.GetRandomAvailableTCPPort() + 10000
		_, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"hello",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithTimeout(1),
					poc.WithHost("127.0.0.1"),
					poc.WithPort(invalidPort), // ä¸å­˜åœ¨çš„æœ¬åœ°ç«¯å£
					poc.WithForceHTTPS(false),
				}, nil
			}),
			aispec.WithChatBase_ErrHandler(func(httpErr error) {
				panic("error handler panic")
			}))

		// å¦‚æœæ²¡æœ‰panicï¼Œåº”è¯¥è¿”å›é”™è¯¯
		assert.Error(t, err, "ChatBase should return error when connection fails")
	})
}

// TestChatBaseStability_MalformedResponses æµ‹è¯•å¤„ç†æ ¼å¼é”™è¯¯å“åº”çš„ç¨³å®šæ€§
func TestChatBaseStability_MalformedResponses(t *testing.T) {
	t.Run("IncompleteStreamResponse", func(t *testing.T) {
		host, port := utils.DebugMockHTTP([]byte(mockAiStreamIncompleteRsp))

		var streamContent strings.Builder

		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"hello",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
				data, _ := io.ReadAll(reader)
				streamContent.Write(data)
			}))

		// åº”è¯¥èƒ½å¤„ç†ä¸å®Œæ•´çš„å“åº”
		assert.NoError(t, err, "Should handle incomplete stream response")
		assert.Contains(t, res, "Hello", "Should extract available content")
	})

	t.Run("MalformedStreamResponse", func(t *testing.T) {
		host, port := utils.DebugMockHTTP([]byte(mockAiStreamMalformedRsp))

		var streamContent strings.Builder

		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"hello",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
				data, _ := io.ReadAll(reader)
				streamContent.Write(data)
			}))

		// åº”è¯¥èƒ½å¤„ç†æ ¼å¼é”™è¯¯çš„å“åº”ï¼Œä¸å´©æºƒå°±æ˜¯æˆåŠŸ
		assert.NoError(t, err, "Should handle malformed stream response")
		// å¯¹äºæ ¼å¼é”™è¯¯çš„å“åº”ï¼Œèƒ½æ­£å¸¸å¤„ç†è€Œä¸å´©æºƒå°±æ˜¯æˆåŠŸ
		// ä¸å¼ºåˆ¶è¦æ±‚æå–ç‰¹å®šå†…å®¹ï¼Œå› ä¸ºè¿™å–å†³äºå…·ä½“çš„å®ç°
		t.Logf("Response from malformed stream: %q", res)
		t.Logf("Stream content: %q", streamContent.String())
	})
}

// TestChatBaseStability_EnableThinking æµ‹è¯•æ€è€ƒæ¨¡å¼çš„ç¨³å®šæ€§
func TestChatBaseStability_EnableThinking(t *testing.T) {
	t.Run("EnableThinkingBasic", func(t *testing.T) {
		// ä½¿ç”¨æµå¼å“åº”æµ‹è¯•EnableThinking
		host, port := utils.DebugMockHTTP([]byte(mockAiStreamRsp))
		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"hello",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_EnableThinking(true),
			// æ·»åŠ æµå¼å¤„ç†å™¨ç¡®ä¿ç¨³å®šæ€§
			aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
				io.Copy(io.Discard, reader)
			}))

		assert.NoError(t, err, "EnableThinking should work")
		assert.Equal(t, "ä½ å¥½", res)
	})

	t.Run("EnableThinkingWithCustomField", func(t *testing.T) {
		// ä½¿ç”¨æµå¼å“åº”
		host, port := utils.DebugMockHTTP([]byte(mockAiStreamRsp))
		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"hello",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_EnableThinkingEx(true, "reasoning_effort", "high"),
			aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
				io.Copy(io.Discard, reader)
			}))

		assert.NoError(t, err, "EnableThinkingEx should work")
		assert.Equal(t, "ä½ å¥½", res)
	})

	t.Run("ThinkingBudget", func(t *testing.T) {
		// ä½¿ç”¨æµå¼å“åº”
		host, port := utils.DebugMockHTTP([]byte(mockAiStreamRsp))
		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"hello",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_EnableThinking(true),
			aispec.WithChatBase_ThinkingBudget(1000),
			aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
				io.Copy(io.Discard, reader)
			}))

		assert.NoError(t, err, "ThinkingBudget should work")
		assert.Equal(t, "ä½ å¥½", res)
	})
}

// TestChatBaseStability_PoCOptionsGeneration æµ‹è¯•PoCOptionsç”Ÿæˆçš„ç¨³å®šæ€§
func TestChatBaseStability_PoCOptionsGeneration(t *testing.T) {
	t.Run("PoCOptionsError", func(t *testing.T) {
		_, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"hello",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return nil, fmt.Errorf("simulated PoCOptions generation error")
			}))

		assert.Error(t, err, "Should handle PoCOptions generation error")
		assert.Contains(t, err.Error(), "build config failed", "Error should indicate config build failure")
	})

	t.Run("NilPoCOptions", func(t *testing.T) {
		// ä½¿ç”¨æµå¼å“åº”
		host, port := utils.DebugMockHTTP([]byte(mockAiStreamRsp))
		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"hello",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
				io.Copy(io.Discard, reader)
			}))

		assert.NoError(t, err, "Should handle PoCOptions gracefully")
		assert.Equal(t, "ä½ å¥½", res)
	})
}

// TestChatBaseStability_LongRunningStream æµ‹è¯•é•¿æ—¶é—´è¿è¡Œæµçš„ç¨³å®šæ€§
func TestChatBaseStability_LongRunningStream(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiLongStreamRsp))

	var streamData strings.Builder
	var reasonData strings.Builder

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o-mini",
		"generate a long response",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(10), // æ›´é•¿çš„è¶…æ—¶æ—¶é—´
			}, nil
		}),
		aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
			data, _ := io.ReadAll(reader)
			streamData.Write(data)
		}),
		aispec.WithChatBase_ReasonStreamHandler(func(reader io.Reader) {
			data, _ := io.ReadAll(reader)
			reasonData.Write(data)
		}))

	assert.NoError(t, err, "Long running stream should work")
	// éªŒè¯å“åº”å’Œæµå¤„ç†éƒ½èƒ½æ­£å¸¸å·¥ä½œ
	// å¯¹äºé•¿æµå¼å“åº”ï¼Œé‡ç‚¹æ˜¯èƒ½å¤Ÿç¨³å®šå¤„ç†è€Œä¸æ˜¯ç‰¹å®šçš„å†…å®¹
	t.Logf("Response: %q", res)
	t.Logf("Stream data length: %d", streamData.Len())
	t.Logf("Reason data length: %d", reasonData.Len())

	// åªè¦èƒ½æ­£å¸¸å®Œæˆå¤„ç†å°±ç®—æˆåŠŸ
	assert.True(t, true, "Long running stream completed successfully")
}

// TestChatBaseStability_ImageHandling æµ‹è¯•å›¾ç‰‡å¤„ç†çš„ç¨³å®šæ€§
func TestChatBaseStability_ImageHandling(t *testing.T) {
	t.Run("SingleImage", func(t *testing.T) {
		// ä½¿ç”¨æµå¼å“åº”
		host, port := utils.DebugMockHTTP([]byte(mockAiStreamRsp))
		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"æè¿°è¿™å¼ å›¾ç‰‡",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_ImageRawInstance(&aispec.ImageDescription{
				Url: "https://example.com/image.jpg",
			}),
			aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
				io.Copy(io.Discard, reader)
			}))

		assert.NoError(t, err, "Single image should work")
		assert.Equal(t, "ä½ å¥½", res)
	})

	t.Run("MultipleImages", func(t *testing.T) {
		// ä½¿ç”¨æµå¼å“åº”
		host, port := utils.DebugMockHTTP([]byte(mockAiStreamRsp))
		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"",
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_ImageRawInstance(
				&aispec.ImageDescription{Url: "https://example.com/image1.jpg"},
				&aispec.ImageDescription{Url: "https://example.com/image2.jpg"},
			),
			aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
				io.Copy(io.Discard, reader)
			}))

		assert.NoError(t, err, "Multiple images should work")
		assert.Equal(t, "ä½ å¥½", res)
	})
}

// TestChatBaseStability_EdgeCases æµ‹è¯•å„ç§è¾¹ç•Œæƒ…å†µ
func TestChatBaseStability_EdgeCases(t *testing.T) {
	t.Run("EmptyMessage", func(t *testing.T) {
		// ä½¿ç”¨æµå¼å“åº”
		host, port := utils.DebugMockHTTP([]byte(mockAiStreamRsp))
		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			"", // ç©ºæ¶ˆæ¯
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
				io.Copy(io.Discard, reader)
			}))

		assert.NoError(t, err, "Empty message should work")
		assert.Equal(t, "ä½ å¥½", res)
	})

	t.Run("VeryLongMessage", func(t *testing.T) {
		// ä½¿ç”¨æµå¼å“åº”
		host, port := utils.DebugMockHTTP([]byte(mockAiStreamRsp))
		longMessage := strings.Repeat("è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æ¶ˆæ¯ã€‚", 100) // å‡å°‘é•¿åº¦é¿å…è¶…æ—¶

		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			longMessage,
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(10),
				}, nil
			}),
			aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
				io.Copy(io.Discard, reader)
			}))

		assert.NoError(t, err, "Very long message should work")
		assert.Equal(t, "ä½ å¥½", res)
	})

	t.Run("SpecialCharactersMessage", func(t *testing.T) {
		// ä½¿ç”¨æµå¼å“åº”
		host, port := utils.DebugMockHTTP([]byte(mockAiStreamRsp))
		specialMessage := "ç‰¹æ®Šå­—ç¬¦æµ‹è¯•: ğŸš€ ğŸ’» ğŸ”§ \n\t\r ä¸­æ–‡å­—ç¬¦ English ãƒ†ã‚¹ãƒˆ ğŸŒŸ"

		res, err := aispec.ChatBase(
			"http://example.com/v1/chat/completions",
			"gpt-4o-mini",
			specialMessage,
			aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
				return []poc.PocConfigOption{
					poc.WithHost(host),
					poc.WithPort(port),
					poc.WithForceHTTPS(false),
					poc.WithTimeout(5),
				}, nil
			}),
			aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
				io.Copy(io.Discard, reader)
			}))

		assert.NoError(t, err, "Special characters message should work")
		assert.Equal(t, "ä½ å¥½", res)
	})
}

// ==================== ToolCall Callback Tests ====================

// mockAiToolCallRsp æ¨¡æ‹ŸåŒ…å« tool_calls çš„éæµå¼ AI å“åº”
// ç”¨äºæµ‹è¯• ToolCallCallback åŠŸèƒ½
const mockAiToolCallRsp = `HTTP/1.1 200 OK
Connection: close
Content-Type: application/json; charset=utf-8

{
  "id": "chatcmpl-toolcall-test-123",
  "object": "chat.completion",
  "created": 1753327376,
  "model": "gpt-4o-mini",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "tool_calls": [
          {
            "id": "call_abc123",
            "type": "function",
            "function": {
              "name": "get_weather",
              "arguments": "{\"location\":\"Boston\",\"unit\":\"celsius\"}"
            }
          }
        ]
      },
      "finish_reason": "tool_calls"
    }
  ],
  "usage": { "prompt_tokens": 10, "completion_tokens": 20, "total_tokens": 30 }
}
`

// mockAiToolCallMultipleRsp æ¨¡æ‹ŸåŒ…å«å¤šä¸ª tool_calls çš„å“åº”
const mockAiToolCallMultipleRsp = `HTTP/1.1 200 OK
Connection: close
Content-Type: application/json; charset=utf-8

{
  "id": "chatcmpl-toolcall-multi-456",
  "object": "chat.completion",
  "created": 1753327376,
  "model": "gpt-4o-mini",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "tool_calls": [
          {
            "id": "call_first",
            "type": "function",
            "function": {
              "name": "get_weather",
              "arguments": "{\"location\":\"Boston\"}"
            }
          },
          {
            "id": "call_second",
            "type": "function",
            "function": {
              "name": "get_time",
              "arguments": "{\"timezone\":\"EST\"}"
            }
          }
        ]
      },
      "finish_reason": "tool_calls"
    }
  ],
  "usage": { "prompt_tokens": 10, "completion_tokens": 30, "total_tokens": 40 }
}
`

// TestToolCallCallback_WithCallback tests that tool calls are passed to callback when set
func TestToolCallCallback_WithCallback(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiToolCallRsp))

	var receivedToolCalls []*aispec.ToolCall
	var callbackInvoked bool

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o-mini",
		"What is the weather in Boston?",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_ToolCallCallback(func(toolCalls []*aispec.ToolCall) {
			callbackInvoked = true
			receivedToolCalls = toolCalls
		}),
	)

	assert.NoError(t, err, "Request should succeed")
	assert.True(t, callbackInvoked, "ToolCallCallback should be invoked")
	assert.Len(t, receivedToolCalls, 1, "Should receive 1 tool call")

	// Verify tool call details
	tc := receivedToolCalls[0]
	assert.Equal(t, "call_abc123", tc.ID, "Tool call ID should match")
	assert.Equal(t, "function", tc.Type, "Tool call type should be function")
	assert.Equal(t, "get_weather", tc.Function.Name, "Function name should match")
	assert.Contains(t, tc.Function.Arguments, "Boston", "Arguments should contain location")

	// Verify that <|TOOL_CALL...|> is NOT in the response when callback is set
	assert.NotContains(t, res, "<|TOOL_CALL", "Response should NOT contain <|TOOL_CALL when callback is set")
}

// TestToolCallCallback_WithoutCallback tests that tool calls are converted to <|TOOL_CALL...|> format when no callback
func TestToolCallCallback_WithoutCallback(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiToolCallRsp))

	var streamContent strings.Builder

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o-mini",
		"What is the weather in Boston?",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
			data, _ := io.ReadAll(reader)
			streamContent.Write(data)
		}),
		// No ToolCallCallback set - should use legacy <|TOOL_CALL...|> format
	)

	assert.NoError(t, err, "Request should succeed")

	// Verify that <|TOOL_CALL...|> IS in the response when no callback is set
	assert.Contains(t, res, "<|TOOL_CALL_", "Response should contain <|TOOL_CALL_ when no callback is set")
	assert.Contains(t, res, "<|TOOL_CALL_END", "Response should contain <|TOOL_CALL_END when no callback is set")
	assert.Contains(t, res, "get_weather", "Response should contain function name")
}

// TestToolCallCallback_MultipleToolCalls tests handling of multiple tool calls
func TestToolCallCallback_MultipleToolCalls(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiToolCallMultipleRsp))

	var receivedToolCalls []*aispec.ToolCall

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o-mini",
		"What is the weather and time in Boston?",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_ToolCallCallback(func(toolCalls []*aispec.ToolCall) {
			receivedToolCalls = append(receivedToolCalls, toolCalls...)
		}),
	)

	assert.NoError(t, err, "Request should succeed")
	assert.Len(t, receivedToolCalls, 2, "Should receive 2 tool calls")

	// Verify first tool call
	assert.Equal(t, "call_first", receivedToolCalls[0].ID)
	assert.Equal(t, "get_weather", receivedToolCalls[0].Function.Name)

	// Verify second tool call
	assert.Equal(t, "call_second", receivedToolCalls[1].ID)
	assert.Equal(t, "get_time", receivedToolCalls[1].Function.Name)

	// Verify no <|TOOL_CALL...|> format
	assert.NotContains(t, res, "<|TOOL_CALL", "Response should NOT contain <|TOOL_CALL when callback is set")
}

// TestToolCallCallback_WithStreamHandler tests that both stream handler and tool call callback work together
func TestToolCallCallback_WithStreamHandler(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiToolCallRsp))

	var receivedToolCalls []*aispec.ToolCall
	var streamHandlerCalled bool

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o-mini",
		"What is the weather in Boston?",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
			streamHandlerCalled = true
			io.Copy(io.Discard, reader)
		}),
		aispec.WithChatBase_ToolCallCallback(func(toolCalls []*aispec.ToolCall) {
			receivedToolCalls = toolCalls
		}),
	)

	assert.NoError(t, err, "Request should succeed")
	assert.True(t, streamHandlerCalled, "Stream handler should be called")
	assert.Len(t, receivedToolCalls, 1, "Should receive 1 tool call")
	assert.Equal(t, "get_weather", receivedToolCalls[0].Function.Name)
	assert.NotContains(t, res, "<|TOOL_CALL", "Response should NOT contain <|TOOL_CALL when callback is set")
}

// TestToolCallCallback_NoToolCalls tests that callback is not invoked when response has no tool calls
func TestToolCallCallback_NoToolCalls(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiRsp))

	var callbackInvoked bool

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o-mini",
		"hello",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_ToolCallCallback(func(toolCalls []*aispec.ToolCall) {
			callbackInvoked = true
		}),
	)

	assert.NoError(t, err, "Request should succeed")
	assert.False(t, callbackInvoked, "ToolCallCallback should NOT be invoked when no tool calls in response")
	assert.Equal(t, "ä½ å¥½ï¼ğŸ˜Š å¾ˆé«˜å…´è§åˆ°ä½ ï½æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ", res, "Normal response should still work")
}

// ==================== Complex Real-World SSE Tests ====================

// mockAiComplexReasoningStreamRsp æ¨¡æ‹Ÿå¤æ‚çš„å¸¦æ¨ç†å†…å®¹çš„æµå¼å“åº”
// æµ‹è¯•åœºæ™¯ï¼šAI å…ˆè¿›è¡Œæ¨ç†ï¼ˆreasoning_contentï¼‰ï¼Œç„¶åè¾“å‡ºç»“æœ
const mockAiComplexReasoningStreamRsp = `HTTP/1.1 200 OK
Connection: close
Content-Type: text/event-stream

data: {"id":"complex-reason-1","object":"chat.completion.chunk","created":1753329315,"model":"deepseek-r1","choices":[{"index":0,"delta":{"role":"assistant","content":"","reasoning_content":"Let me analyze this step by step..."},"finish_reason":null}]}

data: {"id":"complex-reason-2","object":"chat.completion.chunk","created":1753329316,"model":"deepseek-r1","choices":[{"index":0,"delta":{"reasoning_content":" First, I need to understand the user's question."},"finish_reason":null}]}

data: {"id":"complex-reason-3","object":"chat.completion.chunk","created":1753329317,"model":"deepseek-r1","choices":[{"index":0,"delta":{"reasoning_content":" The user wants to know about weather."},"finish_reason":null}]}

data: {"id":"complex-reason-4","object":"chat.completion.chunk","created":1753329318,"model":"deepseek-r1","choices":[{"index":0,"delta":{"content":"Based on my analysis, "},"finish_reason":null}]}

data: {"id":"complex-reason-5","object":"chat.completion.chunk","created":1753329319,"model":"deepseek-r1","choices":[{"index":0,"delta":{"content":"the weather today is sunny with a high of 25Â°C."},"finish_reason":null}]}

data: {"id":"complex-reason-6","object":"chat.completion.chunk","created":1753329320,"model":"deepseek-r1","choices":[{"index":0,"delta":{},"finish_reason":"stop"}]}

data: [DONE]
`

// mockAiStreamWithToolCallRsp æ¨¡æ‹Ÿæµå¼å“åº”ä¸­å¸¦æœ‰ tool_calls
// æµ‹è¯•åœºæ™¯ï¼šæµå¼å“åº”æœ€ååŒ…å« tool_calls delta
const mockAiStreamWithToolCallRsp = `HTTP/1.1 200 OK
Connection: close
Content-Type: text/event-stream

data: {"id":"stream-tool-1","object":"chat.completion.chunk","created":1753329315,"model":"gpt-4o","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"stream-tool-2","object":"chat.completion.chunk","created":1753329316,"model":"gpt-4o","choices":[{"index":0,"delta":{"content":"I'll check the weather for you."},"finish_reason":null}]}

data: {"id":"stream-tool-3","object":"chat.completion.chunk","created":1753329317,"model":"gpt-4o","choices":[{"index":0,"delta":{"tool_calls":[{"index":0,"id":"call_stream_abc","type":"function","function":{"name":"get_weather","arguments":""}}]},"finish_reason":null}]}

data: {"id":"stream-tool-4","object":"chat.completion.chunk","created":1753329318,"model":"gpt-4o","choices":[{"index":0,"delta":{"tool_calls":[{"index":0,"function":{"arguments":"{\"location\":"}}]},"finish_reason":null}]}

data: {"id":"stream-tool-5","object":"chat.completion.chunk","created":1753329319,"model":"gpt-4o","choices":[{"index":0,"delta":{"tool_calls":[{"index":0,"function":{"arguments":"\"Boston\"}"}}]},"finish_reason":null}]}

data: {"id":"stream-tool-6","object":"chat.completion.chunk","created":1753329320,"model":"gpt-4o","choices":[{"index":0,"delta":{},"finish_reason":"tool_calls"}]}

data: [DONE]
`

// mockAiReasonThenToolCallRsp æ¨¡æ‹Ÿå…ˆæ¨ç†åè°ƒç”¨å·¥å…·çš„éæµå¼å“åº”
// æµ‹è¯•åœºæ™¯ï¼šAI å…ˆè¾“å‡º reasoning_contentï¼Œç„¶åå†³å®šè°ƒç”¨å·¥å…·
const mockAiReasonThenToolCallRsp = `HTTP/1.1 200 OK
Connection: close
Content-Type: application/json; charset=utf-8

{
  "id": "reason-tool-123",
  "object": "chat.completion",
  "created": 1753327376,
  "model": "deepseek-r1",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "reasoning_content": "The user is asking about the current weather. I don't have real-time weather data, so I need to use the get_weather tool to fetch this information for Boston.",
        "tool_calls": [
          {
            "id": "call_reason_tool_001",
            "type": "function",
            "function": {
              "name": "get_weather",
              "arguments": "{\"location\":\"Boston\",\"unit\":\"fahrenheit\"}"
            }
          }
        ]
      },
      "finish_reason": "tool_calls"
    }
  ],
  "usage": { "prompt_tokens": 15, "completion_tokens": 50, "total_tokens": 65 }
}
`

// mockAiMultiToolCallWithContentRsp æ¨¡æ‹ŸåŒæ—¶æœ‰å†…å®¹å’Œå¤šä¸ªå·¥å…·è°ƒç”¨çš„å“åº”
const mockAiMultiToolCallWithContentRsp = `HTTP/1.1 200 OK
Connection: close
Content-Type: application/json; charset=utf-8

{
  "id": "multi-tool-content-456",
  "object": "chat.completion",
  "created": 1753327376,
  "model": "gpt-4o",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "I'll help you with that. Let me gather the information you need.",
        "tool_calls": [
          {
            "id": "call_multi_1",
            "type": "function",
            "function": {
              "name": "get_weather",
              "arguments": "{\"location\":\"Boston\"}"
            }
          },
          {
            "id": "call_multi_2",
            "type": "function",
            "function": {
              "name": "get_time",
              "arguments": "{\"timezone\":\"America/New_York\"}"
            }
          },
          {
            "id": "call_multi_3",
            "type": "function",
            "function": {
              "name": "search_restaurants",
              "arguments": "{\"location\":\"Boston\",\"cuisine\":\"Italian\"}"
            }
          }
        ]
      },
      "finish_reason": "tool_calls"
    }
  ],
  "usage": { "prompt_tokens": 20, "completion_tokens": 80, "total_tokens": 100 }
}
`

// TestComplexReasoning_StreamWithReason tests complex streaming with reasoning content
func TestComplexReasoning_StreamWithReason(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiComplexReasoningStreamRsp))

	var streamContent strings.Builder
	var reasonContent strings.Builder
	var streamHandlerCalled, reasonHandlerCalled bool

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"deepseek-r1",
		"What is the weather today?",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
			streamHandlerCalled = true
			data, _ := io.ReadAll(reader)
			streamContent.Write(data)
		}),
		aispec.WithChatBase_ReasonStreamHandler(func(reader io.Reader) {
			reasonHandlerCalled = true
			data, _ := io.ReadAll(reader)
			reasonContent.Write(data)
		}),
	)

	assert.NoError(t, err, "Complex reasoning stream should succeed")
	assert.True(t, streamHandlerCalled, "Stream handler should be called")
	assert.True(t, reasonHandlerCalled, "Reason handler should be called")

	// Verify reasoning content
	assert.Contains(t, reasonContent.String(), "step by step", "Reason content should contain reasoning")
	assert.Contains(t, reasonContent.String(), "understand the user", "Reason content should contain analysis")

	// Verify output content
	assert.Contains(t, res, "Based on my analysis", "Response should contain conclusion")
	assert.Contains(t, res, "sunny", "Response should contain weather info")
}

// TestComplexReasoning_ThenToolCall tests reasoning followed by tool call
func TestComplexReasoning_ThenToolCall(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiReasonThenToolCallRsp))

	var receivedToolCalls []*aispec.ToolCall
	var reasonContent strings.Builder

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"deepseek-r1",
		"What is the weather in Boston?",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_ReasonStreamHandler(func(reader io.Reader) {
			data, _ := io.ReadAll(reader)
			reasonContent.Write(data)
		}),
		aispec.WithChatBase_ToolCallCallback(func(toolCalls []*aispec.ToolCall) {
			receivedToolCalls = toolCalls
		}),
	)

	assert.NoError(t, err, "Reason then tool call should succeed")

	// Verify reasoning content was captured
	assert.Contains(t, reasonContent.String(), "real-time weather", "Reasoning should mention real-time weather")
	assert.Contains(t, reasonContent.String(), "get_weather tool", "Reasoning should mention the tool")

	// Verify tool call was captured
	assert.Len(t, receivedToolCalls, 1, "Should receive 1 tool call")
	assert.Equal(t, 0, receivedToolCalls[0].Index, "First tool call should have Index 0")
	assert.Equal(t, "get_weather", receivedToolCalls[0].Function.Name)
	assert.Equal(t, "call_reason_tool_001", receivedToolCalls[0].ID)
	assert.Contains(t, receivedToolCalls[0].Function.Arguments, "Boston")

	// Verify no <|TOOL_CALL...|> in response
	assert.NotContains(t, res, "<|TOOL_CALL", "Response should NOT contain <|TOOL_CALL when callback is set")
}

// TestComplexReasoning_MultiToolCallWithContent tests response with both content and multiple tool calls
func TestComplexReasoning_MultiToolCallWithContent(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiMultiToolCallWithContentRsp))

	var receivedToolCalls []*aispec.ToolCall
	var streamContent strings.Builder

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o",
		"Tell me about Boston - weather, time, and restaurants",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
			data, _ := io.ReadAll(reader)
			streamContent.Write(data)
		}),
		aispec.WithChatBase_ToolCallCallback(func(toolCalls []*aispec.ToolCall) {
			receivedToolCalls = append(receivedToolCalls, toolCalls...)
		}),
	)

	assert.NoError(t, err, "Multi tool call with content should succeed")

	// Verify content was captured
	assert.Contains(t, res, "help you with that", "Response should contain content")
	assert.Contains(t, res, "gather the information", "Response should contain content")

	// Verify all 3 tool calls were captured
	assert.Len(t, receivedToolCalls, 3, "Should receive 3 tool calls")

	// Verify each tool call has correct Index (0, 1, 2)
	for i, tc := range receivedToolCalls {
		assert.Equal(t, i, tc.Index, "Tool call at position %d should have Index %d", i, i)
	}

	// Verify each tool call
	toolNames := make([]string, 0, 3)
	for _, tc := range receivedToolCalls {
		toolNames = append(toolNames, tc.Function.Name)
	}
	assert.Contains(t, toolNames, "get_weather", "Should have get_weather tool")
	assert.Contains(t, toolNames, "get_time", "Should have get_time tool")
	assert.Contains(t, toolNames, "search_restaurants", "Should have search_restaurants tool")

	// Verify no <|TOOL_CALL...|> in response
	assert.NotContains(t, res, "<|TOOL_CALL", "Response should NOT contain <|TOOL_CALL when callback is set")
}

// TestComplexReasoning_StreamToolCallDelta tests streaming tool call with delta arguments
func TestComplexReasoning_StreamToolCallDelta(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiStreamWithToolCallRsp))

	var streamContent strings.Builder

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o",
		"What is the weather in Boston?",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
			data, _ := io.ReadAll(reader)
			streamContent.Write(data)
		}),
		// No ToolCallCallback - should use legacy format for streaming tool calls
	)

	assert.NoError(t, err, "Stream with tool call delta should succeed")

	// Verify content was captured
	assert.Contains(t, res, "check the weather", "Response should contain initial content")

	// For streaming tool calls with delta arguments, verify the arguments are accumulated
	// The arguments come in multiple chunks: {"location": and "Boston"}
	assert.Contains(t, res, "location", "Response should contain accumulated arguments")
	assert.Contains(t, res, "Boston", "Response should contain location value")
}

// TestComplexReasoning_StreamToolCallWithCallback_NoContentLeakage tests that streaming tool_calls
// are ONLY passed to callback and do NOT leak into content stream.
// This is critical for clients like Cursor that expect OpenAI-standard behavior.
func TestComplexReasoning_StreamToolCallWithCallback_NoContentLeakage(t *testing.T) {
	// Mock SSE response with streaming tool_calls in delta (use same format as mockAiStreamWithToolCallRsp)
	mockStreamingToolCall := `HTTP/1.1 200 OK
Connection: close
Content-Type: text/event-stream

data: {"id":"stream-nocontent-1","object":"chat.completion.chunk","created":1753329315,"model":"gpt-4o","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"stream-nocontent-2","object":"chat.completion.chunk","created":1753329316,"model":"gpt-4o","choices":[{"index":0,"delta":{"content":"Let me check that for you."},"finish_reason":null}]}

data: {"id":"stream-nocontent-3","object":"chat.completion.chunk","created":1753329317,"model":"gpt-4o","choices":[{"index":0,"delta":{"tool_calls":[{"index":0,"id":"call_stream_001","type":"function","function":{"name":"read_file","arguments":""}}]},"finish_reason":null}]}

data: {"id":"stream-nocontent-4","object":"chat.completion.chunk","created":1753329318,"model":"gpt-4o","choices":[{"index":0,"delta":{"tool_calls":[{"index":0,"function":{"arguments":"{\"path\":\"/test/"}}]},"finish_reason":null}]}

data: {"id":"stream-nocontent-5","object":"chat.completion.chunk","created":1753329319,"model":"gpt-4o","choices":[{"index":0,"delta":{"tool_calls":[{"index":0,"function":{"arguments":"README.md\"}"}}]},"finish_reason":null}]}

data: {"id":"stream-nocontent-6","object":"chat.completion.chunk","created":1753329320,"model":"gpt-4o","choices":[{"index":0,"delta":{},"finish_reason":"tool_calls"}]}

data: [DONE]
`
	host, port := utils.DebugMockHTTP([]byte(mockStreamingToolCall))

	var receivedToolCalls []*aispec.ToolCall
	var contentStream strings.Builder

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o",
		"Read the README file",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
			data, _ := io.ReadAll(reader)
			contentStream.Write(data)
		}),
		aispec.WithChatBase_ToolCallCallback(func(toolCalls []*aispec.ToolCall) {
			receivedToolCalls = append(receivedToolCalls, toolCalls...)
		}),
	)

	assert.NoError(t, err, "Streaming tool call should succeed")

	// CRITICAL: Verify tool_calls data does NOT appear in content stream
	assert.NotContains(t, res, "read_file", "Tool call function name should NOT be in content")
	assert.NotContains(t, res, "README.md", "Tool call arguments should NOT be in content")
	assert.NotContains(t, contentStream.String(), "read_file", "Stream content should NOT contain function name")
	assert.NotContains(t, contentStream.String(), "README.md", "Stream content should NOT contain arguments")

	// Verify content only contains actual content
	assert.Contains(t, res, "Let me check", "Response should contain actual content")

	// Verify tool calls were passed to callback
	assert.Greater(t, len(receivedToolCalls), 0, "Should receive tool calls via callback")

	// Verify tool call structure
	var foundReadFile bool
	for _, tc := range receivedToolCalls {
		if tc.Function.Name == "read_file" {
			foundReadFile = true
			assert.Equal(t, "call_stream_001", tc.ID, "Tool call ID should match")
			assert.Equal(t, "function", tc.Type, "Tool call type should be 'function'")
			// Note: In streaming, arguments come in chunks, so we may have partial data
			t.Logf("Tool call: %s, args: %s", tc.Function.Name, tc.Function.Arguments)
		}
	}
	assert.True(t, foundReadFile, "Should have received read_file tool call")
}

// TestComplexReasoning_StreamNoCallback tests streaming without callback preserves legacy format
func TestComplexReasoning_LegacyToolCallFormat(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiToolCallRsp))

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o-mini",
		"What is the weather in Boston?",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		// Explicitly no ToolCallCallback to test legacy behavior
	)

	assert.NoError(t, err, "Legacy tool call format should succeed")

	// Verify legacy <|TOOL_CALL...|> format is present
	assert.Contains(t, res, "<|TOOL_CALL_", "Legacy format should contain <|TOOL_CALL_")
	assert.Contains(t, res, "<|TOOL_CALL_END", "Legacy format should contain <|TOOL_CALL_END")
	assert.Contains(t, res, "get_weather", "Legacy format should contain function name")
	assert.Contains(t, res, "Boston", "Legacy format should contain arguments")
}

// TestComplexReasoning_ReasonWithoutToolCall tests pure reasoning without tool calls
func TestComplexReasoning_PureReasoning(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiComplexReasoningStreamRsp))

	var reasonContent strings.Builder
	var callbackInvoked bool

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"deepseek-r1",
		"Explain quantum computing",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_ReasonStreamHandler(func(reader io.Reader) {
			data, _ := io.ReadAll(reader)
			reasonContent.Write(data)
		}),
		aispec.WithChatBase_ToolCallCallback(func(toolCalls []*aispec.ToolCall) {
			callbackInvoked = true
		}),
	)

	assert.NoError(t, err, "Pure reasoning should succeed")
	assert.False(t, callbackInvoked, "ToolCallCallback should NOT be invoked for pure reasoning")

	// Verify reasoning was captured
	assert.NotEmpty(t, reasonContent.String(), "Reasoning content should be captured")
	assert.Contains(t, reasonContent.String(), "step by step", "Reasoning should be present")

	// Verify content was captured
	assert.Contains(t, res, "Based on my analysis", "Response should contain conclusion")
}

// TestComplexReasoning_ConcurrentHandlers tests that all handlers work correctly together
func TestComplexReasoning_ConcurrentHandlers(t *testing.T) {
	host, port := utils.DebugMockHTTP([]byte(mockAiReasonThenToolCallRsp))

	var streamCallCount, reasonCallCount, toolCallCount int
	var mutex sync.Mutex

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"deepseek-r1",
		"What is the weather?",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_StreamHandler(func(reader io.Reader) {
			mutex.Lock()
			streamCallCount++
			mutex.Unlock()
			io.Copy(io.Discard, reader)
		}),
		aispec.WithChatBase_ReasonStreamHandler(func(reader io.Reader) {
			mutex.Lock()
			reasonCallCount++
			mutex.Unlock()
			io.Copy(io.Discard, reader)
		}),
		aispec.WithChatBase_ToolCallCallback(func(toolCalls []*aispec.ToolCall) {
			mutex.Lock()
			toolCallCount += len(toolCalls)
			mutex.Unlock()
		}),
	)

	assert.NoError(t, err, "Concurrent handlers should succeed")

	// All handlers should be called
	assert.Equal(t, 1, streamCallCount, "Stream handler should be called once")
	assert.Equal(t, 1, reasonCallCount, "Reason handler should be called once")
	assert.Equal(t, 1, toolCallCount, "Tool call callback should receive 1 tool call")

	// Response should not contain legacy format
	assert.NotContains(t, res, "<|TOOL_CALL", "Response should NOT contain legacy format")
}

// ==================== Tools Parameter Tests ====================

// mockAiToolCallWithToolsRsp æ¨¡æ‹Ÿå½“è¯·æ±‚åŒ…å« tools å‚æ•°æ—¶ï¼ŒAI è¿”å› tool_calls çš„å“åº”
const mockAiToolCallWithToolsRsp = `HTTP/1.1 200 OK
Connection: close
Content-Type: application/json; charset=utf-8

{
  "id": "tools-test-123",
  "object": "chat.completion",
  "created": 1753327376,
  "model": "gpt-4o",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "tool_calls": [
          {
            "id": "call_tools_test_001",
            "type": "function",
            "function": {
              "name": "get_weather",
              "arguments": "{\"location\":\"Beijing\",\"unit\":\"celsius\"}"
            }
          }
        ]
      },
      "finish_reason": "tool_calls"
    }
  ],
  "usage": { "prompt_tokens": 50, "completion_tokens": 30, "total_tokens": 80 }
}
`

// TestChatBase_WithTools tests that tools parameter is correctly passed to the request
func TestChatBase_WithTools(t *testing.T) {
	var capturedRequest []byte

	// Use DebugMockHTTPEx to capture the request and verify tools field
	host, port := utils.DebugMockHTTPEx(func(req []byte) []byte {
		capturedRequest = req
		return []byte(mockAiToolCallWithToolsRsp)
	})

	// Define tools
	tools := []aispec.Tool{
		{
			Type: "function",
			Function: aispec.ToolFunction{
				Name:        "get_weather",
				Description: "Get the current weather in a given location",
				Parameters: map[string]any{
					"type": "object",
					"properties": map[string]any{
						"location": map[string]any{
							"type":        "string",
							"description": "The city name",
						},
						"unit": map[string]any{
							"type": "string",
							"enum": []string{"celsius", "fahrenheit"},
						},
					},
					"required": []string{"location"},
				},
			},
		},
	}

	var receivedToolCalls []*aispec.ToolCall

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o",
		"What is the weather in Beijing?",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_Tools(tools),
		aispec.WithChatBase_ToolChoice("auto"),
		aispec.WithChatBase_ToolCallCallback(func(toolCalls []*aispec.ToolCall) {
			receivedToolCalls = toolCalls
		}),
	)

	assert.NoError(t, err, "Request with tools should succeed")

	// ===== CRITICAL: Verify the request body contains tools field =====
	requestBody := string(capturedRequest)
	assert.Contains(t, requestBody, `"tools"`, "Request MUST contain 'tools' field when tools are provided")
	assert.Contains(t, requestBody, `"tool_choice"`, "Request MUST contain 'tool_choice' field when tool_choice is provided")
	assert.Contains(t, requestBody, `"get_weather"`, "Request should contain function name in tools")
	assert.Contains(t, requestBody, `"function"`, "Request should contain function type in tools")
	t.Logf("Request body contains tools: %v", strings.Contains(requestBody, `"tools"`))

	// Verify tool calls were received
	assert.Len(t, receivedToolCalls, 1, "Should receive 1 tool call")
	assert.Equal(t, "get_weather", receivedToolCalls[0].Function.Name)
	assert.Equal(t, "call_tools_test_001", receivedToolCalls[0].ID)
	assert.Contains(t, receivedToolCalls[0].Function.Arguments, "Beijing")

	// Verify no <|TOOL_CALL...|> in response when callback is set
	assert.NotContains(t, res, "<|TOOL_CALL", "Response should NOT contain legacy format when callback is set")

	t.Logf("Tool call received: %s with args: %s", receivedToolCalls[0].Function.Name, receivedToolCalls[0].Function.Arguments)
}

// TestChatBase_WithTools_MultipleTools tests multiple tools in a single request
func TestChatBase_WithTools_MultipleTools(t *testing.T) {
	// Mock response with multiple tool calls
	mockMultiToolRsp := `HTTP/1.1 200 OK
Connection: close
Content-Type: application/json; charset=utf-8

{
  "id": "multi-tools-test",
  "object": "chat.completion",
  "created": 1753327376,
  "model": "gpt-4o",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "I'll check both for you.",
        "tool_calls": [
          {
            "id": "call_multi_1",
            "type": "function",
            "function": {
              "name": "get_weather",
              "arguments": "{\"location\":\"Beijing\"}"
            }
          },
          {
            "id": "call_multi_2",
            "type": "function",
            "function": {
              "name": "get_time",
              "arguments": "{\"timezone\":\"Asia/Shanghai\"}"
            }
          }
        ]
      },
      "finish_reason": "tool_calls"
    }
  ]
}
`
	var capturedRequest []byte
	host, port := utils.DebugMockHTTPEx(func(req []byte) []byte {
		capturedRequest = req
		return []byte(mockMultiToolRsp)
	})

	// Define multiple tools
	tools := []aispec.Tool{
		{
			Type: "function",
			Function: aispec.ToolFunction{
				Name:        "get_weather",
				Description: "Get weather",
			},
		},
		{
			Type: "function",
			Function: aispec.ToolFunction{
				Name:        "get_time",
				Description: "Get current time",
			},
		},
	}

	var receivedToolCalls []*aispec.ToolCall

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o",
		"What is the weather and time in Beijing?",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_Tools(tools),
		aispec.WithChatBase_ToolCallCallback(func(toolCalls []*aispec.ToolCall) {
			receivedToolCalls = append(receivedToolCalls, toolCalls...)
		}),
	)

	assert.NoError(t, err, "Request with multiple tools should succeed")

	// ===== CRITICAL: Verify the request body contains multiple tools =====
	requestBody := string(capturedRequest)
	assert.Contains(t, requestBody, `"tools"`, "Request MUST contain 'tools' field")
	assert.Contains(t, requestBody, `"get_weather"`, "Request should contain get_weather function")
	assert.Contains(t, requestBody, `"get_time"`, "Request should contain get_time function")
	t.Logf("Request contains both tools: get_weather=%v, get_time=%v",
		strings.Contains(requestBody, `"get_weather"`), strings.Contains(requestBody, `"get_time"`))

	// Verify content was captured
	assert.Contains(t, res, "check both", "Response should contain content")

	// Verify both tool calls were received
	assert.Len(t, receivedToolCalls, 2, "Should receive 2 tool calls")

	// Verify tool call indices
	for i, tc := range receivedToolCalls {
		assert.Equal(t, i, tc.Index, "Tool call %d should have Index %d", i, i)
	}

	// Verify tool names
	toolNames := make([]string, 0, 2)
	for _, tc := range receivedToolCalls {
		toolNames = append(toolNames, tc.Function.Name)
	}
	assert.Contains(t, toolNames, "get_weather", "Should have get_weather tool")
	assert.Contains(t, toolNames, "get_time", "Should have get_time tool")
}

// TestChatBase_WithTools_NoCallback tests that legacy format is used when no callback is set
func TestChatBase_WithTools_NoCallback(t *testing.T) {
	var capturedRequest []byte
	host, port := utils.DebugMockHTTPEx(func(req []byte) []byte {
		capturedRequest = req
		return []byte(mockAiToolCallWithToolsRsp)
	})

	tools := []aispec.Tool{
		{
			Type: "function",
			Function: aispec.ToolFunction{
				Name:        "get_weather",
				Description: "Get weather",
			},
		},
	}

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o",
		"What is the weather?",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_Tools(tools),
		// No ToolCallCallback - should use legacy format
	)

	assert.NoError(t, err, "Request should succeed")

	// ===== CRITICAL: Verify the request body still contains tools =====
	requestBody := string(capturedRequest)
	assert.Contains(t, requestBody, `"tools"`, "Request MUST contain 'tools' field even without callback")
	assert.Contains(t, requestBody, `"get_weather"`, "Request should contain function name in tools")
	t.Logf("Request contains tools field: %v", strings.Contains(requestBody, `"tools"`))

	// Verify legacy format is used when no callback is set
	assert.Contains(t, res, "<|TOOL_CALL_", "Response SHOULD contain legacy format when no callback is set")
	assert.Contains(t, res, "get_weather", "Legacy format should contain function name")
	assert.Contains(t, res, "Beijing", "Legacy format should contain arguments")
}

// TestChatBase_WithTools_ToolChoiceRequired tests tool_choice = "required"
func TestChatBase_WithTools_ToolChoiceRequired(t *testing.T) {
	var capturedRequest []byte
	host, port := utils.DebugMockHTTPEx(func(req []byte) []byte {
		capturedRequest = req
		return []byte(mockAiToolCallWithToolsRsp)
	})

	tools := []aispec.Tool{
		{
			Type: "function",
			Function: aispec.ToolFunction{
				Name: "get_weather",
			},
		},
	}

	var callbackCalled bool

	_, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o",
		"Get weather",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_Tools(tools),
		aispec.WithChatBase_ToolChoice("required"),
		aispec.WithChatBase_ToolCallCallback(func(toolCalls []*aispec.ToolCall) {
			callbackCalled = true
		}),
	)

	assert.NoError(t, err, "Request with tool_choice=required should succeed")

	// ===== CRITICAL: Verify tool_choice is correctly set in request =====
	requestBody := string(capturedRequest)
	assert.Contains(t, requestBody, `"tools"`, "Request MUST contain 'tools' field")
	assert.Contains(t, requestBody, `"tool_choice"`, "Request MUST contain 'tool_choice' field")
	assert.Contains(t, requestBody, `"required"`, "Request should contain tool_choice value 'required'")
	t.Logf("Request contains tool_choice=required: %v", strings.Contains(requestBody, `"required"`))

	assert.True(t, callbackCalled, "Tool call callback should be called")
}

// TestChatBase_WithTools_SpecificFunction tests tool_choice with specific function
func TestChatBase_WithTools_SpecificFunction(t *testing.T) {
	var capturedRequest []byte
	host, port := utils.DebugMockHTTPEx(func(req []byte) []byte {
		capturedRequest = req
		return []byte(mockAiToolCallWithToolsRsp)
	})

	tools := []aispec.Tool{
		{
			Type: "function",
			Function: aispec.ToolFunction{
				Name: "get_weather",
			},
		},
		{
			Type: "function",
			Function: aispec.ToolFunction{
				Name: "get_time",
			},
		},
	}

	// Specific tool_choice format
	toolChoice := map[string]any{
		"type": "function",
		"function": map[string]any{
			"name": "get_weather",
		},
	}

	var receivedToolCalls []*aispec.ToolCall

	_, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o",
		"Tell me about Beijing",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_Tools(tools),
		aispec.WithChatBase_ToolChoice(toolChoice),
		aispec.WithChatBase_ToolCallCallback(func(toolCalls []*aispec.ToolCall) {
			receivedToolCalls = toolCalls
		}),
	)

	assert.NoError(t, err, "Request with specific tool_choice should succeed")

	// ===== CRITICAL: Verify complex tool_choice object is in request =====
	requestBody := string(capturedRequest)
	assert.Contains(t, requestBody, `"tools"`, "Request MUST contain 'tools' field")
	assert.Contains(t, requestBody, `"tool_choice"`, "Request MUST contain 'tool_choice' field")
	// Verify the specific function is included in tool_choice
	assert.Contains(t, requestBody, `"function"`, "Request should contain 'function' in tool_choice")
	t.Logf("Request contains specific tool_choice: %v", strings.Contains(requestBody, `"tool_choice"`))

	assert.Len(t, receivedToolCalls, 1, "Should receive exactly 1 tool call")
	assert.Equal(t, "get_weather", receivedToolCalls[0].Function.Name)
}

// TestChatBase_WithEmptyTools tests that empty tools array doesn't cause issues
func TestChatBase_WithEmptyTools(t *testing.T) {
	var capturedRequest []byte
	host, port := utils.DebugMockHTTPEx(func(req []byte) []byte {
		capturedRequest = req
		return []byte(mockAiRsp)
	})

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o",
		"Hello",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		aispec.WithChatBase_Tools([]aispec.Tool{}), // Empty tools array
	)

	assert.NoError(t, err, "Request with empty tools should succeed")
	assert.Contains(t, res, "ä½ å¥½", "Normal response should work")

	// ===== CRITICAL: Empty tools array should NOT include tools field in request =====
	requestBody := string(capturedRequest)
	// When tools is empty array, it should not include tools field
	t.Logf("Request body with empty tools contains 'tools' field: %v", strings.Contains(requestBody, `"tools"`))
}

// TestChatBase_WithoutTools tests that no tools field is present when tools are not provided
func TestChatBase_WithoutTools(t *testing.T) {
	var capturedRequest []byte
	host, port := utils.DebugMockHTTPEx(func(req []byte) []byte {
		capturedRequest = req
		return []byte(mockAiRsp)
	})

	res, err := aispec.ChatBase(
		"http://example.com/v1/chat/completions",
		"gpt-4o",
		"Hello without tools",
		aispec.WithChatBase_PoCOptions(func() ([]poc.PocConfigOption, error) {
			return []poc.PocConfigOption{
				poc.WithHost(host),
				poc.WithPort(port),
				poc.WithForceHTTPS(false),
				poc.WithTimeout(5),
			}, nil
		}),
		// NOTE: No WithChatBase_Tools option - should NOT include tools in request
	)

	assert.NoError(t, err, "Request without tools should succeed")
	assert.NotEmpty(t, res, "Response should not be empty")

	// ===== CRITICAL: Verify the request body does NOT contain tools field =====
	requestBody := string(capturedRequest)
	assert.NotContains(t, requestBody, `"tools"`, "Request MUST NOT contain 'tools' field when no tools provided")
	assert.NotContains(t, requestBody, `"tool_choice"`, "Request MUST NOT contain 'tool_choice' field when no tools provided")
	t.Logf("Request without tools does not contain 'tools' field: %v", !strings.Contains(requestBody, `"tools"`))
}
