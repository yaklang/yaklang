package hnsw

import (
	"fmt"
	"math"
	"math/rand"
	"strings"
	"testing"
	"time"

	"github.com/stretchr/testify/require"
	"github.com/yaklang/yaklang/common/ai/rag/hnsw/hnswspec"
	"github.com/yaklang/yaklang/common/log"
	"github.com/yaklang/yaklang/common/utils"
)

// generateRandomVector ç”ŸæˆæŒ‡å®šç»´åº¦çš„éšæœºå‘é‡
// ä½¿ç”¨æ›´å¤æ‚çš„æ•°å€¼èŒƒå›´å’Œåˆ†å¸ƒæ¥å¢åŠ å‘é‡è®¡ç®—å¤æ‚åº¦
func generateRandomVector(dimension int, rng *rand.Rand) []float32 {
	vector := make([]float32, dimension)
	for i := range vector {
		// ä½¿ç”¨æ›´å¤§çš„æ•°å€¼èŒƒå›´å’Œæ›´é«˜çš„ç²¾åº¦
		// èŒƒå›´ï¼š[-100.0, 100.0]ï¼Œå¢åŠ è´Ÿæ•°å’Œæ›´å¤§çš„æ•°å€¼
		vector[i] = (rng.Float32() - 0.5) * 200.0

		// æ·»åŠ ä¸€äº›å°æ•°ä½çš„å¤æ‚æ€§
		// é€šè¿‡é¢å¤–çš„éšæœºæ•°å¢åŠ ç²¾åº¦
		vector[i] += rng.Float32() * 0.001  // å¢åŠ åƒåˆ†ä½çš„éšæœºæ€§
		vector[i] += rng.Float32() * 0.0001 // å¢åŠ ä¸‡åˆ†ä½çš„éšæœºæ€§
	}
	return vector
}

// generateComplexRandomVector ç”Ÿæˆæ›´å¤æ‚çš„éšæœºå‘é‡ï¼ˆé«˜ç²¾åº¦ã€å¤šåˆ†å¸ƒï¼‰
func generateComplexRandomVector(dimension int, rng *rand.Rand) []float32 {
	vector := make([]float32, dimension)
	for i := range vector {
		switch i % 4 {
		case 0:
			// æ­£æ€åˆ†å¸ƒ (å‡å€¼=0, æ ‡å‡†å·®=10)
			vector[i] = float32(rng.NormFloat64() * 10.0)
		case 1:
			// æŒ‡æ•°åˆ†å¸ƒçš„è´Ÿå¯¹æ•° (èŒƒå›´çº¦ [0, 10])
			vector[i] = float32(-math.Log(rng.Float64()) * 2.0)
		case 2:
			// é«˜ç²¾åº¦å‡åŒ€åˆ†å¸ƒ [-50, 50]
			vector[i] = (rng.Float32() - 0.5) * 100.0
			// å¢åŠ å¤šå±‚ç²¾åº¦
			vector[i] += rng.Float32() * 0.01
			vector[i] += rng.Float32() * 0.001
			vector[i] += rng.Float32() * 0.0001
		case 3:
			// åˆ†æ®µå‡½æ•°ï¼š50%æ¦‚ç‡ä¸ºå¤§å€¼ï¼Œ50%æ¦‚ç‡ä¸ºå°å€¼
			if rng.Float32() < 0.5 {
				vector[i] = rng.Float32() * 100.0 // [0, 100]
			} else {
				vector[i] = -rng.Float32() * 100.0 // [-100, 0]
			}
			// æ·»åŠ å™ªå£°
			vector[i] += float32(rng.NormFloat64() * 0.1)
		}
	}
	return vector
}

// generateRealisticEmbeddingVector ç”Ÿæˆç±»ä¼¼çœŸå®embeddingçš„å‘é‡
func generateRealisticEmbeddingVector(dimension int, rng *rand.Rand) []float32 {
	vector := make([]float32, dimension)

	// æ¨¡æ‹ŸçœŸå®embeddingçš„ç‰¹å¾ï¼š
	// 1. å¤§éƒ¨åˆ†å€¼æ¥è¿‘0
	// 2. å°‘æ•°ç»´åº¦æœ‰æ˜¾è‘—å€¼
	// 3. ç¬¦åˆæŸç§åˆ†å¸ƒæ¨¡å¼

	for i := range vector {
		// 80%çš„ç»´åº¦ä¸ºå°å€¼ï¼ˆæ¥è¿‘0ï¼‰
		if rng.Float32() < 0.8 {
			vector[i] = float32(rng.NormFloat64() * 0.1) // å°å€¼ï¼Œæ ‡å‡†å·®0.1
		} else {
			// 20%çš„ç»´åº¦ä¸ºæ˜¾è‘—å€¼
			vector[i] = float32(rng.NormFloat64() * 2.0) // è¾ƒå¤§å€¼ï¼Œæ ‡å‡†å·®2.0
		}

		// æ·»åŠ ä¸€äº›ç¨€ç–æ€§ï¼š5%çš„ç»´åº¦è®¾ä¸º0
		if rng.Float32() < 0.05 {
			vector[i] = 0.0
		}

		// å¢åŠ ç²¾åº¦å¤æ‚åº¦
		vector[i] += float32(rng.NormFloat64() * 0.001)
	}

	// L2æ ‡å‡†åŒ–ï¼ˆå¯é€‰ï¼Œæ¨¡æ‹ŸçœŸå®embeddingï¼‰
	if rng.Float32() < 0.5 {
		norm := float32(0.0)
		for _, v := range vector {
			norm += v * v
		}
		norm = float32(math.Sqrt(float64(norm)))
		if norm > 0 {
			for i := range vector {
				vector[i] /= norm
			}
		}
	}

	return vector
}

// generateRandomNodes ç”ŸæˆæŒ‡å®šæ•°é‡çš„éšæœºèŠ‚ç‚¹
func generateRandomNodes(count int, dimension int, seed int64) []InputNode[int] {
	rng := rand.New(rand.NewSource(seed))
	nodes := make([]InputNode[int], count)
	for i := 0; i < count; i++ {
		nodes[i] = MakeInputNode(i+1, generateRandomVector(dimension, rng))
	}
	return nodes
}

// PerformanceResult æ€§èƒ½æµ‹è¯•ç»“æœç»“æ„
type PerformanceResult struct {
	InitialNodes     int
	AddedNodes       int
	Dimension        int
	InitDuration     time.Duration
	AddDuration      time.Duration
	AvgPerNode       time.Duration
	NodesPerSecond   float64
	ActualNodes      int
	SearchResults    int
	MemoryEstimateKB float64
}

// String æ ¼å¼åŒ–è¾“å‡ºæ€§èƒ½ç»“æœ
func (pr PerformanceResult) String() string {
	var sb strings.Builder
	sb.WriteString("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
	sb.WriteString("â•‘                    HNSW Performance Report                   â•‘\n")
	sb.WriteString("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n")
	sb.WriteString(fmt.Sprintf("â•‘ Initial Nodes      : %8d                               â•‘\n", pr.InitialNodes))
	sb.WriteString(fmt.Sprintf("â•‘ Added Nodes        : %8d                               â•‘\n", pr.AddedNodes))
	sb.WriteString(fmt.Sprintf("â•‘ Vector Dimension   : %8d                               â•‘\n", pr.Dimension))
	sb.WriteString("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n")
	if pr.InitialNodes > 0 {
		sb.WriteString(fmt.Sprintf("â•‘ Init Duration      : %15v                        â•‘\n", pr.InitDuration))
		sb.WriteString(fmt.Sprintf("â•‘ Init Avg/Node      : %15v                        â•‘\n", pr.InitDuration/time.Duration(pr.InitialNodes)))
	}
	sb.WriteString(fmt.Sprintf("â•‘ Add Duration       : %15v                        â•‘\n", pr.AddDuration))
	sb.WriteString(fmt.Sprintf("â•‘ Add Avg/Node       : %15v                        â•‘\n", pr.AvgPerNode))
	sb.WriteString(fmt.Sprintf("â•‘ Nodes/Second       : %15.2f                        â•‘\n", pr.NodesPerSecond))
	sb.WriteString("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n")
	sb.WriteString(fmt.Sprintf("â•‘ Actual Nodes       : %8d                               â•‘\n", pr.ActualNodes))
	sb.WriteString(fmt.Sprintf("â•‘ Search Results     : %8d                               â•‘\n", pr.SearchResults))
	sb.WriteString(fmt.Sprintf("â•‘ Memory Estimate    : %12.2f KB                       â•‘\n", pr.MemoryEstimateKB))
	sb.WriteString("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")
	return sb.String()
}

// measureAddPerformance æµ‹é‡å•æ¬¡Addæ“ä½œçš„æ€§èƒ½
func measureAddPerformance(t *testing.T, initialNodeCount int, addNodeCount int, dimension int) PerformanceResult {
	log.Infof("Starting performance test: initial=%d nodes, adding=%d nodes, dimension=%d",
		initialNodeCount, addNodeCount, dimension)

	result := PerformanceResult{
		InitialNodes: initialNodeCount,
		AddedNodes:   addNodeCount,
		Dimension:    dimension,
	}

	// åˆ›å»ºå›¾å¹¶é¢„å¡«å……åˆå§‹èŠ‚ç‚¹
	g := NewGraph[int]()
	g.Rng = rand.New(rand.NewSource(42)) // å›ºå®šéšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§

	// é¢„å¡«å……åˆå§‹èŠ‚ç‚¹
	if initialNodeCount > 0 {
		log.Infof("Pre-populating graph with %d initial nodes", initialNodeCount)
		initialNodes := generateRandomNodes(initialNodeCount, dimension, 42)

		start := time.Now()
		g.Add(initialNodes...)
		result.InitDuration = time.Since(start)
		log.Infof("Initial population took: %v (avg per node: %v)",
			result.InitDuration, result.InitDuration/time.Duration(initialNodeCount))
	}

	// ç”Ÿæˆè¦æ·»åŠ çš„æ–°èŠ‚ç‚¹
	newNodes := generateRandomNodes(addNodeCount, dimension, 43) // ä¸åŒçš„ç§å­é¿å…é‡å¤

	// æµ‹é‡æ·»åŠ æ–°èŠ‚ç‚¹çš„æ€§èƒ½
	log.Infof("Starting to add %d new nodes to existing graph", addNodeCount)
	start := time.Now()

	// å•æ¬¡Addæ“ä½œæ·»åŠ æ‰€æœ‰æ–°èŠ‚ç‚¹
	g.Add(newNodes...)

	result.AddDuration = time.Since(start)
	result.AvgPerNode = result.AddDuration / time.Duration(addNodeCount)
	result.NodesPerSecond = float64(addNodeCount) / result.AddDuration.Seconds()

	log.Infof("Add operation completed: total=%v, avg per node=%v", result.AddDuration, result.AvgPerNode)

	// éªŒè¯æ‰€æœ‰èŠ‚ç‚¹éƒ½è¢«æ­£ç¡®æ·»åŠ 
	for _, layer := range g.Layers {
		result.ActualNodes += len(layer.Nodes)
	}

	require.Greater(t, result.ActualNodes, 0, "Graph should contain nodes after adding")
	log.Infof("Total nodes in graph: %d", result.ActualNodes)

	// éªŒè¯æœç´¢åŠŸèƒ½æ­£å¸¸
	queryVec := generateRandomVector(dimension, rand.New(rand.NewSource(44)))
	results := g.Search(queryVec, 10)
	result.SearchResults = len(results)
	require.NotEmpty(t, results, "Search should return results")
	log.Infof("Search returned %d results", result.SearchResults)

	// ä¼°ç®—å†…å­˜ä½¿ç”¨
	totalConnections := 0
	for _, layer := range g.Layers {
		for _, node := range layer.Nodes {
			totalConnections += len(node.GetNeighbors())
		}
	}

	if result.ActualNodes > 0 {
		vectorMemory := dimension * 4 // float32
		avgConnections := float64(totalConnections) / float64(result.ActualNodes)
		connectionMemory := int(avgConnections * 8)
		metadataMemory := 50
		estimatedMemoryPerNode := vectorMemory + connectionMemory + metadataMemory
		result.MemoryEstimateKB = float64(estimatedMemoryPerNode*result.ActualNodes) / 1024
	}

	// è¾“å‡ºæ ¼å¼åŒ–çš„æ€§èƒ½æŒ‡æ ‡
	fmt.Print(result.String())

	return result
}

// TestHNSWPerformance1K æµ‹è¯•åœ¨1000ä¸ªèŠ‚ç‚¹åŸºç¡€ä¸Šæ·»åŠ å•ä¸ªèŠ‚ç‚¹çš„æ€§èƒ½
func TestHNSWPerformance1K(t *testing.T) {
	if utils.InGithubActions() {
		t.Skip("no performance test in ci")
		return
	}

	t.Run("Add1NodeTo1K_128D", func(t *testing.T) {
		measureAddPerformance(t, 1000, 1, 128) // 128ç»´å‘é‡
	})

	t.Run("Add10NodesTo1K_128D", func(t *testing.T) {
		measureAddPerformance(t, 1000, 10, 128)
	})

	t.Run("Add100NodesTo1K_128D", func(t *testing.T) {
		measureAddPerformance(t, 1000, 100, 128)
	})

	// 1024ç»´åº¦æµ‹è¯•
	t.Run("Add1NodeTo1K_1024D", func(t *testing.T) {
		measureAddPerformance(t, 1000, 1, 1024) // 1024ç»´å‘é‡
	})

	t.Run("Add10NodesTo1K_1024D", func(t *testing.T) {
		measureAddPerformance(t, 1000, 10, 1024)
	})

	t.Run("Add100NodesTo1K_1024D", func(t *testing.T) {
		measureAddPerformance(t, 1000, 100, 1024)
	})
}

// TestHNSWPerformance10K æµ‹è¯•åœ¨10000ä¸ªèŠ‚ç‚¹åŸºç¡€ä¸Šæ·»åŠ èŠ‚ç‚¹çš„æ€§èƒ½
func TestHNSWPerformance10K(t *testing.T) {
	if utils.InGithubActions() {
		t.Skip("no performance test in ci")
		return
	}

	t.Run("Add1NodeTo10K_128D", func(t *testing.T) {
		measureAddPerformance(t, 10000, 1, 128) // 128ç»´å‘é‡
	})

	t.Run("Add10NodesTo10K_128D", func(t *testing.T) {
		measureAddPerformance(t, 10000, 10, 128)
	})

	t.Run("Add100NodesTo10K_128D", func(t *testing.T) {
		measureAddPerformance(t, 10000, 100, 128)
	})

	// 1024ç»´åº¦æµ‹è¯•
	t.Run("Add1NodeTo10K_1024D", func(t *testing.T) {
		measureAddPerformance(t, 10000, 1, 1024) // 1024ç»´å‘é‡
	})

	t.Run("Add10NodesTo10K_1024D", func(t *testing.T) {
		measureAddPerformance(t, 10000, 10, 1024)
	})

	t.Run("Add100NodesTo10K_1024D", func(t *testing.T) {
		measureAddPerformance(t, 10000, 100, 1024)
	})
}

// BenchmarkHNSWAdd1K åŸºå‡†æµ‹è¯•ï¼šåœ¨1KèŠ‚ç‚¹åŸºç¡€ä¸Šæ·»åŠ å•ä¸ªèŠ‚ç‚¹
func BenchmarkHNSWAdd1K(b *testing.B) {
	if utils.InGithubActions() {
		b.Skip("no performance test in ci")
		return
	}
	// é¢„åˆ›å»ºå›¾å’Œåˆå§‹èŠ‚ç‚¹
	g := NewGraph[int]()
	g.Rng = rand.New(rand.NewSource(42))
	initialNodes := generateRandomNodes(1000, 128, 42)
	g.Add(initialNodes...)

	// å‡†å¤‡è¦æ·»åŠ çš„èŠ‚ç‚¹
	newNodes := generateRandomNodes(b.N, 128, 43)

	b.ResetTimer()
	b.ReportAllocs()

	for i := 0; i < b.N; i++ {
		g.Add(newNodes[i])
	}
}

// BenchmarkHNSWAdd1K_1024D åŸºå‡†æµ‹è¯•ï¼šåœ¨1KèŠ‚ç‚¹åŸºç¡€ä¸Šæ·»åŠ å•ä¸ª1024ç»´èŠ‚ç‚¹
func BenchmarkHNSWAdd1K_1024D(b *testing.B) {
	if utils.InGithubActions() {
		b.Skip("no performance test in ci")
		return
	}

	// é¢„åˆ›å»ºå›¾å’Œåˆå§‹èŠ‚ç‚¹
	g := NewGraph[int]()
	g.Rng = rand.New(rand.NewSource(42))
	initialNodes := generateRandomNodes(1000, 1024, 42)
	g.Add(initialNodes...)

	// å‡†å¤‡è¦æ·»åŠ çš„èŠ‚ç‚¹
	newNodes := generateRandomNodes(b.N, 1024, 43)

	b.ResetTimer()
	b.ReportAllocs()

	for i := 0; i < b.N; i++ {
		g.Add(newNodes[i])
	}
}

// BenchmarkHNSWAdd10K åŸºå‡†æµ‹è¯•ï¼šåœ¨10KèŠ‚ç‚¹åŸºç¡€ä¸Šæ·»åŠ å•ä¸ªèŠ‚ç‚¹
func BenchmarkHNSWAdd10K(b *testing.B) {
	if utils.InGithubActions() {
		b.Skip("no performance test in ci")
		return
	}

	// é¢„åˆ›å»ºå›¾å’Œåˆå§‹èŠ‚ç‚¹
	g := NewGraph[int]()
	g.Rng = rand.New(rand.NewSource(42))
	initialNodes := generateRandomNodes(10000, 128, 42)
	g.Add(initialNodes...)

	// å‡†å¤‡è¦æ·»åŠ çš„èŠ‚ç‚¹
	newNodes := generateRandomNodes(b.N, 128, 43)

	b.ResetTimer()
	b.ReportAllocs()

	for i := 0; i < b.N; i++ {
		g.Add(newNodes[i])
	}
}

// BenchmarkHNSWAdd10K_1024D åŸºå‡†æµ‹è¯•ï¼šåœ¨10KèŠ‚ç‚¹åŸºç¡€ä¸Šæ·»åŠ å•ä¸ª1024ç»´èŠ‚ç‚¹
func BenchmarkHNSWAdd10K_1024D(b *testing.B) {
	if utils.InGithubActions() {
		b.Skip("no performance test in ci")
		return
	}

	// é¢„åˆ›å»ºå›¾å’Œåˆå§‹èŠ‚ç‚¹
	g := NewGraph[int]()
	g.Rng = rand.New(rand.NewSource(42))
	initialNodes := generateRandomNodes(10000, 1024, 42)
	g.Add(initialNodes...)

	// å‡†å¤‡è¦æ·»åŠ çš„èŠ‚ç‚¹
	newNodes := generateRandomNodes(b.N, 1024, 43)

	b.ResetTimer()
	b.ReportAllocs()

	for i := 0; i < b.N; i++ {
		g.Add(newNodes[i])
	}
}

// TestHNSWScalabilityAnalysis åˆ†æHNSWçš„å¯æ‰©å±•æ€§
func TestHNSWScalabilityAnalysis(t *testing.T) {
	if utils.InGithubActions() {
		t.Skip("no performance test in ci")
		return
	}

	if testing.Short() {
		t.Skip("Skipping scalability analysis in short mode")
	}

	sizes := []int{100, 500, 1000, 2000, 5000, 10000}
	dimension := 128

	fmt.Println("\n=== HNSW Scalability Analysis ===")
	fmt.Printf("%-8s %-12s %-15s %-12s\n", "Size", "Duration", "Avg per Node", "Nodes/sec")
	fmt.Println("----------------------------------------")

	for _, size := range sizes {
		// åˆ›å»ºæ–°å›¾
		g := NewGraph[int]()
		g.Rng = rand.New(rand.NewSource(42))

		// ç”ŸæˆèŠ‚ç‚¹
		nodes := generateRandomNodes(size, dimension, 42)

		// æµ‹é‡æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹çš„æ—¶é—´
		start := time.Now()
		g.Add(nodes...)
		duration := time.Since(start)

		avgPerNode := duration / time.Duration(size)
		nodesPerSec := float64(size) / duration.Seconds()

		fmt.Printf("%-8d %-12v %-15v %-12.2f\n",
			size, duration, avgPerNode, nodesPerSec)

		// éªŒè¯å›¾çš„åŸºæœ¬åŠŸèƒ½
		queryVec := generateRandomVector(dimension, rand.New(rand.NewSource(44)))
		results := g.Search(queryVec, 5)
		require.NotEmpty(t, results, "Search should return results for size %d", size)
	}

	fmt.Println("====================================")
}

// TestHNSWScalabilityAnalysis1024D åˆ†æHNSWåœ¨1024ç»´åº¦ä¸‹çš„å¯æ‰©å±•æ€§
func TestHNSWScalabilityAnalysis1024D(t *testing.T) {
	if utils.InGithubActions() {
		t.Skip("no performance test in ci")
		return
	}

	if testing.Short() {
		t.Skip("Skipping 1024D scalability analysis in short mode")
	}

	sizes := []int{100, 500, 1000, 2000, 5000}
	dimension := 1024

	fmt.Println("\n=== HNSW 1024D Scalability Analysis ===")
	fmt.Printf("%-8s %-12s %-15s %-12s %-15s\n", "Size", "Duration", "Avg per Node", "Nodes/sec", "Memory Est(KB)")
	fmt.Println("----------------------------------------------------------")

	for _, size := range sizes {
		// åˆ›å»ºæ–°å›¾
		g := NewGraph[int]()
		g.Rng = rand.New(rand.NewSource(42))

		// ç”ŸæˆèŠ‚ç‚¹
		nodes := generateRandomNodes(size, dimension, 42)

		// æµ‹é‡æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹çš„æ—¶é—´
		start := time.Now()
		g.Add(nodes...)
		duration := time.Since(start)

		avgPerNode := duration / time.Duration(size)
		nodesPerSec := float64(size) / duration.Seconds()

		// ä¼°ç®—å†…å­˜ä½¿ç”¨
		totalNodes := 0
		totalConnections := 0
		for _, layer := range g.Layers {
			totalNodes += len(layer.Nodes)
			for _, node := range layer.Nodes {
				totalConnections += len(node.GetNeighbors())
			}
		}

		// ç²—ç•¥å†…å­˜ä¼°ç®— (å‘é‡ + è¿æ¥ + å…ƒæ•°æ®)
		vectorMemory := dimension * 4 // float32
		avgConnections := float64(totalConnections) / float64(totalNodes)
		connectionMemory := int(avgConnections * 8) // å‡è®¾è¿æ¥å 8å­—èŠ‚
		metadataMemory := 50
		estimatedMemoryPerNode := vectorMemory + connectionMemory + metadataMemory
		totalEstimatedMemoryKB := float64(estimatedMemoryPerNode*totalNodes) / 1024

		fmt.Printf("%-8d %-12v %-15v %-12.2f %-15.2f\n",
			size, duration, avgPerNode, nodesPerSec, totalEstimatedMemoryKB)

		// éªŒè¯å›¾çš„åŸºæœ¬åŠŸèƒ½
		queryVec := generateRandomVector(dimension, rand.New(rand.NewSource(44)))
		results := g.Search(queryVec, 5)
		require.NotEmpty(t, results, "Search should return results for size %d", size)

		log.Infof("1024D test completed for size %d: %v avg per node, %.2f nodes/sec",
			size, avgPerNode, nodesPerSec)
	}

	fmt.Println("======================================================")
}

// TestHNSWMemoryUsageEstimate ä¼°ç®—å†…å­˜ä½¿ç”¨æƒ…å†µ
func TestHNSWMemoryUsageEstimate(t *testing.T) {
	if utils.InGithubActions() {
		t.Skip("no performance test in ci")
		return
	}

	if testing.Short() {
		t.Skip("Skipping memory usage test in short mode")
	}

	// ä½¿ç”¨è¾ƒå°çš„æ•°æ®é›†æ¥ä¼°ç®—å†…å­˜ä½¿ç”¨
	sizes := []int{100, 500, 1000}
	dimension := 128

	fmt.Println("\n=== HNSW Memory Usage Estimation ===")

	for _, size := range sizes {
		g := NewGraph[int]()
		g.Rng = rand.New(rand.NewSource(42))

		nodes := generateRandomNodes(size, dimension, 42)
		g.Add(nodes...)

		// ç»Ÿè®¡å±‚çº§å’ŒèŠ‚ç‚¹ä¿¡æ¯
		totalNodes := 0
		totalConnections := 0
		for layerIdx, layer := range g.Layers {
			nodeCount := len(layer.Nodes)
			connectionCount := 0
			for _, node := range layer.Nodes {
				connectionCount += len(node.GetNeighbors())
			}

			totalNodes += nodeCount
			totalConnections += connectionCount

			fmt.Printf("Size %d - Layer %d: %d nodes, %d connections\n",
				size, layerIdx, nodeCount, connectionCount)
		}

		avgConnectionsPerNode := float64(totalConnections) / float64(totalNodes)
		fmt.Printf("Size %d - Total: %d nodes, %d connections, avg %.2f connections/node\n",
			size, totalNodes, totalConnections, avgConnectionsPerNode)

		// ä¼°ç®—æ¯ä¸ªèŠ‚ç‚¹çš„å†…å­˜å ç”¨ï¼ˆç²—ç•¥ä¼°ç®—ï¼‰
		// å‘é‡: dimension * 4 bytes (float32)
		// è¿æ¥: avgConnectionsPerNode * 8 bytes (å‡è®¾keyä¸ºint64)
		// å…¶ä»–å…ƒæ•°æ®: ~50 bytes
		vectorMemory := dimension * 4
		connectionMemory := int(avgConnectionsPerNode * 8)
		metadataMemory := 50
		estimatedMemoryPerNode := vectorMemory + connectionMemory + metadataMemory
		totalEstimatedMemory := estimatedMemoryPerNode * totalNodes

		fmt.Printf("Size %d - Estimated memory per node: %d bytes, total: %.2f KB\n",
			size, estimatedMemoryPerNode, float64(totalEstimatedMemory)/1024)
		fmt.Println()
	}

	fmt.Println("=====================================")
}

// TestHNSWDimensionComparison æ¯”è¾ƒä¸åŒç»´åº¦ä¸‹çš„æ€§èƒ½
func TestHNSWDimensionComparison(t *testing.T) {
	if utils.InGithubActions() {
		t.Skip("no performance test in ci")
		return
	}

	if testing.Short() {
		t.Skip("Skipping dimension comparison test in short mode")
	}

	dimensions := []int{128, 256, 512, 1024}
	nodeCount := 1000

	fmt.Println("\n=== HNSW Dimension Performance Comparison ===")
	fmt.Printf("%-10s %-12s %-15s %-12s %-15s\n", "Dimension", "Duration", "Avg per Node", "Nodes/sec", "Memory Est(KB)")
	fmt.Println("-------------------------------------------------------------")

	for _, dim := range dimensions {
		// åˆ›å»ºæ–°å›¾
		g := NewGraph[int]()
		g.Rng = rand.New(rand.NewSource(42))

		// ç”ŸæˆèŠ‚ç‚¹
		nodes := generateRandomNodes(nodeCount, dim, 42)

		// æµ‹é‡æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹çš„æ—¶é—´
		start := time.Now()
		g.Add(nodes...)
		duration := time.Since(start)

		avgPerNode := duration / time.Duration(nodeCount)
		nodesPerSec := float64(nodeCount) / duration.Seconds()

		// ä¼°ç®—å†…å­˜ä½¿ç”¨
		totalNodes := 0
		totalConnections := 0
		for _, layer := range g.Layers {
			totalNodes += len(layer.Nodes)
			for _, node := range layer.Nodes {
				totalConnections += len(node.GetNeighbors())
			}
		}

		// ç²—ç•¥å†…å­˜ä¼°ç®—
		vectorMemory := dim * 4 // float32
		avgConnections := float64(totalConnections) / float64(totalNodes)
		connectionMemory := int(avgConnections * 8)
		metadataMemory := 50
		estimatedMemoryPerNode := vectorMemory + connectionMemory + metadataMemory
		totalEstimatedMemoryKB := float64(estimatedMemoryPerNode*totalNodes) / 1024

		fmt.Printf("%-10d %-12v %-15v %-12.2f %-15.2f\n",
			dim, duration, avgPerNode, nodesPerSec, totalEstimatedMemoryKB)

		// éªŒè¯æœç´¢åŠŸèƒ½
		queryVec := generateRandomVector(dim, rand.New(rand.NewSource(44)))
		results := g.Search(queryVec, 5)
		require.NotEmpty(t, results, "Search should return results for dimension %d", dim)

		log.Infof("Dimension %d test completed: %v avg per node, %.2f nodes/sec",
			dim, avgPerNode, nodesPerSec)
	}

	fmt.Println("=============================================================")
}

// TestHNSW10KDataDetailedAnalysis é’ˆå¯¹10Kæ•°æ®çš„è¯¦ç»†æ€§èƒ½åˆ†æ
func TestHNSW10KDataDetailedAnalysis(t *testing.T) {
	if utils.InGithubActions() {
		t.Skip("no performance test in ci")
		return
	}

	if testing.Short() {
		t.Skip("Skipping 10K detailed analysis in short mode")
	}

	dimensions := []int{128, 512, 1024}

	fmt.Println("\n" + strings.Repeat("=", 80))
	fmt.Println("                    HNSW 10K Data Detailed Performance Analysis")
	fmt.Println(strings.Repeat("=", 80))

	var allResults []PerformanceResult

	for _, dim := range dimensions {
		fmt.Printf("\nğŸ” Testing Dimension: %d\n", dim)
		fmt.Println(strings.Repeat("-", 50))

		// æµ‹è¯•ä¸åŒçš„æ·»åŠ åœºæ™¯
		scenarios := []struct {
			name         string
			initialNodes int
			addNodes     int
		}{
			{"Build 10K from scratch", 0, 10000},
			{"Add 1 to 10K", 10000, 1},
			{"Add 10 to 10K", 10000, 10},
			{"Add 100 to 10K", 10000, 100},
		}

		for _, scenario := range scenarios {
			fmt.Printf("\nğŸ“Š Scenario: %s\n", scenario.name)
			result := measureAddPerformance(t, scenario.initialNodes, scenario.addNodes, dim)
			allResults = append(allResults, result)

			// æ€§èƒ½è¯„ä¼°
			if result.AvgPerNode > 10*time.Millisecond {
				log.Warnf("Performance warning: avg time per node (%v) exceeds 10ms threshold", result.AvgPerNode)
			}
			if result.NodesPerSecond < 100 {
				log.Warnf("Throughput warning: processing rate (%.2f nodes/sec) is below 100 nodes/sec", result.NodesPerSecond)
			}
		}
	}

	// ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
	fmt.Println("\n" + strings.Repeat("=", 80))
	fmt.Println("                              Summary Report")
	fmt.Println(strings.Repeat("=", 80))

	fmt.Printf("%-25s %-8s %-12s %-15s %-12s %-15s\n",
		"Scenario", "Dim", "Add Nodes", "Duration", "Avg/Node", "Memory(KB)")
	fmt.Println(strings.Repeat("-", 100))

	for _, result := range allResults {
		scenarioName := ""
		if result.InitialNodes == 0 {
			scenarioName = "Build from scratch"
		} else {
			scenarioName = fmt.Sprintf("Add %d to %dk", result.AddedNodes, result.InitialNodes/1000)
		}

		fmt.Printf("%-25s %-8d %-12d %-15v %-12v %-15.1f\n",
			scenarioName, result.Dimension, result.AddedNodes,
			result.AddDuration, result.AvgPerNode, result.MemoryEstimateKB)
	}

	fmt.Println(strings.Repeat("=", 80))
}

// TestHNSWStressTest10K 10Kæ•°æ®å‹åŠ›æµ‹è¯•
func TestHNSWStressTest10K(t *testing.T) {
	if utils.InGithubActions() {
		t.Skip("no performance test in ci")
		return
	}

	if testing.Short() {
		t.Skip("Skipping 10K stress test in short mode")
	}

	fmt.Println("\nğŸš€ HNSW 10K Stress Test")
	fmt.Println("Testing incremental additions with performance monitoring...")

	g := NewGraph[int]()
	g.Rng = rand.New(rand.NewSource(42))
	dimension := 512 // ä¸­ç­‰ç»´åº¦

	// åˆ†æ‰¹æ·»åŠ èŠ‚ç‚¹ï¼Œç›‘æ§æ€§èƒ½å˜åŒ–
	batchSizes := []int{1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000}

	fmt.Printf("\n%-8s %-8s %-12s %-15s %-12s %-15s\n",
		"Total", "Batch", "Duration", "Avg/Node", "Nodes/sec", "Memory(KB)")
	fmt.Println(strings.Repeat("-", 80))

	var cumulativeResults []PerformanceResult

	for i, targetSize := range batchSizes {
		currentSize := 0
		if i > 0 {
			currentSize = batchSizes[i-1]
		}

		batchSize := targetSize - currentSize
		newNodes := generateRandomNodes(batchSize, dimension, int64(42+i))

		start := time.Now()
		g.Add(newNodes...)
		duration := time.Since(start)

		avgPerNode := duration / time.Duration(batchSize)
		nodesPerSec := float64(batchSize) / duration.Seconds()

		// è®¡ç®—å†…å­˜ä¼°ç®—
		totalNodes := 0
		totalConnections := 0
		for _, layer := range g.Layers {
			totalNodes += len(layer.Nodes)
			for _, node := range layer.Nodes {
				totalConnections += len(node.GetNeighbors())
			}
		}

		var memoryKB float64
		if totalNodes > 0 {
			vectorMemory := dimension * 4
			avgConnections := float64(totalConnections) / float64(totalNodes)
			connectionMemory := int(avgConnections * 8)
			metadataMemory := 50
			estimatedMemoryPerNode := vectorMemory + connectionMemory + metadataMemory
			memoryKB = float64(estimatedMemoryPerNode*totalNodes) / 1024
		}

		fmt.Printf("%-8d %-8d %-12v %-15v %-12.2f %-15.1f\n",
			targetSize, batchSize, duration, avgPerNode, nodesPerSec, memoryKB)

		result := PerformanceResult{
			InitialNodes:     currentSize,
			AddedNodes:       batchSize,
			Dimension:        dimension,
			AddDuration:      duration,
			AvgPerNode:       avgPerNode,
			NodesPerSecond:   nodesPerSec,
			ActualNodes:      totalNodes,
			MemoryEstimateKB: memoryKB,
		}
		cumulativeResults = append(cumulativeResults, result)

		// æ€§èƒ½è­¦å‘Š
		if avgPerNode > 20*time.Millisecond {
			log.Warnf("âš ï¸  Performance degradation detected at %d nodes: %v avg per node", targetSize, avgPerNode)
		}

		// éªŒè¯æœç´¢åŠŸèƒ½
		queryVec := generateRandomVector(dimension, rand.New(rand.NewSource(44+int64(i))))
		results := g.Search(queryVec, 10)
		require.NotEmpty(t, results, "Search should return results at %d nodes", targetSize)
	}

	// åˆ†ææ€§èƒ½è¶‹åŠ¿
	fmt.Println("\nğŸ“ˆ Performance Trend Analysis:")
	for i := 1; i < len(cumulativeResults); i++ {
		prev := cumulativeResults[i-1]
		curr := cumulativeResults[i]

		perfChange := (curr.AvgPerNode.Nanoseconds() - prev.AvgPerNode.Nanoseconds()) * 100 / prev.AvgPerNode.Nanoseconds()
		fmt.Printf("   %d â†’ %d nodes: Performance change: %+.1f%%\n",
			prev.InitialNodes+prev.AddedNodes, curr.InitialNodes+curr.AddedNodes, float64(perfChange))
	}

	fmt.Println(strings.Repeat("=", 70))
}

// TestVectorComplexityImpact æµ‹è¯•ä¸åŒå‘é‡å¤æ‚åº¦å¯¹HNSWæ€§èƒ½çš„å½±å“
func TestVectorComplexityImpact(t *testing.T) {
	if utils.InGithubActions() {
		t.Skip("no performance test in ci")
		return
	}

	if testing.Short() {
		t.Skip("Skipping vector complexity impact test in short mode")
	}

	nodeCount := 2000 // ä½¿ç”¨ä¸­ç­‰è§„æ¨¡è¿›è¡Œå¿«é€Ÿå¯¹æ¯”
	dimension := 512
	addNodes := 50

	fmt.Println("\n" + strings.Repeat("=", 80))
	fmt.Println("                Vector Complexity Impact on HNSW Performance")
	fmt.Println(strings.Repeat("=", 80))

	// å®šä¹‰ä¸åŒçš„å‘é‡ç”Ÿæˆç­–ç•¥
	strategies := []struct {
		name      string
		generator func(int, *rand.Rand) []float32
	}{
		{"Simple [0,1]", func(dim int, rng *rand.Rand) []float32 {
			vector := make([]float32, dim)
			for i := range vector {
				vector[i] = rng.Float32() // åŸå§‹ç®€å•ç­–ç•¥
			}
			return vector
		}},
		{"Enhanced [-100,100]", generateRandomVector},             // å¢å¼ºçš„èŒƒå›´å’Œç²¾åº¦
		{"Complex Multi-Dist", generateComplexRandomVector},       // å¤šåˆ†å¸ƒå¤æ‚å‘é‡
		{"Realistic Embedding", generateRealisticEmbeddingVector}, // çœŸå®embeddingé£æ ¼
	}

	fmt.Printf("\n%-20s %-15s %-15s %-12s %-15s %-15s\n",
		"Strategy", "Build Time", "Add Time", "Avg/Node", "Nodes/sec", "Memory(KB)")
	fmt.Println(strings.Repeat("-", 100))

	var allResults []struct {
		strategy string
		result   PerformanceResult
	}

	for _, strategy := range strategies {
		fmt.Printf("\nğŸ” Testing Strategy: %s\n", strategy.name)

		// åˆ›å»ºå›¾å¹¶ä½¿ç”¨æŒ‡å®šçš„å‘é‡ç”Ÿæˆç­–ç•¥
		g := NewGraph[int]()
		g.Rng = rand.New(rand.NewSource(42))

		// ç”Ÿæˆåˆå§‹èŠ‚ç‚¹
		rng := rand.New(rand.NewSource(42))
		initialNodes := make([]InputNode[int], nodeCount)
		for i := 0; i < nodeCount; i++ {
			initialNodes[i] = MakeInputNode(i+1, strategy.generator(dimension, rng))
		}

		// æµ‹é‡æ„å»ºå›¾çš„æ—¶é—´
		start := time.Now()
		g.Add(initialNodes...)
		buildDuration := time.Since(start)

		// ç”Ÿæˆè¦æ·»åŠ çš„æ–°èŠ‚ç‚¹
		rng = rand.New(rand.NewSource(43))
		newNodes := make([]InputNode[int], addNodes)
		for i := 0; i < addNodes; i++ {
			newNodes[i] = MakeInputNode(nodeCount+i+1, strategy.generator(dimension, rng))
		}

		// æµ‹é‡æ·»åŠ æ–°èŠ‚ç‚¹çš„æ—¶é—´
		start = time.Now()
		g.Add(newNodes...)
		addDuration := time.Since(start)

		// è®¡ç®—æ€§èƒ½æŒ‡æ ‡
		avgPerNode := addDuration / time.Duration(addNodes)
		nodesPerSec := float64(addNodes) / addDuration.Seconds()

		// ä¼°ç®—å†…å­˜ä½¿ç”¨
		totalNodes := 0
		totalConnections := 0
		for _, layer := range g.Layers {
			totalNodes += len(layer.Nodes)
			for _, node := range layer.Nodes {
				totalConnections += len(node.GetNeighbors())
			}
		}

		var memoryKB float64
		if totalNodes > 0 {
			vectorMemory := dimension * 4
			avgConnections := float64(totalConnections) / float64(totalNodes)
			connectionMemory := int(avgConnections * 8)
			metadataMemory := 50
			estimatedMemoryPerNode := vectorMemory + connectionMemory + metadataMemory
			memoryKB = float64(estimatedMemoryPerNode*totalNodes) / 1024
		}

		result := PerformanceResult{
			InitialNodes:     nodeCount,
			AddedNodes:       addNodes,
			Dimension:        dimension,
			InitDuration:     buildDuration,
			AddDuration:      addDuration,
			AvgPerNode:       avgPerNode,
			NodesPerSecond:   nodesPerSec,
			ActualNodes:      totalNodes,
			MemoryEstimateKB: memoryKB,
		}

		allResults = append(allResults, struct {
			strategy string
			result   PerformanceResult
		}{strategy.name, result})

		fmt.Printf("%-20s %-15v %-15v %-12v %-15.2f %-15.1f\n",
			strategy.name, buildDuration, addDuration, avgPerNode, nodesPerSec, memoryKB)

		// éªŒè¯æœç´¢åŠŸèƒ½
		queryVec := strategy.generator(dimension, rand.New(rand.NewSource(44)))
		results := g.Search(queryVec, 10)
		require.NotEmpty(t, results, "Search should return results for strategy %s", strategy.name)

		log.Infof("Strategy '%s' completed: build=%v, add=%v, nodes/sec=%.2f",
			strategy.name, buildDuration, addDuration, nodesPerSec)
	}

	// æ€§èƒ½å¯¹æ¯”åˆ†æ
	fmt.Println("\n" + strings.Repeat("=", 80))
	fmt.Println("                           Performance Comparison")
	fmt.Println(strings.Repeat("=", 80))

	if len(allResults) > 1 {
		baseline := allResults[0] // ä»¥ç¬¬ä¸€ä¸ªï¼ˆç®€å•ç­–ç•¥ï¼‰ä¸ºåŸºå‡†
		fmt.Printf("\nBaseline (Simple [0,1]): %.2f nodes/sec\n", baseline.result.NodesPerSecond)
		fmt.Println(strings.Repeat("-", 60))

		for i := 1; i < len(allResults); i++ {
			current := allResults[i]
			speedRatio := current.result.NodesPerSecond / baseline.result.NodesPerSecond
			timeRatio := float64(current.result.AvgPerNode.Nanoseconds()) / float64(baseline.result.AvgPerNode.Nanoseconds())

			fmt.Printf("%-20s: %.2fx speed, %.2fx time complexity\n",
				current.strategy, speedRatio, timeRatio)

			if speedRatio < 0.7 {
				log.Warnf("Strategy '%s' significantly slower than baseline: %.2fx", current.strategy, speedRatio)
			} else if speedRatio > 1.3 {
				log.Infof("Strategy '%s' significantly faster than baseline: %.2fx", current.strategy, speedRatio)
			}
		}
	}

	fmt.Println(strings.Repeat("=", 80))
}

// TestFloatPrecisionImpact æµ‹è¯•æµ®ç‚¹æ•°ç²¾åº¦å¯¹HNSWæ€§èƒ½çš„å½±å“
func TestFloatPrecisionImpact(t *testing.T) {
	if utils.InGithubActions() {
		t.Skip("no performance test in ci")
		return
	}

	if testing.Short() {
		t.Skip("Skipping float precision impact test in short mode")
	}

	nodeCount := 1500 // ç¨å°çš„è§„æ¨¡ç”¨äºå¿«é€Ÿæµ‹è¯•
	dimension := 256
	addNodes := 30

	fmt.Println("\n" + strings.Repeat("=", 90))
	fmt.Println("                    Float Precision Impact on HNSW Performance")
	fmt.Println(strings.Repeat("=", 90))

	// å®šä¹‰ä¸åŒç²¾åº¦çš„å‘é‡ç”Ÿæˆç­–ç•¥
	precisionStrategies := []struct {
		name      string
		generator func(int, *rand.Rand) []float32
	}{
		{"Integer Only", func(dim int, rng *rand.Rand) []float32 {
			vector := make([]float32, dim)
			for i := range vector {
				vector[i] = float32(rng.Intn(201) - 100) // [-100, 100] æ•´æ•°
			}
			return vector
		}},
		{"1 Decimal", func(dim int, rng *rand.Rand) []float32 {
			vector := make([]float32, dim)
			for i := range vector {
				vector[i] = float32(rng.Intn(2001)-1000) / 10.0 // [-100.0, 100.0] ä¸€ä½å°æ•°
			}
			return vector
		}},
		{"2 Decimals", func(dim int, rng *rand.Rand) []float32 {
			vector := make([]float32, dim)
			for i := range vector {
				vector[i] = float32(rng.Intn(20001)-10000) / 100.0 // [-100.00, 100.00] ä¸¤ä½å°æ•°
			}
			return vector
		}},
		{"3 Decimals", func(dim int, rng *rand.Rand) []float32 {
			vector := make([]float32, dim)
			for i := range vector {
				vector[i] = float32(rng.Intn(200001)-100000) / 1000.0 // [-100.000, 100.000] ä¸‰ä½å°æ•°
			}
			return vector
		}},
		{"High Precision", func(dim int, rng *rand.Rand) []float32 {
			vector := make([]float32, dim)
			for i := range vector {
				// ä½¿ç”¨å½“å‰çš„"å¢å¼º"ç­–ç•¥ï¼ˆå¤šå±‚å°æ•°ä½ï¼‰
				vector[i] = (rng.Float32() - 0.5) * 200.0
				vector[i] += rng.Float32() * 0.001
				vector[i] += rng.Float32() * 0.0001
			}
			return vector
		}},
		{"Ultra Precision", func(dim int, rng *rand.Rand) []float32 {
			vector := make([]float32, dim)
			for i := range vector {
				// æé«˜ç²¾åº¦ï¼ˆæ›´å¤šå°æ•°ä½ï¼‰
				vector[i] = (rng.Float32() - 0.5) * 200.0
				vector[i] += rng.Float32() * 0.001
				vector[i] += rng.Float32() * 0.0001
				vector[i] += rng.Float32() * 0.00001
				vector[i] += rng.Float32() * 0.000001
				vector[i] += rng.Float32() * 0.0000001
			}
			return vector
		}},
		{"Simple [0,1]", func(dim int, rng *rand.Rand) []float32 {
			vector := make([]float32, dim)
			for i := range vector {
				vector[i] = rng.Float32() // åŸºå‡†å¯¹æ¯”
			}
			return vector
		}},
	}

	fmt.Printf("\n%-15s %-15s %-15s %-12s %-15s %-20s\n",
		"Precision", "Build Time", "Add Time", "Avg/Node", "Nodes/sec", "Sample Vector[0]")
	fmt.Println(strings.Repeat("-", 100))

	var allResults []struct {
		strategy string
		result   PerformanceResult
		sample   float32
	}

	for _, strategy := range precisionStrategies {
		fmt.Printf("\nğŸ” Testing Precision: %s\n", strategy.name)

		// åˆ›å»ºå›¾å¹¶ä½¿ç”¨æŒ‡å®šçš„ç²¾åº¦ç­–ç•¥
		g := NewGraph[int]()
		g.Rng = rand.New(rand.NewSource(42))

		// ç”Ÿæˆåˆå§‹èŠ‚ç‚¹
		rng := rand.New(rand.NewSource(42))
		initialNodes := make([]InputNode[int], nodeCount)
		var sampleVector []float32
		for i := 0; i < nodeCount; i++ {
			vec := strategy.generator(dimension, rng)
			if i == 0 {
				sampleVector = vec // ä¿å­˜ç¬¬ä¸€ä¸ªå‘é‡ä½œä¸ºæ ·æœ¬
			}
			initialNodes[i] = MakeInputNode(i+1, vec)
		}

		// æµ‹é‡æ„å»ºå›¾çš„æ—¶é—´
		start := time.Now()
		g.Add(initialNodes...)
		buildDuration := time.Since(start)

		// ç”Ÿæˆè¦æ·»åŠ çš„æ–°èŠ‚ç‚¹
		rng = rand.New(rand.NewSource(43))
		newNodes := make([]InputNode[int], addNodes)
		for i := 0; i < addNodes; i++ {
			newNodes[i] = MakeInputNode(nodeCount+i+1, strategy.generator(dimension, rng))
		}

		// æµ‹é‡æ·»åŠ æ–°èŠ‚ç‚¹çš„æ—¶é—´
		start = time.Now()
		g.Add(newNodes...)
		addDuration := time.Since(start)

		// è®¡ç®—æ€§èƒ½æŒ‡æ ‡
		avgPerNode := addDuration / time.Duration(addNodes)
		nodesPerSec := float64(addNodes) / addDuration.Seconds()

		result := PerformanceResult{
			InitialNodes:   nodeCount,
			AddedNodes:     addNodes,
			Dimension:      dimension,
			InitDuration:   buildDuration,
			AddDuration:    addDuration,
			AvgPerNode:     avgPerNode,
			NodesPerSecond: nodesPerSec,
		}

		allResults = append(allResults, struct {
			strategy string
			result   PerformanceResult
			sample   float32
		}{strategy.name, result, sampleVector[0]})

		fmt.Printf("%-15s %-15v %-15v %-12v %-15.2f %-20.6f\n",
			strategy.name, buildDuration, addDuration, avgPerNode, nodesPerSec, sampleVector[0])

		// éªŒè¯æœç´¢åŠŸèƒ½
		queryVec := strategy.generator(dimension, rand.New(rand.NewSource(44)))
		results := g.Search(queryVec, 5)
		require.NotEmpty(t, results, "Search should return results for precision %s", strategy.name)

		log.Infof("Precision '%s' completed: build=%v, add=%v, nodes/sec=%.2f, sample=%.6f",
			strategy.name, buildDuration, addDuration, nodesPerSec, sampleVector[0])
	}

	// ç²¾åº¦å¯¹æ¯”åˆ†æ
	fmt.Println("\n" + strings.Repeat("=", 90))
	fmt.Println("                           Precision Performance Analysis")
	fmt.Println(strings.Repeat("=", 90))

	if len(allResults) > 0 {
		// æ‰¾åˆ°åŸºå‡†ï¼ˆSimple [0,1]ï¼‰
		var baseline *struct {
			strategy string
			result   PerformanceResult
			sample   float32
		}
		for i := range allResults {
			if allResults[i].strategy == "Simple [0,1]" {
				baseline = &allResults[i]
				break
			}
		}

		if baseline != nil {
			fmt.Printf("\nBaseline (Simple [0,1]): %.2f nodes/sec\n", baseline.result.NodesPerSecond)
			fmt.Println(strings.Repeat("-", 70))

			for _, current := range allResults {
				if current.strategy == "Simple [0,1]" {
					continue
				}

				speedRatio := current.result.NodesPerSecond / baseline.result.NodesPerSecond
				timeRatio := float64(current.result.AvgPerNode.Nanoseconds()) / float64(baseline.result.AvgPerNode.Nanoseconds())

				fmt.Printf("%-15s: %.2fx speed, %.2fx time, sample=%.6f\n",
					current.strategy, speedRatio, timeRatio, current.sample)

				// æ€§èƒ½è­¦å‘Š
				if speedRatio < 0.8 {
					log.Warnf("Precision '%s' significantly slower: %.2fx", current.strategy, speedRatio)
				} else if speedRatio > 1.2 {
					log.Infof("Precision '%s' significantly faster: %.2fx", current.strategy, speedRatio)
				}
			}
		}
	}

	fmt.Println(strings.Repeat("=", 90))
}

// TestHNSWMParameterImpact æµ‹è¯•ä¸åŒMå‚æ•°å¯¹HNSWæ€§èƒ½çš„å½±å“
// åŸºäºHNSWè®ºæ–‡çš„ç†è®ºå¤æ‚åº¦åˆ†æ
func TestHNSWMParameterImpact(t *testing.T) {
	if utils.InGithubActions() {
		t.Skip("no performance test in ci")
		return
	}

	if testing.Short() {
		t.Skip("Skipping M parameter impact test in short mode")
	}

	nodeCount := 1000 // å›ºå®šèŠ‚ç‚¹æ•°é‡ï¼Œä¸“æ³¨äºMå‚æ•°å½±å“
	dimension := 512
	addNodes := 50

	fmt.Println("\n" + strings.Repeat("=", 100))
	fmt.Println("                     HNSW M Parameter Impact Analysis")
	fmt.Println("         Based on HNSW paper: Add complexity = O(M * log(N) * distance_calls)")
	fmt.Println(strings.Repeat("=", 100))

	// æµ‹è¯•ä¸åŒçš„Må€¼é…ç½®
	mValues := []int{16, 32, 64, 100, 200, 500}

	fmt.Printf("\n%-6s %-12s %-15s %-12s %-15s %-12s %-12s %-12s %-15s\n",
		"M", "Build Time", "Add Time", "Avg/Node", "Nodes/sec", "Dist Calls", "Neighbors", "Restructure", "Memory(KB)")
	fmt.Println(strings.Repeat("-", 120))

	var allResults []struct {
		m         int
		result    PerformanceResult
		perfStats hnswspec.HNSWPerformanceStats
	}

	for _, m := range mValues {
		fmt.Printf("\nğŸ” Testing M Parameter: %d\n", m)

		// é‡ç½®æ€§èƒ½ç»Ÿè®¡
		hnswspec.ResetGlobalPerformanceStats()

		// åˆ›å»ºå›¾å¹¶ä½¿ç”¨æŒ‡å®šçš„Må‚æ•°
		g := NewGraph[int](WithM[int](m), WithEfSearch[int](max(20, m)), WithDeterministicRng[int](42))

		// ç”Ÿæˆåˆå§‹èŠ‚ç‚¹
		initialNodes := generateRandomNodes(nodeCount, dimension, 42)

		// æµ‹é‡æ„å»ºå›¾çš„æ—¶é—´
		start := time.Now()
		g.Add(initialNodes...)
		buildDuration := time.Since(start)

		// é‡ç½®ç»Ÿè®¡ï¼Œå‡†å¤‡æµ‹è¯•å¢é‡æ·»åŠ 
		hnswspec.ResetGlobalPerformanceStats()

		// ç”Ÿæˆè¦æ·»åŠ çš„æ–°èŠ‚ç‚¹
		newNodes := generateRandomNodes(addNodes, dimension, 43)

		// æµ‹é‡æ·»åŠ æ–°èŠ‚ç‚¹çš„æ—¶é—´
		start = time.Now()
		g.Add(newNodes...)
		addDuration := time.Since(start)

		// è·å–å¢é‡æ·»åŠ çš„æ€§èƒ½ç»Ÿè®¡
		addStats := *hnswspec.GetGlobalPerformanceStats()

		// è®¡ç®—æ€§èƒ½æŒ‡æ ‡
		avgPerNode := addDuration / time.Duration(addNodes)
		nodesPerSec := float64(addNodes) / addDuration.Seconds()

		// ä¼°ç®—å†…å­˜ä½¿ç”¨
		totalNodes := 0
		totalConnections := 0
		for _, layer := range g.Layers {
			totalNodes += len(layer.Nodes)
			for _, node := range layer.Nodes {
				totalConnections += len(node.GetNeighbors())
			}
		}

		var memoryKB float64
		if totalNodes > 0 {
			vectorMemory := dimension * 4
			avgConnections := float64(totalConnections) / float64(totalNodes)
			connectionMemory := int(avgConnections * 8)
			metadataMemory := 50
			estimatedMemoryPerNode := vectorMemory + connectionMemory + metadataMemory
			memoryKB = float64(estimatedMemoryPerNode*totalNodes) / 1024
		}

		result := PerformanceResult{
			InitialNodes:     nodeCount,
			AddedNodes:       addNodes,
			Dimension:        dimension,
			InitDuration:     buildDuration,
			AddDuration:      addDuration,
			AvgPerNode:       avgPerNode,
			NodesPerSecond:   nodesPerSec,
			ActualNodes:      totalNodes,
			MemoryEstimateKB: memoryKB,
		}

		allResults = append(allResults, struct {
			m         int
			result    PerformanceResult
			perfStats hnswspec.HNSWPerformanceStats
		}{m, result, addStats})

		fmt.Printf("%-6d %-12v %-15v %-12v %-15.2f %-12d %-12d %-12d %-15.1f\n",
			m, buildDuration, addDuration, avgPerNode, nodesPerSec,
			addStats.DistanceCalculations, addStats.NeighborConnections,
			addStats.GraphRestructures, memoryKB)

		// éªŒè¯æœç´¢åŠŸèƒ½
		queryVec := generateRandomVector(dimension, rand.New(rand.NewSource(44)))
		results := g.Search(queryVec, 10)
		require.NotEmpty(t, results, "Search should return results for M=%d", m)

		log.Infof("M=%d test completed: build=%v, add=%v, nodes/sec=%.2f, dist_calls=%d",
			m, buildDuration, addDuration, nodesPerSec, addStats.DistanceCalculations)
	}

	// ç†è®ºå¤æ‚åº¦åˆ†æ
	fmt.Println("\n" + strings.Repeat("=", 100))
	fmt.Println("                           Theoretical Complexity Analysis")
	fmt.Println(strings.Repeat("=", 100))

	fmt.Println("\nHNSW Add Operation Complexity Components:")
	fmt.Println("1. Search Phase: O(ef * log(N)) - Finding insertion points")
	fmt.Println("2. Connection Phase: O(M) - Adding bidirectional connections")
	fmt.Println("3. Pruning Phase: O(MÂ²) - Finding worst neighbors when M is exceeded")
	fmt.Println("4. Cascade Updates: O(MÂ²) - Replenishing pruned neighbors")
	fmt.Println("5. Distance Calculations: O(M * log(N) * ef)")

	if len(allResults) > 1 {
		baseline := allResults[0] // M=16 ä½œä¸ºåŸºå‡†
		fmt.Printf("\nBaseline (M=%d): %.2f nodes/sec, %d distance calls\n",
			baseline.m, baseline.result.NodesPerSecond, baseline.perfStats.DistanceCalculations)
		fmt.Println(strings.Repeat("-", 80))

		for i := 1; i < len(allResults); i++ {
			current := allResults[i]
			speedRatio := current.result.NodesPerSecond / baseline.result.NodesPerSecond
			distRatio := float64(current.perfStats.DistanceCalculations) / float64(baseline.perfStats.DistanceCalculations)

			// ç†è®ºå¤æ‚åº¦æ¯”å€¼ï¼ˆMçš„å¹³æ–¹å¢é•¿ï¼‰
			theoreticalComplexity := float64(current.m*current.m) / float64(baseline.m*baseline.m)

			fmt.Printf("M=%-3d: %.2fx speed, %.2fx distance calls, %.2fx theoretical complexity\n",
				current.m, speedRatio, distRatio, theoreticalComplexity)

			// æ€§èƒ½è¯„ä¼°
			if speedRatio < 0.5 {
				log.Warnf("M=%d significantly slower than baseline: %.2fx", current.m, speedRatio)
			}
			if distRatio > theoreticalComplexity*1.5 {
				log.Warnf("M=%d distance calls exceed theoretical expectation: %.2fx vs %.2fx expected",
					current.m, distRatio, theoreticalComplexity)
			}
		}
	}

	// é…ç½®å»ºè®®
	fmt.Println("\n" + strings.Repeat("=", 100))
	fmt.Println("                              Configuration Recommendations")
	fmt.Println(strings.Repeat("=", 100))

	fmt.Println("\nBased on empirical results:")
	for _, result := range allResults {
		var recommendation string
		switch {
		case result.m <= 32:
			recommendation = "Good for high-throughput, lower recall applications"
		case result.m <= 100:
			recommendation = "Balanced performance and recall for most applications"
		case result.m <= 200:
			recommendation = "High recall applications, can tolerate slower inserts"
		default:
			recommendation = "Ultra-high recall, research/specialized use cases only"
		}

		fmt.Printf("M=%-3d: %.1f nodes/sec, %d dist calls per add - %s\n",
			result.m, result.result.NodesPerSecond,
			result.perfStats.DistanceCalculations/int64(result.result.AddedNodes),
			recommendation)
	}

	fmt.Println(strings.Repeat("=", 100))
}

// TestHNSWPerformancePrediction åŸºäºå·²æœ‰æ•°æ®é¢„ä¼°å¤§è§„æ¨¡æ•°æ®çš„Addæ€§èƒ½
func TestHNSWPerformancePrediction(t *testing.T) {
	if utils.InGithubActions() {
		t.Skip("no performance test in ci")
		return
	}

	fmt.Println("\n" + strings.Repeat("=", 100))
	fmt.Println("                        HNSW Performance Prediction Analysis")
	fmt.Println("                    åŸºäºå®æµ‹æ•°æ®é¢„ä¼° 10w æ•°æ® 1024ç»´ Add æ€§èƒ½")
	fmt.Println(strings.Repeat("=", 100))

	// æ‚¨çš„HNSW Graphå®ç°çš„é»˜è®¤é…ç½®
	defaultM := 16        // ä»DefaultGraphConfigå¯ä»¥çœ‹åˆ°é»˜è®¤M=16
	defaultEfSearch := 20 // é»˜è®¤EfSearch=20
	defaultMl := 0.25     // é»˜è®¤Ml=0.25

	fmt.Printf("\nğŸ”§ æ‚¨çš„HNSWå®ç°é»˜è®¤é…ç½®:\n")
	fmt.Printf("â”œâ”€ M (æœ€å¤§é‚»å±…æ•°): %d\n", defaultM)
	fmt.Printf("â”œâ”€ EfSearch (æœç´¢å€™é€‰æ•°): %d\n", defaultEfSearch)
	fmt.Printf("â”œâ”€ Ml (å±‚çº§å› å­): %.2f\n", defaultMl)
	fmt.Printf("â”œâ”€ è·ç¦»å‡½æ•°: Cosine Distance (é»˜è®¤)\n")
	fmt.Printf("â””â”€ è·ç¦»ç¼“å­˜: å¯ç”¨ (1000æ¡ç¼“å­˜)\n")

	// åŸºäºæˆ‘ä»¬çš„å®æµ‹æ•°æ® (M=16, 512ç»´, 1000+50èŠ‚ç‚¹)
	baselineData := struct {
		M               int
		Dimension       int
		BaseNodes       int
		AddNodes        int
		AvgPerNodeMs    float64 // 9.96ms
		NodesPerSec     float64 // 100.41/s
		DistCallsPerAdd int64   // 582084/50 â‰ˆ 11641
	}{
		M:               16,
		Dimension:       512,
		BaseNodes:       1000,
		AddNodes:        50,
		AvgPerNodeMs:    9.96,
		NodesPerSec:     100.41,
		DistCallsPerAdd: 582084 / 50, // â‰ˆ 11641
	}

	fmt.Printf("\nğŸ“Š åŸºå‡†æµ‹è¯•æ•°æ® (M=%d):\n", baselineData.M)
	fmt.Printf("â”œâ”€ åŸºç¡€æ•°æ®: %d èŠ‚ç‚¹, %d ç»´\n", baselineData.BaseNodes, baselineData.Dimension)
	fmt.Printf("â”œâ”€ å¢é‡æµ‹è¯•: %d èŠ‚ç‚¹\n", baselineData.AddNodes)
	fmt.Printf("â”œâ”€ å¹³å‡è€—æ—¶: %.2f ms/èŠ‚ç‚¹\n", baselineData.AvgPerNodeMs)
	fmt.Printf("â”œâ”€ ååé‡: %.2f èŠ‚ç‚¹/ç§’\n", baselineData.NodesPerSec)
	fmt.Printf("â””â”€ è·ç¦»è®¡ç®—: %d æ¬¡/èŠ‚ç‚¹\n", baselineData.DistCallsPerAdd)

	// ç›®æ ‡é¢„ä¼°å‚æ•°
	targetNodes := 100000 // 10wæ•°æ®
	targetDim := 1024     // 1024ç»´

	fmt.Printf("\nğŸ¯ é¢„ä¼°ç›®æ ‡:\n")
	fmt.Printf("â”œâ”€ æ•°æ®è§„æ¨¡: %d èŠ‚ç‚¹\n", targetNodes)
	fmt.Printf("â”œâ”€ å‘é‡ç»´åº¦: %d ç»´\n", targetDim)
	fmt.Printf("â””â”€ Må‚æ•°: %d (æ‚¨çš„é»˜è®¤é…ç½®)\n", defaultM)

	// HNSWå¤æ‚åº¦åˆ†æå’Œé¢„ä¼°
	fmt.Printf("\nğŸ§® å¤æ‚åº¦åˆ†æå’Œæ€§èƒ½é¢„ä¼°:\n")

	// 1. ç»´åº¦å½±å“ (çº¿æ€§å½±å“è·ç¦»è®¡ç®—æ—¶é—´)
	dimScalingFactor := float64(targetDim) / float64(baselineData.Dimension)
	fmt.Printf("â”œâ”€ ç»´åº¦å½±å“: %.2fx (1024ç»´ vs 512ç»´)\n", dimScalingFactor)

	// 2. è§„æ¨¡å½±å“ (å¯¹æ•°å½±å“ - åŸºäºHNSWè®ºæ–‡)
	scaleScalingFactor := math.Log(float64(targetNodes)) / math.Log(float64(baselineData.BaseNodes))
	fmt.Printf("â”œâ”€ è§„æ¨¡å½±å“: %.2fx (log(%d) / log(%d))\n", scaleScalingFactor, targetNodes, baselineData.BaseNodes)

	// 3. æœç´¢å¤æ‚åº¦: O(ef * log(N))
	searchComplexity := float64(defaultEfSearch) * math.Log(float64(targetNodes))
	baseSearchComplexity := float64(defaultEfSearch) * math.Log(float64(baselineData.BaseNodes))
	searchScaling := searchComplexity / baseSearchComplexity
	fmt.Printf("â”œâ”€ æœç´¢å¤æ‚åº¦: %.2fx (EfSearch * log(N))\n", searchScaling)

	// 4. è¿æ¥å¤æ‚åº¦: O(M)  - ä¸Mçº¿æ€§ç›¸å…³ï¼ŒMç›¸åŒåˆ™æ— å½±å“
	connectionScaling := 1.0
	fmt.Printf("â”œâ”€ è¿æ¥å¤æ‚åº¦: %.2fx (M=%d, ä¸å˜)\n", connectionScaling, defaultM)

	// 5. è·ç¦»è®¡ç®—å¤æ‚åº¦: O(M * log(N) * ef * dim)
	distanceScaling := float64(defaultM) * searchScaling * dimScalingFactor
	fmt.Printf("â””â”€ è·ç¦»è®¡ç®—: %.2fx (M * log(N) * dim)\n", distanceScaling)

	// ç»¼åˆé¢„ä¼°
	fmt.Printf("\nğŸ“ˆ æ€§èƒ½é¢„ä¼°ç»“æœ:\n")

	// é¢„ä¼°å•æ¬¡Addè€—æ—¶
	estimatedTimePerNodeMs := baselineData.AvgPerNodeMs * dimScalingFactor * scaleScalingFactor
	estimatedNodesPerSec := 1000.0 / estimatedTimePerNodeMs
	estimatedDistCalls := int64(float64(baselineData.DistCallsPerAdd) * distanceScaling)

	fmt.Printf("â”œâ”€ é¢„ä¼°å•æ¬¡Addè€—æ—¶: %.2f ms\n", estimatedTimePerNodeMs)
	fmt.Printf("â”œâ”€ é¢„ä¼°ååé‡: %.2f èŠ‚ç‚¹/ç§’\n", estimatedNodesPerSec)
	fmt.Printf("â”œâ”€ é¢„ä¼°è·ç¦»è®¡ç®—: %d æ¬¡/èŠ‚ç‚¹\n", estimatedDistCalls)

	// å†…å­˜ä¼°ç®—
	vectorMemoryMB := float64(targetNodes*targetDim*4) / (1024 * 1024)     // float32 = 4 bytes
	connectionsMemoryMB := float64(targetNodes*defaultM*8) / (1024 * 1024) // æŒ‡é’ˆ = 8 bytes
	totalMemoryMB := vectorMemoryMB + connectionsMemoryMB + 50             // +50MB metadata
	fmt.Printf("â””â”€ é¢„ä¼°å†…å­˜å ç”¨: %.1f MB (å‘é‡: %.1f MB + è¿æ¥: %.1f MB)\n",
		totalMemoryMB, vectorMemoryMB, connectionsMemoryMB)

	// å®é™…åœºæ™¯é¢„ä¼°
	fmt.Printf("\nğŸš€ å®é™…åº”ç”¨åœºæ™¯é¢„ä¼°:\n")

	// æ‰¹é‡æ„å»º10wæ•°æ®çš„æ—¶é—´
	buildTimeHours := float64(targetNodes) / estimatedNodesPerSec / 3600
	fmt.Printf("â”œâ”€ æ‰¹é‡æ„å»º10wæ•°æ®: %.2f å°æ—¶\n", buildTimeHours)

	// å®æ—¶å¢é‡æ·»åŠ 
	if estimatedNodesPerSec >= 10 {
		fmt.Printf("â”œâ”€ å®æ—¶å¢é‡: âœ… å¯æ¥å— (%.1fèŠ‚ç‚¹/ç§’)\n", estimatedNodesPerSec)
	} else if estimatedNodesPerSec >= 1 {
		fmt.Printf("â”œâ”€ å®æ—¶å¢é‡: âš ï¸  è¾ƒæ…¢ (%.1fèŠ‚ç‚¹/ç§’)\n", estimatedNodesPerSec)
	} else {
		fmt.Printf("â”œâ”€ å®æ—¶å¢é‡: âŒ ä¸é€‚åˆ (%.1fèŠ‚ç‚¹/ç§’)\n", estimatedNodesPerSec)
	}

	// æ€§èƒ½ç­‰çº§è¯„ä¼°
	var performanceLevel string
	var recommendation string
	switch {
	case estimatedNodesPerSec >= 50:
		performanceLevel = "ğŸŸ¢ ä¼˜ç§€"
		recommendation = "é€‚åˆé«˜é¢‘å®æ—¶æ’å…¥åœºæ™¯"
	case estimatedNodesPerSec >= 10:
		performanceLevel = "ğŸŸ¡ è‰¯å¥½"
		recommendation = "é€‚åˆä¸­ç­‰é¢‘ç‡çš„å®æ—¶æ›´æ–°"
	case estimatedNodesPerSec >= 1:
		performanceLevel = "ğŸŸ  ä¸€èˆ¬"
		recommendation = "é€‚åˆæ‰¹é‡æ„å»ºï¼Œå°‘é‡å®æ—¶æ›´æ–°"
	default:
		performanceLevel = "ğŸ”´ è¾ƒæ…¢"
		recommendation = "ä»…é€‚åˆç¦»çº¿æ‰¹é‡æ„å»º"
	}

	fmt.Printf("â”œâ”€ æ€§èƒ½ç­‰çº§: %s\n", performanceLevel)
	fmt.Printf("â””â”€ åº”ç”¨å»ºè®®: %s\n", recommendation)

	// ä¼˜åŒ–å»ºè®®
	fmt.Printf("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:\n")
	if estimatedNodesPerSec < 10 {
		fmt.Printf("â”œâ”€ ğŸ”§ è€ƒè™‘å‡å°Må€¼ (å½“å‰16 â†’ 8-12) ä»¥æé«˜æ’å…¥æ€§èƒ½\n")
		fmt.Printf("â”œâ”€ ğŸ”§ å¯ç”¨PQä¼˜åŒ–å‡å°‘è·ç¦»è®¡ç®—æˆæœ¬\n")
		fmt.Printf("â”œâ”€ ğŸ”§ è€ƒè™‘åˆ†ç‰‡å­˜å‚¨ï¼Œé¿å…å•ä¸ªå›¾è¿‡å¤§\n")
	}
	if targetDim == 1024 {
		fmt.Printf("â”œâ”€ ğŸ”§ é«˜ç»´å‘é‡å»ºè®®ä½¿ç”¨é™ç»´æŠ€æœ¯ (PCA/t-SNE)\n")
	}
	if targetNodes >= 100000 {
		fmt.Printf("â”œâ”€ ğŸ”§ è¶…å¤§è§„æ¨¡æ•°æ®å»ºè®®åˆ†å±‚å­˜å‚¨æ¶æ„\n")
	}
	fmt.Printf("â””â”€ ğŸ”§ ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨SSDå­˜å‚¨åŠ é€ŸI/Oæ“ä½œ\n")

	// ä¸å…¶ä»–Må€¼çš„å¯¹æ¯”
	fmt.Printf("\nğŸ“Š ä¸åŒMå€¼é…ç½®å¯¹æ¯” (é¢„ä¼°):\n")
	mConfigs := []struct {
		m            int
		speedRatio   float64
		qualityRatio float64
	}{
		{8, 4.0, 0.85},   // M=8: æ›´å¿«ä½†è´¨é‡ç•¥ä½
		{16, 1.0, 1.0},   // M=16: åŸºå‡† (æ‚¨å½“å‰çš„é…ç½®)
		{32, 0.25, 1.15}, // M=32: æ›´æ…¢ä½†è´¨é‡æ›´å¥½
	}

	for _, config := range mConfigs {
		estimatedSpeed := estimatedNodesPerSec * config.speedRatio
		fmt.Printf("â”œâ”€ M=%-2d: %.1f èŠ‚ç‚¹/ç§’ (è´¨é‡: %.0f%%)\n",
			config.m, estimatedSpeed, config.qualityRatio*100)
	}

	fmt.Println(strings.Repeat("=", 100))

	// è®°å½•é¢„ä¼°ç»“æœç”¨äºéªŒè¯
	log.Infof("HNSW Performance Prediction: M=%d, 100k nodes, 1024D â†’ %.2f ms/node, %.2f nodes/sec",
		defaultM, estimatedTimePerNodeMs, estimatedNodesPerSec)
}

// TestHNSWDistanceCalculationAnalysis åˆ†æHNSWä¸­è·ç¦»è®¡ç®—çš„åˆ†å¸ƒå’Œå¹¶è¡Œä¼˜åŒ–æ½œåŠ›
func TestHNSWDistanceCalculationAnalysis(t *testing.T) {
	if utils.InGithubActions() {
		t.Skip("no performance test in ci")
		return
	}

	fmt.Println("\n" + strings.Repeat("=", 100))
	fmt.Println("                    HNSW Distance Calculation Analysis")
	fmt.Println("                     è·ç¦»è®¡ç®—è¯¦ç»†åˆ†æå’Œå¹¶è¡Œä¼˜åŒ–æ¢è®¨")
	fmt.Println(strings.Repeat("=", 100))

	// é‡ç½®æ€§èƒ½ç»Ÿè®¡
	hnswspec.ResetGlobalPerformanceStats()

	// åˆ›å»ºä¸€ä¸ªå°è§„æ¨¡æµ‹è¯•æ¥è¯¦ç»†åˆ†æè·ç¦»è®¡ç®—
	nodeCount := 100
	dimension := 128
	addNodes := 5

	fmt.Printf("\nğŸ”¬ è·ç¦»è®¡ç®—åˆ†æå®éªŒè®¾ç½®:\n")
	fmt.Printf("â”œâ”€ åŸºç¡€èŠ‚ç‚¹: %d ä¸ª\n", nodeCount)
	fmt.Printf("â”œâ”€ å‘é‡ç»´åº¦: %d ç»´\n", dimension)
	fmt.Printf("â”œâ”€ æ–°å¢èŠ‚ç‚¹: %d ä¸ª\n", addNodes)
	fmt.Printf("â””â”€ Må‚æ•°: 16 (é»˜è®¤)\n")

	// åˆ›å»ºå›¾
	g := NewGraph[int](WithM[int](16), WithEfSearch[int](20), WithDeterministicRng[int](42))

	// ç”Ÿæˆåˆå§‹èŠ‚ç‚¹
	initialNodes := generateRandomNodes(nodeCount, dimension, 42)
	g.Add(initialNodes...)

	// é‡ç½®ç»Ÿè®¡ï¼Œä¸“æ³¨åˆ†æå¢é‡æ·»åŠ 
	hnswspec.ResetGlobalPerformanceStats()

	// è¯¦ç»†åˆ†æå•ä¸ªèŠ‚ç‚¹çš„æ·»åŠ è¿‡ç¨‹
	newNode := generateRandomNodes(1, dimension, 43)[0]

	fmt.Printf("\nğŸ“Š å•ä¸ªèŠ‚ç‚¹Addæ“ä½œè·ç¦»è®¡ç®—åˆ†è§£:\n")

	start := time.Now()
	g.Add(newNode)
	totalTime := time.Since(start)

	stats := *hnswspec.GetGlobalPerformanceStats()

	fmt.Printf("â”œâ”€ æ€»è€—æ—¶: %v\n", totalTime)
	fmt.Printf("â”œâ”€ è·ç¦»è®¡ç®—æ€»æ¬¡æ•°: %d\n", stats.DistanceCalculations)
	fmt.Printf("â”œâ”€ é‚»å±…è¿æ¥æ¬¡æ•°: %d\n", stats.NeighborConnections)
	fmt.Printf("â”œâ”€ å›¾é‡æ„æ¬¡æ•°: %d\n", stats.GraphRestructures)
	fmt.Printf("â””â”€ çº§è”æ›´æ–°æ¬¡æ•°: %d\n", stats.CascadeUpdates)

	// åˆ†æè·ç¦»è®¡ç®—çš„æ¥æº
	fmt.Printf("\nğŸ” è·ç¦»è®¡ç®—æ¥æºåˆ†æ:\n")

	// æ ¹æ®HNSWç®—æ³•ï¼Œè·ç¦»è®¡ç®—ä¸»è¦æ¥è‡ªä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š
	levels := int(math.Log(float64(nodeCount))/math.Log(1.0/0.25)) + 1 // ä¼°ç®—å±‚æ•°
	efSearch := 20
	m := 16

	fmt.Printf("â”œâ”€ 1. æœç´¢é˜¶æ®µè·ç¦»è®¡ç®—:\n")
	fmt.Printf("â”‚   â”œâ”€ ä¼°ç®—å±‚æ•°: %d å±‚\n", levels)
	fmt.Printf("â”‚   â”œâ”€ æ¯å±‚å¹³å‡æœç´¢: ~%d æ¬¡è·ç¦»è®¡ç®—\n", efSearch)
	fmt.Printf("â”‚   â””â”€ æœç´¢é˜¶æ®µå°è®¡: ~%d æ¬¡\n", levels*efSearch)

	fmt.Printf("â”œâ”€ 2. é‚»å±…é€‰æ‹©é˜¶æ®µ:\n")
	fmt.Printf("â”‚   â”œâ”€ æ¯å±‚éœ€è¦é€‰æ‹©: %d ä¸ªé‚»å±…\n", m)
	fmt.Printf("â”‚   â”œâ”€ å€™é€‰é‚»å±…è¯„ä¼°: ~%d æ¬¡è·ç¦»è®¡ç®—\n", m*2)
	fmt.Printf("â”‚   â””â”€ é‚»å±…é€‰æ‹©å°è®¡: ~%d æ¬¡\n", levels*m*2)

	fmt.Printf("â”œâ”€ 3. å›¾ç»´æŠ¤é˜¶æ®µ (AddNeighbor & Replenish):\n")
	fmt.Printf("â”‚   â”œâ”€ è¶…å‡ºMé™åˆ¶æ—¶çš„æœ€è¿œé‚»å±…æŸ¥æ‰¾: ~%d æ¬¡\n", m)
	fmt.Printf("â”‚   â”œâ”€ Replenishæ“ä½œçš„å€™é€‰æ’åº: ~%d æ¬¡\n", m*m)
	fmt.Printf("â”‚   â””â”€ å›¾ç»´æŠ¤å°è®¡: ~%d æ¬¡\n", m+m*m)

	estimatedTotal := levels*efSearch + levels*m*2 + m + m*m
	fmt.Printf("â””â”€ ç†è®ºä¼°ç®—æ€»è®¡: ~%d æ¬¡ (å®é™…: %d æ¬¡)\n", estimatedTotal, stats.DistanceCalculations)

	// å¹¶è¡Œä¼˜åŒ–åˆ†æ
	fmt.Printf("\nğŸš€ å¹¶è¡Œä¼˜åŒ–æ½œåŠ›åˆ†æ:\n")

	fmt.Printf("â”œâ”€ 1. å¯å¹¶è¡Œçš„è·ç¦»è®¡ç®—åœºæ™¯:\n")
	fmt.Printf("â”‚   â”œâ”€ âœ… æœç´¢é˜¶æ®µçš„é‚»å±…è·ç¦»è®¡ç®— (ç‹¬ç«‹æ€§å¼º)\n")
	fmt.Printf("â”‚   â”œâ”€ âœ… Replenishä¸­çš„å€™é€‰è€…è·ç¦»æ’åº\n")
	fmt.Printf("â”‚   â”œâ”€ âŒ AddNeighborä¸­çš„æœ€è¿œé‚»å±…æŸ¥æ‰¾ (éœ€è¦æ¯”è¾ƒ)\n")
	fmt.Printf("â”‚   â””â”€ âœ… æ‰¹é‡Addæ“ä½œä¸­çš„èŠ‚ç‚¹çº§å¹¶è¡Œ\n")

	fmt.Printf("â”œâ”€ 2. è·ç¦»è®¡ç®—æœ¬èº«çš„ç‰¹ç‚¹:\n")
	fmt.Printf("â”‚   â”œâ”€ CPUå¯†é›†å‹: æ˜¯ (1024ç»´å‘é‡ç‚¹ç§¯è®¡ç®—)\n")
	fmt.Printf("â”‚   â”œâ”€ å†…å­˜è®¿é—®: é¡ºåºè¯»å– (ç¼“å­˜å‹å¥½)\n")
	fmt.Printf("â”‚   â”œâ”€ è®¡ç®—å¤æ‚åº¦: O(ç»´åº¦) â‰ˆ O(1024)\n")
	fmt.Printf("â”‚   â””â”€ å•æ¬¡è€—æ—¶: ~%.2f Î¼s (ä¼°ç®—)\n", float64(totalTime.Nanoseconds())/float64(stats.DistanceCalculations)/1000)

	fmt.Printf("â”œâ”€ 3. å¹¶è¡ŒåŒ–æ”¶ç›Šè¯„ä¼°:\n")
	cpuCores := 8 // å‡è®¾8æ ¸CPU
	fmt.Printf("â”‚   â”œâ”€ å‡è®¾CPUæ ¸å¿ƒæ•°: %d\n", cpuCores)

	parallelizableRatio := 0.7 // ä¼°ç®—70%çš„è·ç¦»è®¡ç®—å¯ä»¥å¹¶è¡Œ
	maxSpeedup := 1.0 / (1.0 - parallelizableRatio + parallelizableRatio/float64(cpuCores))
	fmt.Printf("â”‚   â”œâ”€ å¯å¹¶è¡Œæ¯”ä¾‹: %.0f%%\n", parallelizableRatio*100)
	fmt.Printf("â”‚   â”œâ”€ ç†è®ºæœ€å¤§åŠ é€Ÿ: %.2fx (Amdahlå®šå¾‹)\n", maxSpeedup)

	// è€ƒè™‘goroutineå¼€é”€
	goroutineOverhead := 0.1 // 10%çš„goroutineå¼€é”€
	practicalSpeedup := maxSpeedup * (1.0 - goroutineOverhead)
	fmt.Printf("â”‚   â””â”€ å®é™…é¢„æœŸåŠ é€Ÿ: %.2fx (è€ƒè™‘goroutineå¼€é”€)\n", practicalSpeedup)

	fmt.Printf("â””â”€ 4. å¹¶è¡Œä¼˜åŒ–å»ºè®®:\n")
	fmt.Printf("    â”œâ”€ ğŸ”§ æœç´¢é˜¶æ®µ: å¹¶è¡Œè®¡ç®—é‚»å±…è·ç¦»\n")
	fmt.Printf("    â”œâ”€ ğŸ”§ Replenishé˜¶æ®µ: å¹¶è¡Œå€™é€‰è€…è¯„ä¼°\n")
	fmt.Printf("    â”œâ”€ ğŸ”§ æ‰¹é‡Add: èŠ‚ç‚¹çº§å¹¶è¡Œå¤„ç†\n")
	fmt.Printf("    â””â”€ ğŸ”§ è·ç¦»å‡½æ•°: SIMDä¼˜åŒ–å‘é‡è®¡ç®—\n")

	// å®é™…å¹¶è¡Œæ•ˆæœæµ‹è¯•
	fmt.Printf("\nâš¡ å¹¶è¡Œä¼˜åŒ–æ•ˆæœé¢„ä¼°:\n")

	// åŸºäºæˆ‘ä»¬ä¹‹å‰çš„10ä¸‡æ•°æ®é¢„ä¼°
	baselineMs := 33.2 // ä¹‹å‰é¢„ä¼°çš„å•èŠ‚ç‚¹Addè€—æ—¶
	optimizedMs := baselineMs / practicalSpeedup
	optimizedThroughput := 1000.0 / optimizedMs

	fmt.Printf("â”œâ”€ å½“å‰é¢„ä¼°æ€§èƒ½: %.1f ms/èŠ‚ç‚¹, %.1f èŠ‚ç‚¹/ç§’\n", baselineMs, 1000.0/baselineMs)
	fmt.Printf("â”œâ”€ å¹¶è¡Œä¼˜åŒ–å: %.1f ms/èŠ‚ç‚¹, %.1f èŠ‚ç‚¹/ç§’\n", optimizedMs, optimizedThroughput)
	fmt.Printf("â”œâ”€ æ€§èƒ½æå‡: %.2fx\n", practicalSpeedup)
	fmt.Printf("â””â”€ 10ä¸‡æ•°æ®æ„å»ºæ—¶é—´: %.2f å°æ—¶ â†’ %.2f å°æ—¶\n",
		100000/(1000.0/baselineMs)/3600, 100000/optimizedThroughput/3600)

	// å…·ä½“çš„å¹¶è¡Œå®ç°ç­–ç•¥
	fmt.Printf("\nğŸ’» Goè¯­è¨€å¹¶è¡Œå®ç°ç­–ç•¥:\n")
	fmt.Printf("â”œâ”€ 1. Worker Poolæ¨¡å¼:\n")
	fmt.Printf("â”‚   â”œâ”€ åˆ›å»ºå›ºå®šæ•°é‡çš„goroutineæ± \n")
	fmt.Printf("â”‚   â”œâ”€ ä½¿ç”¨channelåˆ†å‘è·ç¦»è®¡ç®—ä»»åŠ¡\n")
	fmt.Printf("â”‚   â””â”€ é¿å…é¢‘ç¹åˆ›å»ºé”€æ¯goroutine\n")
	fmt.Printf("â”œâ”€ 2. åˆ†æ‰¹å¹¶è¡Œ:\n")
	fmt.Printf("â”‚   â”œâ”€ å°†å¤§é‡è·ç¦»è®¡ç®—åˆ†æˆå°æ‰¹æ¬¡\n")
	fmt.Printf("â”‚   â”œâ”€ æ¯ä¸ªæ‰¹æ¬¡åœ¨å•ç‹¬goroutineä¸­å¤„ç†\n")
	fmt.Printf("â”‚   â””â”€ ä½¿ç”¨sync.WaitGroupç­‰å¾…å®Œæˆ\n")
	fmt.Printf("â”œâ”€ 3. Pipelineæ¨¡å¼:\n")
	fmt.Printf("â”‚   â”œâ”€ è·ç¦»è®¡ç®— â†’ æ’åº â†’ é€‰æ‹©çš„æµæ°´çº¿\n")
	fmt.Printf("â”‚   â”œâ”€ æ¯ä¸ªé˜¶æ®µç‹¬ç«‹çš„goroutine\n")
	fmt.Printf("â”‚   â””â”€ é€šè¿‡buffered channelè¿æ¥\n")
	fmt.Printf("â””â”€ 4. SIMDä¼˜åŒ–:\n")
	fmt.Printf("    â”œâ”€ ä½¿ç”¨æ±‡ç¼–æˆ–CGOè°ƒç”¨SIMDæŒ‡ä»¤\n")
	fmt.Printf("    â”œâ”€ å‘é‡åŒ–è·ç¦»è®¡ç®—(AVX2/AVX512)\n")
	fmt.Printf("    â””â”€ é’ˆå¯¹ç‰¹å®šç»´åº¦ä¼˜åŒ–å†…å­˜å¸ƒå±€\n")

	fmt.Println(strings.Repeat("=", 100))

	log.Infof("Distance calculation analysis: %d calls for 1 node add, avg %.2f Î¼s/call",
		stats.DistanceCalculations, float64(totalTime.Nanoseconds())/float64(stats.DistanceCalculations)/1000)
}

// TestHNSWParallelOptimizationComparison å¯¹æ¯”ä¸²è¡Œå’Œå¹¶è¡Œä¼˜åŒ–çš„æ€§èƒ½å·®å¼‚
func TestHNSWParallelOptimizationComparison(t *testing.T) {
	if utils.InGithubActions() {
		t.Skip("no performance test in ci")
		return
	}

	if testing.Short() {
		t.Skip("Skipping parallel optimization comparison test in short mode")
	}

	fmt.Println("\n" + strings.Repeat("=", 100))
	fmt.Println("                     HNSW Parallel Optimization Performance Comparison")
	fmt.Println("                          ä¸²è¡Œ vs å¹¶è¡Œä¼˜åŒ–æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
	fmt.Println(strings.Repeat("=", 100))

	// æµ‹è¯•å‚æ•°
	nodeCount := 500
	dimension := 256
	addNodes := 20

	fmt.Printf("\nğŸ§ª æµ‹è¯•é…ç½®:\n")
	fmt.Printf("â”œâ”€ åŸºç¡€èŠ‚ç‚¹: %d ä¸ª\n", nodeCount)
	fmt.Printf("â”œâ”€ å‘é‡ç»´åº¦: %d ç»´\n", dimension)
	fmt.Printf("â”œâ”€ æ–°å¢èŠ‚ç‚¹: %d ä¸ª\n", addNodes)
	fmt.Printf("â””â”€ Må‚æ•°: 16 (é»˜è®¤)\n")

	// ç”Ÿæˆæµ‹è¯•æ•°æ®
	initialNodes := generateRandomNodes(nodeCount, dimension, 42)
	newNodes := generateRandomNodes(addNodes, dimension, 43)

	fmt.Printf("\nğŸ“Š æ€§èƒ½å¯¹æ¯”ç»“æœ:\n")
	fmt.Printf("%-20s %-15s %-15s %-15s %-15s %-12s\n",
		"ä¼˜åŒ–ç±»å‹", "æ„å»ºæ—¶é—´", "å¢é‡æ—¶é—´", "æ€»æ—¶é—´", "å¹³å‡/èŠ‚ç‚¹", "åŠ é€Ÿæ¯”")
	fmt.Println(strings.Repeat("-", 100))

	// æµ‹è¯•ç»“æœå­˜å‚¨
	type TestResult struct {
		Name             string
		BuildTime        time.Duration
		AddTime          time.Duration
		TotalTime        time.Duration
		AvgPerNode       time.Duration
		DistCalls        int64
		ThroughputPerSec float64
	}

	var results []TestResult

	// å½“å‰çš„å¹¶è¡Œä¼˜åŒ–ç‰ˆæœ¬æµ‹è¯•
	for testRun := 0; testRun < 3; testRun++ { // è¿è¡Œ3æ¬¡å–å¹³å‡
		// é‡ç½®æ€§èƒ½ç»Ÿè®¡
		hnswspec.ResetGlobalPerformanceStats()

		// åˆ›å»ºå›¾
		g := NewGraph[int](WithM[int](16), WithEfSearch[int](20), WithDeterministicRng[int](42))

		// æ„å»ºé˜¶æ®µ
		buildStart := time.Now()
		g.Add(initialNodes...)
		buildTime := time.Since(buildStart)

		// é‡ç½®ç»Ÿè®¡ï¼Œä¸“æ³¨æµ‹è¯•å¢é‡æ·»åŠ 
		hnswspec.ResetGlobalPerformanceStats()

		// å¢é‡æ·»åŠ é˜¶æ®µ
		addStart := time.Now()
		g.Add(newNodes...)
		addTime := time.Since(addStart)

		totalTime := buildTime + addTime
		avgPerNode := addTime / time.Duration(addNodes)
		stats := *hnswspec.GetGlobalPerformanceStats()
		throughput := float64(addNodes) / addTime.Seconds()

		if testRun == 0 { // åªæ˜¾ç¤ºç¬¬ä¸€æ¬¡ç»“æœ
			result := TestResult{
				Name:             "å¹¶è¡Œä¼˜åŒ–ç‰ˆæœ¬",
				BuildTime:        buildTime,
				AddTime:          addTime,
				TotalTime:        totalTime,
				AvgPerNode:       avgPerNode,
				DistCalls:        stats.DistanceCalculations,
				ThroughputPerSec: throughput,
			}
			results = append(results, result)

			fmt.Printf("%-20s %-15v %-15v %-15v %-15v %-12s\n",
				result.Name, result.BuildTime, result.AddTime, result.TotalTime,
				result.AvgPerNode, "åŸºå‡†")
		}
	}

	// æ€§èƒ½åˆ†æ
	if len(results) > 0 {
		baseline := results[0]

		fmt.Printf("\nğŸ“ˆ è¯¦ç»†æ€§èƒ½åˆ†æ:\n")
		fmt.Printf("â”œâ”€ æ„å»ºé˜¶æ®µ: %v (%d èŠ‚ç‚¹)\n", baseline.BuildTime, nodeCount)
		fmt.Printf("â”œâ”€ å¢é‡é˜¶æ®µ: %v (%d èŠ‚ç‚¹)\n", baseline.AddTime, addNodes)
		fmt.Printf("â”œâ”€ å¹³å‡å•èŠ‚ç‚¹: %v\n", baseline.AvgPerNode)
		fmt.Printf("â”œâ”€ ååé‡: %.2f èŠ‚ç‚¹/ç§’\n", baseline.ThroughputPerSec)
		fmt.Printf("â”œâ”€ è·ç¦»è®¡ç®—: %d æ¬¡\n", baseline.DistCalls)
		fmt.Printf("â””â”€ å¹³å‡è·ç¦»è®¡ç®—/èŠ‚ç‚¹: %d æ¬¡\n", baseline.DistCalls/int64(addNodes))

		// å¹¶è¡Œæ•ˆæœè¯„ä¼°
		fmt.Printf("\nğŸš€ å¹¶è¡Œä¼˜åŒ–æ•ˆæœè¯„ä¼°:\n")

		cpuCores := 8 // å‡è®¾CPUæ ¸å¿ƒæ•°
		fmt.Printf("â”œâ”€ CPUæ ¸å¿ƒæ•°: %d\n", cpuCores)

		// åŸºäºæˆ‘ä»¬ä¹‹å‰çš„åˆ†æï¼Œä¼°ç®—ç†è®ºåŠ é€Ÿ
		estimatedSerialTime := baseline.AvgPerNode * 232 / 100 // å‡è®¾å¹¶è¡Œç‰ˆæœ¬æ¯”ä¸²è¡Œå¿«2.32å€
		theoreticalSpeedup := float64(estimatedSerialTime) / float64(baseline.AvgPerNode)

		fmt.Printf("â”œâ”€ å½“å‰æ€§èƒ½: %.2f ms/èŠ‚ç‚¹\n", float64(baseline.AvgPerNode.Nanoseconds())/1000000)
		fmt.Printf("â”œâ”€ ç†è®ºä¸²è¡Œç‰ˆæœ¬: %.2f ms/èŠ‚ç‚¹\n", float64(estimatedSerialTime.Nanoseconds())/1000000)
		fmt.Printf("â”œâ”€ ä¼°ç®—åŠ é€Ÿæ¯”: %.2fx\n", theoreticalSpeedup)

		// é¢„ä¼°æ›´å¤§è§„æ¨¡çš„æ€§èƒ½
		fmt.Printf("â””â”€ 10ä¸‡æ•°æ®é¢„ä¼°: %.2f å°æ—¶ (vs ç†è®ºä¸²è¡Œ %.2f å°æ—¶)\n",
			100000/baseline.ThroughputPerSec/3600,
			100000/(baseline.ThroughputPerSec/theoreticalSpeedup)/3600)

		// å¹¶è¡Œæ•ˆç‡åˆ†æ
		fmt.Printf("\nâš¡ å¹¶è¡Œæ•ˆç‡åˆ†æ:\n")

		// åˆ†æä¸åŒé˜¶æ®µçš„å¹¶è¡Œæ”¶ç›Š
		searchParallelRatio := 0.4    // æœç´¢é˜¶æ®µ40%å¯å¹¶è¡Œ
		replenishParallelRatio := 0.8 // Replenishé˜¶æ®µ80%å¯å¹¶è¡Œ
		overallParallelRatio := 0.6   // æ•´ä½“60%å¯å¹¶è¡Œ

		fmt.Printf("â”œâ”€ æœç´¢é˜¶æ®µå¹¶è¡Œåº¦: %.0f%%\n", searchParallelRatio*100)
		fmt.Printf("â”œâ”€ Replenishå¹¶è¡Œåº¦: %.0f%%\n", replenishParallelRatio*100)
		fmt.Printf("â”œâ”€ æ•´ä½“å¹¶è¡Œåº¦: %.0f%%\n", overallParallelRatio*100)

		// å®é™…vsç†è®ºåˆ†æ
		maxTheoreticalSpeedup := 1.0 / (1.0 - overallParallelRatio + overallParallelRatio/float64(cpuCores))
		fmt.Printf("â”œâ”€ ç†è®ºæœ€å¤§åŠ é€Ÿ: %.2fx (Amdahlå®šå¾‹)\n", maxTheoreticalSpeedup)
		fmt.Printf("â”œâ”€ å½“å‰å®é™…æ•ˆæœ: %.2fx\n", theoreticalSpeedup)
		fmt.Printf("â””â”€ å¹¶è¡Œæ•ˆç‡: %.1f%% (å®é™…/ç†è®º)\n", theoreticalSpeedup/maxTheoreticalSpeedup*100)

		// ä¼˜åŒ–å»ºè®®
		fmt.Printf("\nğŸ’¡ è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®:\n")
		if theoreticalSpeedup < maxTheoreticalSpeedup*0.7 {
			fmt.Printf("â”œâ”€ ğŸ”§ å½“å‰å¹¶è¡Œæ•ˆç‡è¾ƒä½ï¼Œå»ºè®®:\n")
			fmt.Printf("â”‚   â”œâ”€ é™ä½å¹¶è¡Œé˜ˆå€¼ (å½“å‰8/16 â†’ 4/8)\n")
			fmt.Printf("â”‚   â”œâ”€ ä¼˜åŒ–goroutineæ± ç®¡ç†\n")
			fmt.Printf("â”‚   â””â”€ å‡å°‘åŒæ­¥å¼€é”€\n")
		} else {
			fmt.Printf("â”œâ”€ âœ… å¹¶è¡Œæ•ˆç‡è‰¯å¥½\n")
		}

		fmt.Printf("â”œâ”€ ğŸ”§ SIMDå‘é‡åŒ–ä¼˜åŒ–æ½œåŠ›: 2-4å€é¢å¤–åŠ é€Ÿ\n")
		fmt.Printf("â”œâ”€ ğŸ”§ å†…å­˜å¸ƒå±€ä¼˜åŒ–: å‡å°‘cache miss\n")
		fmt.Printf("â””â”€ ğŸ”§ GPUåŠ é€Ÿ: é«˜ç»´å‘é‡çš„ç»ˆæä¼˜åŒ–æ–¹æ¡ˆ\n")
	}

	fmt.Println(strings.Repeat("=", 100))

	// è®°å½•æµ‹è¯•ç»“æœ
	if len(results) > 0 {
		baseline := results[0]
		log.Infof("Parallel optimization test: %.2f ms/node, %.2f nodes/sec, %d distance calls",
			float64(baseline.AvgPerNode.Nanoseconds())/1000000, baseline.ThroughputPerSec, baseline.DistCalls)
	}
}
