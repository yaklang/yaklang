package hnsw

import (
	"fmt"
	"math/rand"
	"strings"
	"testing"
	"time"

	"github.com/stretchr/testify/require"
	"github.com/yaklang/yaklang/common/log"
)

// generateRandomVector ç”ŸæˆæŒ‡å®šç»´åº¦çš„éšæœºå‘é‡
func generateRandomVector(dimension int, rng *rand.Rand) []float32 {
	vector := make([]float32, dimension)
	for i := range vector {
		vector[i] = rng.Float32()
	}
	return vector
}

// generateRandomNodes ç”ŸæˆæŒ‡å®šæ•°é‡çš„éšæœºèŠ‚ç‚¹
func generateRandomNodes(count int, dimension int, seed int64) []InputNode[int] {
	rng := rand.New(rand.NewSource(seed))
	nodes := make([]InputNode[int], count)
	for i := 0; i < count; i++ {
		nodes[i] = MakeInputNode(i+1, generateRandomVector(dimension, rng))
	}
	return nodes
}

// PerformanceResult æ€§èƒ½æµ‹è¯•ç»“æœç»“æ„
type PerformanceResult struct {
	InitialNodes     int
	AddedNodes       int
	Dimension        int
	InitDuration     time.Duration
	AddDuration      time.Duration
	AvgPerNode       time.Duration
	NodesPerSecond   float64
	ActualNodes      int
	SearchResults    int
	MemoryEstimateKB float64
}

// String æ ¼å¼åŒ–è¾“å‡ºæ€§èƒ½ç»“æœ
func (pr PerformanceResult) String() string {
	var sb strings.Builder
	sb.WriteString("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
	sb.WriteString("â•‘                    HNSW Performance Report                   â•‘\n")
	sb.WriteString("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n")
	sb.WriteString(fmt.Sprintf("â•‘ Initial Nodes      : %8d                               â•‘\n", pr.InitialNodes))
	sb.WriteString(fmt.Sprintf("â•‘ Added Nodes        : %8d                               â•‘\n", pr.AddedNodes))
	sb.WriteString(fmt.Sprintf("â•‘ Vector Dimension   : %8d                               â•‘\n", pr.Dimension))
	sb.WriteString("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n")
	if pr.InitialNodes > 0 {
		sb.WriteString(fmt.Sprintf("â•‘ Init Duration      : %15v                        â•‘\n", pr.InitDuration))
		sb.WriteString(fmt.Sprintf("â•‘ Init Avg/Node      : %15v                        â•‘\n", pr.InitDuration/time.Duration(pr.InitialNodes)))
	}
	sb.WriteString(fmt.Sprintf("â•‘ Add Duration       : %15v                        â•‘\n", pr.AddDuration))
	sb.WriteString(fmt.Sprintf("â•‘ Add Avg/Node       : %15v                        â•‘\n", pr.AvgPerNode))
	sb.WriteString(fmt.Sprintf("â•‘ Nodes/Second       : %15.2f                        â•‘\n", pr.NodesPerSecond))
	sb.WriteString("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n")
	sb.WriteString(fmt.Sprintf("â•‘ Actual Nodes       : %8d                               â•‘\n", pr.ActualNodes))
	sb.WriteString(fmt.Sprintf("â•‘ Search Results     : %8d                               â•‘\n", pr.SearchResults))
	sb.WriteString(fmt.Sprintf("â•‘ Memory Estimate    : %12.2f KB                       â•‘\n", pr.MemoryEstimateKB))
	sb.WriteString("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")
	return sb.String()
}

// measureAddPerformance æµ‹é‡å•æ¬¡Addæ“ä½œçš„æ€§èƒ½
func measureAddPerformance(t *testing.T, initialNodeCount int, addNodeCount int, dimension int) PerformanceResult {
	log.Infof("Starting performance test: initial=%d nodes, adding=%d nodes, dimension=%d",
		initialNodeCount, addNodeCount, dimension)

	result := PerformanceResult{
		InitialNodes: initialNodeCount,
		AddedNodes:   addNodeCount,
		Dimension:    dimension,
	}

	// åˆ›å»ºå›¾å¹¶é¢„å¡«å……åˆå§‹èŠ‚ç‚¹
	g := NewGraph[int]()
	g.Rng = rand.New(rand.NewSource(42)) // å›ºå®šéšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§

	// é¢„å¡«å……åˆå§‹èŠ‚ç‚¹
	if initialNodeCount > 0 {
		log.Infof("Pre-populating graph with %d initial nodes", initialNodeCount)
		initialNodes := generateRandomNodes(initialNodeCount, dimension, 42)

		start := time.Now()
		g.Add(initialNodes...)
		result.InitDuration = time.Since(start)
		log.Infof("Initial population took: %v (avg per node: %v)",
			result.InitDuration, result.InitDuration/time.Duration(initialNodeCount))
	}

	// ç”Ÿæˆè¦æ·»åŠ çš„æ–°èŠ‚ç‚¹
	newNodes := generateRandomNodes(addNodeCount, dimension, 43) // ä¸åŒçš„ç§å­é¿å…é‡å¤

	// æµ‹é‡æ·»åŠ æ–°èŠ‚ç‚¹çš„æ€§èƒ½
	log.Infof("Starting to add %d new nodes to existing graph", addNodeCount)
	start := time.Now()

	// å•æ¬¡Addæ“ä½œæ·»åŠ æ‰€æœ‰æ–°èŠ‚ç‚¹
	g.Add(newNodes...)

	result.AddDuration = time.Since(start)
	result.AvgPerNode = result.AddDuration / time.Duration(addNodeCount)
	result.NodesPerSecond = float64(addNodeCount) / result.AddDuration.Seconds()

	log.Infof("Add operation completed: total=%v, avg per node=%v", result.AddDuration, result.AvgPerNode)

	// éªŒè¯æ‰€æœ‰èŠ‚ç‚¹éƒ½è¢«æ­£ç¡®æ·»åŠ 
	for _, layer := range g.Layers {
		result.ActualNodes += len(layer.Nodes)
	}

	require.Greater(t, result.ActualNodes, 0, "Graph should contain nodes after adding")
	log.Infof("Total nodes in graph: %d", result.ActualNodes)

	// éªŒè¯æœç´¢åŠŸèƒ½æ­£å¸¸
	queryVec := generateRandomVector(dimension, rand.New(rand.NewSource(44)))
	results := g.Search(queryVec, 10)
	result.SearchResults = len(results)
	require.NotEmpty(t, results, "Search should return results")
	log.Infof("Search returned %d results", result.SearchResults)

	// ä¼°ç®—å†…å­˜ä½¿ç”¨
	totalConnections := 0
	for _, layer := range g.Layers {
		for _, node := range layer.Nodes {
			totalConnections += len(node.GetNeighbors())
		}
	}

	if result.ActualNodes > 0 {
		vectorMemory := dimension * 4 // float32
		avgConnections := float64(totalConnections) / float64(result.ActualNodes)
		connectionMemory := int(avgConnections * 8)
		metadataMemory := 50
		estimatedMemoryPerNode := vectorMemory + connectionMemory + metadataMemory
		result.MemoryEstimateKB = float64(estimatedMemoryPerNode*result.ActualNodes) / 1024
	}

	// è¾“å‡ºæ ¼å¼åŒ–çš„æ€§èƒ½æŒ‡æ ‡
	fmt.Print(result.String())

	return result
}

// TestHNSWPerformance1K æµ‹è¯•åœ¨1000ä¸ªèŠ‚ç‚¹åŸºç¡€ä¸Šæ·»åŠ å•ä¸ªèŠ‚ç‚¹çš„æ€§èƒ½
func TestHNSWPerformance1K(t *testing.T) {
	t.Run("Add1NodeTo1K_128D", func(t *testing.T) {
		measureAddPerformance(t, 1000, 1, 128) // 128ç»´å‘é‡
	})

	t.Run("Add10NodesTo1K_128D", func(t *testing.T) {
		measureAddPerformance(t, 1000, 10, 128)
	})

	t.Run("Add100NodesTo1K_128D", func(t *testing.T) {
		measureAddPerformance(t, 1000, 100, 128)
	})

	// 1024ç»´åº¦æµ‹è¯•
	t.Run("Add1NodeTo1K_1024D", func(t *testing.T) {
		measureAddPerformance(t, 1000, 1, 1024) // 1024ç»´å‘é‡
	})

	t.Run("Add10NodesTo1K_1024D", func(t *testing.T) {
		measureAddPerformance(t, 1000, 10, 1024)
	})

	t.Run("Add100NodesTo1K_1024D", func(t *testing.T) {
		measureAddPerformance(t, 1000, 100, 1024)
	})
}

// TestHNSWPerformance10K æµ‹è¯•åœ¨10000ä¸ªèŠ‚ç‚¹åŸºç¡€ä¸Šæ·»åŠ èŠ‚ç‚¹çš„æ€§èƒ½
func TestHNSWPerformance10K(t *testing.T) {
	t.Run("Add1NodeTo10K_128D", func(t *testing.T) {
		measureAddPerformance(t, 10000, 1, 128) // 128ç»´å‘é‡
	})

	t.Run("Add10NodesTo10K_128D", func(t *testing.T) {
		measureAddPerformance(t, 10000, 10, 128)
	})

	t.Run("Add100NodesTo10K_128D", func(t *testing.T) {
		measureAddPerformance(t, 10000, 100, 128)
	})

	// 1024ç»´åº¦æµ‹è¯•
	t.Run("Add1NodeTo10K_1024D", func(t *testing.T) {
		measureAddPerformance(t, 10000, 1, 1024) // 1024ç»´å‘é‡
	})

	t.Run("Add10NodesTo10K_1024D", func(t *testing.T) {
		measureAddPerformance(t, 10000, 10, 1024)
	})

	t.Run("Add100NodesTo10K_1024D", func(t *testing.T) {
		measureAddPerformance(t, 10000, 100, 1024)
	})
}

// BenchmarkHNSWAdd1K åŸºå‡†æµ‹è¯•ï¼šåœ¨1KèŠ‚ç‚¹åŸºç¡€ä¸Šæ·»åŠ å•ä¸ªèŠ‚ç‚¹
func BenchmarkHNSWAdd1K(b *testing.B) {
	// é¢„åˆ›å»ºå›¾å’Œåˆå§‹èŠ‚ç‚¹
	g := NewGraph[int]()
	g.Rng = rand.New(rand.NewSource(42))
	initialNodes := generateRandomNodes(1000, 128, 42)
	g.Add(initialNodes...)

	// å‡†å¤‡è¦æ·»åŠ çš„èŠ‚ç‚¹
	newNodes := generateRandomNodes(b.N, 128, 43)

	b.ResetTimer()
	b.ReportAllocs()

	for i := 0; i < b.N; i++ {
		g.Add(newNodes[i])
	}
}

// BenchmarkHNSWAdd1K_1024D åŸºå‡†æµ‹è¯•ï¼šåœ¨1KèŠ‚ç‚¹åŸºç¡€ä¸Šæ·»åŠ å•ä¸ª1024ç»´èŠ‚ç‚¹
func BenchmarkHNSWAdd1K_1024D(b *testing.B) {
	// é¢„åˆ›å»ºå›¾å’Œåˆå§‹èŠ‚ç‚¹
	g := NewGraph[int]()
	g.Rng = rand.New(rand.NewSource(42))
	initialNodes := generateRandomNodes(1000, 1024, 42)
	g.Add(initialNodes...)

	// å‡†å¤‡è¦æ·»åŠ çš„èŠ‚ç‚¹
	newNodes := generateRandomNodes(b.N, 1024, 43)

	b.ResetTimer()
	b.ReportAllocs()

	for i := 0; i < b.N; i++ {
		g.Add(newNodes[i])
	}
}

// BenchmarkHNSWAdd10K åŸºå‡†æµ‹è¯•ï¼šåœ¨10KèŠ‚ç‚¹åŸºç¡€ä¸Šæ·»åŠ å•ä¸ªèŠ‚ç‚¹
func BenchmarkHNSWAdd10K(b *testing.B) {
	// é¢„åˆ›å»ºå›¾å’Œåˆå§‹èŠ‚ç‚¹
	g := NewGraph[int]()
	g.Rng = rand.New(rand.NewSource(42))
	initialNodes := generateRandomNodes(10000, 128, 42)
	g.Add(initialNodes...)

	// å‡†å¤‡è¦æ·»åŠ çš„èŠ‚ç‚¹
	newNodes := generateRandomNodes(b.N, 128, 43)

	b.ResetTimer()
	b.ReportAllocs()

	for i := 0; i < b.N; i++ {
		g.Add(newNodes[i])
	}
}

// BenchmarkHNSWAdd10K_1024D åŸºå‡†æµ‹è¯•ï¼šåœ¨10KèŠ‚ç‚¹åŸºç¡€ä¸Šæ·»åŠ å•ä¸ª1024ç»´èŠ‚ç‚¹
func BenchmarkHNSWAdd10K_1024D(b *testing.B) {
	// é¢„åˆ›å»ºå›¾å’Œåˆå§‹èŠ‚ç‚¹
	g := NewGraph[int]()
	g.Rng = rand.New(rand.NewSource(42))
	initialNodes := generateRandomNodes(10000, 1024, 42)
	g.Add(initialNodes...)

	// å‡†å¤‡è¦æ·»åŠ çš„èŠ‚ç‚¹
	newNodes := generateRandomNodes(b.N, 1024, 43)

	b.ResetTimer()
	b.ReportAllocs()

	for i := 0; i < b.N; i++ {
		g.Add(newNodes[i])
	}
}

// TestHNSWScalabilityAnalysis åˆ†æHNSWçš„å¯æ‰©å±•æ€§
func TestHNSWScalabilityAnalysis(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping scalability analysis in short mode")
	}

	sizes := []int{100, 500, 1000, 2000, 5000, 10000}
	dimension := 128

	fmt.Println("\n=== HNSW Scalability Analysis ===")
	fmt.Printf("%-8s %-12s %-15s %-12s\n", "Size", "Duration", "Avg per Node", "Nodes/sec")
	fmt.Println("----------------------------------------")

	for _, size := range sizes {
		// åˆ›å»ºæ–°å›¾
		g := NewGraph[int]()
		g.Rng = rand.New(rand.NewSource(42))

		// ç”ŸæˆèŠ‚ç‚¹
		nodes := generateRandomNodes(size, dimension, 42)

		// æµ‹é‡æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹çš„æ—¶é—´
		start := time.Now()
		g.Add(nodes...)
		duration := time.Since(start)

		avgPerNode := duration / time.Duration(size)
		nodesPerSec := float64(size) / duration.Seconds()

		fmt.Printf("%-8d %-12v %-15v %-12.2f\n",
			size, duration, avgPerNode, nodesPerSec)

		// éªŒè¯å›¾çš„åŸºæœ¬åŠŸèƒ½
		queryVec := generateRandomVector(dimension, rand.New(rand.NewSource(44)))
		results := g.Search(queryVec, 5)
		require.NotEmpty(t, results, "Search should return results for size %d", size)
	}

	fmt.Println("====================================")
}

// TestHNSWScalabilityAnalysis1024D åˆ†æHNSWåœ¨1024ç»´åº¦ä¸‹çš„å¯æ‰©å±•æ€§
func TestHNSWScalabilityAnalysis1024D(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping 1024D scalability analysis in short mode")
	}

	sizes := []int{100, 500, 1000, 2000, 5000}
	dimension := 1024

	fmt.Println("\n=== HNSW 1024D Scalability Analysis ===")
	fmt.Printf("%-8s %-12s %-15s %-12s %-15s\n", "Size", "Duration", "Avg per Node", "Nodes/sec", "Memory Est(KB)")
	fmt.Println("----------------------------------------------------------")

	for _, size := range sizes {
		// åˆ›å»ºæ–°å›¾
		g := NewGraph[int]()
		g.Rng = rand.New(rand.NewSource(42))

		// ç”ŸæˆèŠ‚ç‚¹
		nodes := generateRandomNodes(size, dimension, 42)

		// æµ‹é‡æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹çš„æ—¶é—´
		start := time.Now()
		g.Add(nodes...)
		duration := time.Since(start)

		avgPerNode := duration / time.Duration(size)
		nodesPerSec := float64(size) / duration.Seconds()

		// ä¼°ç®—å†…å­˜ä½¿ç”¨
		totalNodes := 0
		totalConnections := 0
		for _, layer := range g.Layers {
			totalNodes += len(layer.Nodes)
			for _, node := range layer.Nodes {
				totalConnections += len(node.GetNeighbors())
			}
		}

		// ç²—ç•¥å†…å­˜ä¼°ç®— (å‘é‡ + è¿æ¥ + å…ƒæ•°æ®)
		vectorMemory := dimension * 4 // float32
		avgConnections := float64(totalConnections) / float64(totalNodes)
		connectionMemory := int(avgConnections * 8) // å‡è®¾è¿æ¥å 8å­—èŠ‚
		metadataMemory := 50
		estimatedMemoryPerNode := vectorMemory + connectionMemory + metadataMemory
		totalEstimatedMemoryKB := float64(estimatedMemoryPerNode*totalNodes) / 1024

		fmt.Printf("%-8d %-12v %-15v %-12.2f %-15.2f\n",
			size, duration, avgPerNode, nodesPerSec, totalEstimatedMemoryKB)

		// éªŒè¯å›¾çš„åŸºæœ¬åŠŸèƒ½
		queryVec := generateRandomVector(dimension, rand.New(rand.NewSource(44)))
		results := g.Search(queryVec, 5)
		require.NotEmpty(t, results, "Search should return results for size %d", size)

		log.Infof("1024D test completed for size %d: %v avg per node, %.2f nodes/sec",
			size, avgPerNode, nodesPerSec)
	}

	fmt.Println("======================================================")
}

// TestHNSWMemoryUsageEstimate ä¼°ç®—å†…å­˜ä½¿ç”¨æƒ…å†µ
func TestHNSWMemoryUsageEstimate(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping memory usage test in short mode")
	}

	// ä½¿ç”¨è¾ƒå°çš„æ•°æ®é›†æ¥ä¼°ç®—å†…å­˜ä½¿ç”¨
	sizes := []int{100, 500, 1000}
	dimension := 128

	fmt.Println("\n=== HNSW Memory Usage Estimation ===")

	for _, size := range sizes {
		g := NewGraph[int]()
		g.Rng = rand.New(rand.NewSource(42))

		nodes := generateRandomNodes(size, dimension, 42)
		g.Add(nodes...)

		// ç»Ÿè®¡å±‚çº§å’ŒèŠ‚ç‚¹ä¿¡æ¯
		totalNodes := 0
		totalConnections := 0
		for layerIdx, layer := range g.Layers {
			nodeCount := len(layer.Nodes)
			connectionCount := 0
			for _, node := range layer.Nodes {
				connectionCount += len(node.GetNeighbors())
			}

			totalNodes += nodeCount
			totalConnections += connectionCount

			fmt.Printf("Size %d - Layer %d: %d nodes, %d connections\n",
				size, layerIdx, nodeCount, connectionCount)
		}

		avgConnectionsPerNode := float64(totalConnections) / float64(totalNodes)
		fmt.Printf("Size %d - Total: %d nodes, %d connections, avg %.2f connections/node\n",
			size, totalNodes, totalConnections, avgConnectionsPerNode)

		// ä¼°ç®—æ¯ä¸ªèŠ‚ç‚¹çš„å†…å­˜å ç”¨ï¼ˆç²—ç•¥ä¼°ç®—ï¼‰
		// å‘é‡: dimension * 4 bytes (float32)
		// è¿æ¥: avgConnectionsPerNode * 8 bytes (å‡è®¾keyä¸ºint64)
		// å…¶ä»–å…ƒæ•°æ®: ~50 bytes
		vectorMemory := dimension * 4
		connectionMemory := int(avgConnectionsPerNode * 8)
		metadataMemory := 50
		estimatedMemoryPerNode := vectorMemory + connectionMemory + metadataMemory
		totalEstimatedMemory := estimatedMemoryPerNode * totalNodes

		fmt.Printf("Size %d - Estimated memory per node: %d bytes, total: %.2f KB\n",
			size, estimatedMemoryPerNode, float64(totalEstimatedMemory)/1024)
		fmt.Println()
	}

	fmt.Println("=====================================")
}

// TestHNSWDimensionComparison æ¯”è¾ƒä¸åŒç»´åº¦ä¸‹çš„æ€§èƒ½
func TestHNSWDimensionComparison(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping dimension comparison test in short mode")
	}

	dimensions := []int{128, 256, 512, 1024}
	nodeCount := 1000

	fmt.Println("\n=== HNSW Dimension Performance Comparison ===")
	fmt.Printf("%-10s %-12s %-15s %-12s %-15s\n", "Dimension", "Duration", "Avg per Node", "Nodes/sec", "Memory Est(KB)")
	fmt.Println("-------------------------------------------------------------")

	for _, dim := range dimensions {
		// åˆ›å»ºæ–°å›¾
		g := NewGraph[int]()
		g.Rng = rand.New(rand.NewSource(42))

		// ç”ŸæˆèŠ‚ç‚¹
		nodes := generateRandomNodes(nodeCount, dim, 42)

		// æµ‹é‡æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹çš„æ—¶é—´
		start := time.Now()
		g.Add(nodes...)
		duration := time.Since(start)

		avgPerNode := duration / time.Duration(nodeCount)
		nodesPerSec := float64(nodeCount) / duration.Seconds()

		// ä¼°ç®—å†…å­˜ä½¿ç”¨
		totalNodes := 0
		totalConnections := 0
		for _, layer := range g.Layers {
			totalNodes += len(layer.Nodes)
			for _, node := range layer.Nodes {
				totalConnections += len(node.GetNeighbors())
			}
		}

		// ç²—ç•¥å†…å­˜ä¼°ç®—
		vectorMemory := dim * 4 // float32
		avgConnections := float64(totalConnections) / float64(totalNodes)
		connectionMemory := int(avgConnections * 8)
		metadataMemory := 50
		estimatedMemoryPerNode := vectorMemory + connectionMemory + metadataMemory
		totalEstimatedMemoryKB := float64(estimatedMemoryPerNode*totalNodes) / 1024

		fmt.Printf("%-10d %-12v %-15v %-12.2f %-15.2f\n",
			dim, duration, avgPerNode, nodesPerSec, totalEstimatedMemoryKB)

		// éªŒè¯æœç´¢åŠŸèƒ½
		queryVec := generateRandomVector(dim, rand.New(rand.NewSource(44)))
		results := g.Search(queryVec, 5)
		require.NotEmpty(t, results, "Search should return results for dimension %d", dim)

		log.Infof("Dimension %d test completed: %v avg per node, %.2f nodes/sec",
			dim, avgPerNode, nodesPerSec)
	}

	fmt.Println("=============================================================")
}

// TestHNSW10KDataDetailedAnalysis é’ˆå¯¹10Kæ•°æ®çš„è¯¦ç»†æ€§èƒ½åˆ†æ
func TestHNSW10KDataDetailedAnalysis(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping 10K detailed analysis in short mode")
	}

	dimensions := []int{128, 512, 1024}

	fmt.Println("\n" + strings.Repeat("=", 80))
	fmt.Println("                    HNSW 10K Data Detailed Performance Analysis")
	fmt.Println(strings.Repeat("=", 80))

	var allResults []PerformanceResult

	for _, dim := range dimensions {
		fmt.Printf("\nğŸ” Testing Dimension: %d\n", dim)
		fmt.Println(strings.Repeat("-", 50))

		// æµ‹è¯•ä¸åŒçš„æ·»åŠ åœºæ™¯
		scenarios := []struct {
			name         string
			initialNodes int
			addNodes     int
		}{
			{"Build 10K from scratch", 0, 10000},
			{"Add 1 to 10K", 10000, 1},
			{"Add 10 to 10K", 10000, 10},
			{"Add 100 to 10K", 10000, 100},
		}

		for _, scenario := range scenarios {
			fmt.Printf("\nğŸ“Š Scenario: %s\n", scenario.name)
			result := measureAddPerformance(t, scenario.initialNodes, scenario.addNodes, dim)
			allResults = append(allResults, result)

			// æ€§èƒ½è¯„ä¼°
			if result.AvgPerNode > 10*time.Millisecond {
				log.Warnf("Performance warning: avg time per node (%v) exceeds 10ms threshold", result.AvgPerNode)
			}
			if result.NodesPerSecond < 100 {
				log.Warnf("Throughput warning: processing rate (%.2f nodes/sec) is below 100 nodes/sec", result.NodesPerSecond)
			}
		}
	}

	// ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
	fmt.Println("\n" + strings.Repeat("=", 80))
	fmt.Println("                              Summary Report")
	fmt.Println(strings.Repeat("=", 80))

	fmt.Printf("%-25s %-8s %-12s %-15s %-12s %-15s\n",
		"Scenario", "Dim", "Add Nodes", "Duration", "Avg/Node", "Memory(KB)")
	fmt.Println(strings.Repeat("-", 100))

	for _, result := range allResults {
		scenarioName := ""
		if result.InitialNodes == 0 {
			scenarioName = "Build from scratch"
		} else {
			scenarioName = fmt.Sprintf("Add %d to %dk", result.AddedNodes, result.InitialNodes/1000)
		}

		fmt.Printf("%-25s %-8d %-12d %-15v %-12v %-15.1f\n",
			scenarioName, result.Dimension, result.AddedNodes,
			result.AddDuration, result.AvgPerNode, result.MemoryEstimateKB)
	}

	fmt.Println(strings.Repeat("=", 80))
}

// TestHNSWStressTest10K 10Kæ•°æ®å‹åŠ›æµ‹è¯•
func TestHNSWStressTest10K(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping 10K stress test in short mode")
	}

	fmt.Println("\nğŸš€ HNSW 10K Stress Test")
	fmt.Println("Testing incremental additions with performance monitoring...")

	g := NewGraph[int]()
	g.Rng = rand.New(rand.NewSource(42))
	dimension := 512 // ä¸­ç­‰ç»´åº¦

	// åˆ†æ‰¹æ·»åŠ èŠ‚ç‚¹ï¼Œç›‘æ§æ€§èƒ½å˜åŒ–
	batchSizes := []int{1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000}

	fmt.Printf("\n%-8s %-12s %-15s %-12s %-15s\n",
		"Nodes", "Duration", "Avg/Node", "Nodes/sec", "Memory(KB)")
	fmt.Println(strings.Repeat("-", 70))

	var cumulativeResults []PerformanceResult

	for i, targetSize := range batchSizes {
		currentSize := 0
		if i > 0 {
			currentSize = batchSizes[i-1]
		}

		batchSize := targetSize - currentSize
		newNodes := generateRandomNodes(batchSize, dimension, int64(42+i))

		start := time.Now()
		g.Add(newNodes...)
		duration := time.Since(start)

		avgPerNode := duration / time.Duration(batchSize)
		nodesPerSec := float64(batchSize) / duration.Seconds()

		// è®¡ç®—å†…å­˜ä¼°ç®—
		totalNodes := 0
		totalConnections := 0
		for _, layer := range g.Layers {
			totalNodes += len(layer.Nodes)
			for _, node := range layer.Nodes {
				totalConnections += len(node.GetNeighbors())
			}
		}

		var memoryKB float64
		if totalNodes > 0 {
			vectorMemory := dimension * 4
			avgConnections := float64(totalConnections) / float64(totalNodes)
			connectionMemory := int(avgConnections * 8)
			metadataMemory := 50
			estimatedMemoryPerNode := vectorMemory + connectionMemory + metadataMemory
			memoryKB = float64(estimatedMemoryPerNode*totalNodes) / 1024
		}

		fmt.Printf("%-8d %-12v %-15v %-12.2f %-15.1f\n",
			targetSize, duration, avgPerNode, nodesPerSec, memoryKB)

		result := PerformanceResult{
			InitialNodes:     currentSize,
			AddedNodes:       batchSize,
			Dimension:        dimension,
			AddDuration:      duration,
			AvgPerNode:       avgPerNode,
			NodesPerSecond:   nodesPerSec,
			ActualNodes:      totalNodes,
			MemoryEstimateKB: memoryKB,
		}
		cumulativeResults = append(cumulativeResults, result)

		// æ€§èƒ½è­¦å‘Š
		if avgPerNode > 20*time.Millisecond {
			log.Warnf("âš ï¸  Performance degradation detected at %d nodes: %v avg per node", targetSize, avgPerNode)
		}

		// éªŒè¯æœç´¢åŠŸèƒ½
		queryVec := generateRandomVector(dimension, rand.New(rand.NewSource(44+int64(i))))
		results := g.Search(queryVec, 10)
		require.NotEmpty(t, results, "Search should return results at %d nodes", targetSize)
	}

	// åˆ†ææ€§èƒ½è¶‹åŠ¿
	fmt.Println("\nğŸ“ˆ Performance Trend Analysis:")
	for i := 1; i < len(cumulativeResults); i++ {
		prev := cumulativeResults[i-1]
		curr := cumulativeResults[i]

		perfChange := (curr.AvgPerNode.Nanoseconds() - prev.AvgPerNode.Nanoseconds()) * 100 / prev.AvgPerNode.Nanoseconds()
		fmt.Printf("   %d â†’ %d nodes: Performance change: %+.1f%%\n",
			prev.InitialNodes+prev.AddedNodes, curr.InitialNodes+curr.AddedNodes, float64(perfChange))
	}

	fmt.Println(strings.Repeat("=", 70))
}
