package hnsw

import (
	"bytes"
	"context"
	"fmt"
	"io"
	"math/rand"
	"strings"
	"testing"

	"github.com/davecgh/go-spew/spew"
	"github.com/stretchr/testify/require"
	"github.com/yaklang/yaklang/common/utils"
)

func TestLoadBinaryRoundTrip(t *testing.T) {
	// åˆ›å»ºä¸€ä¸ªç®€å•çš„ Persistent å¯¹è±¡
	p := &Persistent[string]{
		Total:      3,
		Dims:       4,
		M:          16,
		Ml:         0.5,
		EfSearch:   200,
		ExportMode: ExportModeStandard,
		Layers: []*PersistentLayer{
			{HNSWLevel: 0, Nodes: []uint32{1, 2, 3}},
			{HNSWLevel: 1, Nodes: []uint32{1, 2}},
		},
		OffsetToKey: []*PersistentNode[string]{
			{Key: "", Code: []float64{0.0, 0.0, 0.0, 0.0}}, // 0 offset - reserve node
			{Key: "a", Code: []float64{1.0, 2.0, 3.0, 4.0}},
			{Key: "b", Code: []float64{5.0, 6.0, 7.0, 8.0}},
			{Key: "c", Code: []float64{9.0, 10.0, 11.0, 12.0}},
		},
		Neighbors: map[uint32][]uint32{
			1: {2, 3},
			2: {1, 3},
			3: {1, 2},
		},
	}

	// å¯¼å‡ºåˆ°äºŒè¿›åˆ¶
	ctx := context.Background()
	reader, err := p.ToBinary(ctx)
	require.NoError(t, err)

	// ä»äºŒè¿›åˆ¶åŠ è½½
	loaded, err := LoadBinary[string](reader)
	require.NoError(t, err)

	// éªŒè¯å­—æ®µ
	require.Equal(t, p.Total, loaded.Total)
	require.Equal(t, p.Dims, loaded.Dims)
	require.Equal(t, p.M, loaded.M)
	require.Equal(t, p.Ml, loaded.Ml)
	require.Equal(t, p.EfSearch, loaded.EfSearch)
	require.Equal(t, p.ExportMode, loaded.ExportMode)

	// éªŒè¯å±‚
	require.Len(t, loaded.Layers, len(p.Layers))
	for i := range p.Layers {
		require.Equal(t, p.Layers[i].HNSWLevel, loaded.Layers[i].HNSWLevel)
		require.Equal(t, p.Layers[i].Nodes, loaded.Layers[i].Nodes)
	}

	// éªŒè¯èŠ‚ç‚¹
	require.Len(t, loaded.OffsetToKey, len(p.OffsetToKey))
	for i := range p.OffsetToKey {
		require.Equal(t, p.OffsetToKey[i].Code, loaded.OffsetToKey[i].Code)
	}

	// éªŒè¯é‚»å±…
	require.Len(t, loaded.Neighbors, len(p.Neighbors))
	for k, v := range p.Neighbors {
		require.Equal(t, v, loaded.Neighbors[k])
	}
}

func TestLoadBinaryRoundTripPQ(t *testing.T) {
	// åˆ›å»ºä¸€ä¸ªå¸¦ PQ çš„ Persistent å¯¹è±¡
	p := &Persistent[string]{
		Total:      2,
		Dims:       4,
		M:          16,
		Ml:         0.5,
		EfSearch:   200,
		ExportMode: ExportModePQ,
		PQCodebook: &PersistentPQCodebook{
			M:              2,
			K:              256,
			SubVectorDim:   2,
			PQCodeByteSize: 2,
			Centroids:      [][][]float64{{{1.0, 2.0}, {3.0, 4.0}}, {{5.0, 6.0}, {7.0, 8.0}}},
		},
		Layers: []*PersistentLayer{
			{HNSWLevel: 0, Nodes: []uint32{1, 2}},
		},
		OffsetToKey: []*PersistentNode[string]{
			{Key: "", Code: []byte{0, 0}}, // 0 offset - reserve node
			{Key: "a", Code: []byte{1, 2}},
			{Key: "b", Code: []byte{3, 4}},
		},
		Neighbors: map[uint32][]uint32{
			1: {2},
			2: {1},
		},
	}

	// å¯¼å‡ºåˆ°äºŒè¿›åˆ¶
	ctx := context.Background()
	reader, err := p.ToBinary(ctx)
	require.NoError(t, err)

	// ä»äºŒè¿›åˆ¶åŠ è½½
	loaded, err := LoadBinary[string](reader)
	require.NoError(t, err)

	// éªŒè¯å­—æ®µ
	require.Equal(t, p.Total, loaded.Total)
	require.Equal(t, p.Dims, loaded.Dims)
	require.Equal(t, p.M, loaded.M)
	require.Equal(t, p.Ml, loaded.Ml)
	require.Equal(t, p.EfSearch, loaded.EfSearch)
	require.Equal(t, p.ExportMode, loaded.ExportMode)

	// éªŒè¯ PQ ç æœ¬
	require.NotNil(t, loaded.PQCodebook)
	require.Equal(t, p.PQCodebook.M, loaded.PQCodebook.M)
	require.Equal(t, p.PQCodebook.K, loaded.PQCodebook.K)
	require.Equal(t, p.PQCodebook.SubVectorDim, loaded.PQCodebook.SubVectorDim)
	require.Equal(t, p.PQCodebook.PQCodeByteSize, loaded.PQCodebook.PQCodeByteSize)
	require.Equal(t, p.PQCodebook.Centroids, loaded.PQCodebook.Centroids)

	// éªŒè¯èŠ‚ç‚¹
	require.Len(t, loaded.OffsetToKey, len(p.OffsetToKey))
	for i := range p.OffsetToKey {
		require.Equal(t, p.OffsetToKey[i].Code, loaded.OffsetToKey[i].Code)
	}
}

func TestLoadBinaryEmpty(t *testing.T) {
	// æµ‹è¯•ç©ºæ•°æ®
	empty := bytes.NewReader([]byte(""))
	_, err := LoadBinary[string](empty)
	require.Error(t, err)

	// æµ‹è¯•æ— æ•ˆé­”æ•°
	invalid := bytes.NewReader([]byte("INVALID"))
	_, err = LoadBinary[string](invalid)
	require.Error(t, err)
}

func TestExportGraphToBinaryStandard(t *testing.T) {
	// åˆ›å»ºæ ‡å‡†æ¨¡å¼çš„å›¾
	graph := NewGraph[string](
		WithM[string](16),
		WithMl[string](0.5),
		WithEfSearch[string](200),
		WithCosineDistance[string](),
	)

	// æ·»åŠ æµ‹è¯•èŠ‚ç‚¹
	nodes := []InputNode[string]{
		{Key: "node1", Value: []float32{1.0, 2.0, 3.0, 4.0}},
		{Key: "node2", Value: []float32{5.0, 6.0, 7.0, 8.0}},
		{Key: "node3", Value: []float32{9.0, 10.0, 11.0, 12.0}},
	}
	graph.Add(nodes...)

	// éªŒè¯å›¾ç»“æ„
	require.True(t, len(graph.Layers) > 0)
	require.True(t, len(graph.Layers[0].Nodes) > 0)

	// å¯¼å‡ºåˆ° Persistent
	pers, err := ExportHNSWGraph(graph)
	require.NoError(t, err)
	require.NotNil(t, pers)
	require.True(t, pers.Total >= uint32(3)) // å¯èƒ½åŒ…å«é¢å¤–çš„èŠ‚ç‚¹
	require.Equal(t, uint32(4), pers.Dims)
	require.Equal(t, ExportModeStandard, pers.ExportMode)

	// å¯¼å‡ºåˆ°äºŒè¿›åˆ¶
	ctx := context.Background()
	reader, err := pers.ToBinary(ctx)
	require.NoError(t, err)

	// ä»äºŒè¿›åˆ¶åŠ è½½å›æ¥
	loaded, err := LoadBinary[string](reader)
	require.NoError(t, err)

	// éªŒè¯åŠ è½½çš„ç»“æœ
	require.Equal(t, pers.Total, loaded.Total)
	require.Equal(t, pers.Dims, loaded.Dims)
	require.Equal(t, pers.M, loaded.M)
	require.Equal(t, pers.Ml, loaded.Ml)
	require.Equal(t, pers.EfSearch, loaded.EfSearch)
	require.Equal(t, pers.ExportMode, loaded.ExportMode)
}

func TestExportGraphToBinaryPQ(t *testing.T) {
	// åˆ›å»ºæ ‡å‡†æ¨¡å¼çš„å›¾
	graph := NewGraph[string](
		WithM[string](16),
		WithMl[string](0.5),
		WithEfSearch[string](200),
		WithCosineDistance[string](),
	)

	// æ·»åŠ æµ‹è¯•èŠ‚ç‚¹
	nodes := []InputNode[string]{
		{Key: "node1", Value: []float32{1.0, 2.0, 3.0, 4.0}},
		{Key: "node2", Value: []float32{5.0, 6.0, 7.0, 8.0}},
		{Key: "node3", Value: []float32{9.0, 10.0, 11.0, 12.0}},
		{Key: "node4", Value: []float32{2.0, 3.0, 4.0, 5.0}},
		{Key: "node5", Value: []float32{6.0, 7.0, 8.0, 9.0}},
		{Key: "node6", Value: []float32{10.0, 11.0, 12.0, 13.0}},
		{Key: "node7", Value: []float32{3.0, 4.0, 5.0, 6.0}},
		{Key: "node8", Value: []float32{7.0, 8.0, 9.0, 10.0}},
	}
	graph.Add(nodes...)

	// éªŒè¯å›¾åˆå§‹çŠ¶æ€
	require.False(t, graph.IsPQEnabled())
	require.True(t, len(graph.Layers) > 0)
	require.True(t, len(graph.Layers[0].Nodes) >= 8)

	// ä»ç°æœ‰æ•°æ®è®­ç»ƒPQç è¡¨
	cookbook, err := graph.TrainPQCodebookFromData(2, 4)
	require.NoError(t, err)
	_ = cookbook

	// éªŒè¯PQè®­ç»ƒæˆåŠŸ
	require.True(t, graph.IsPQEnabled())
	require.NotNil(t, graph.pqCodebook)
	require.NotNil(t, graph.pqQuantizer)

	// éªŒè¯æ‰€æœ‰èŠ‚ç‚¹éƒ½è½¬æ¢ä¸ºPQèŠ‚ç‚¹
	convertedCount := 0
	for _, layer := range graph.Layers {
		for _, node := range layer.Nodes {
			if node.IsPQEnabled() {
				convertedCount++
				// ç¡®ä¿PQ codeså­˜åœ¨ä¸”é•¿åº¦æ­£ç¡®
				codes, ok := node.GetPQCodes()
				require.True(t, ok, "PQ node should have codes")
				require.Equal(t, 2, len(codes), "PQ codes should be length 2")
			}
		}
	}
	require.True(t, convertedCount > 0)

	// å¯¼å‡ºåˆ° Persistent
	pers, err := ExportHNSWGraph(graph)
	require.NoError(t, err)
	require.NotNil(t, pers)
	require.Equal(t, ExportModePQ, pers.ExportMode)
	require.NotNil(t, pers.PQCodebook)
	require.Equal(t, uint32(2), pers.PQCodebook.M)
	require.Equal(t, uint32(4), pers.PQCodebook.K)

	// å¯¼å‡ºåˆ°äºŒè¿›åˆ¶
	ctx := context.Background()
	reader, err := pers.ToBinary(ctx)
	require.NoError(t, err)

	var buf bytes.Buffer
	raw, _ := io.ReadAll(io.TeeReader(reader, &buf))
	i := utils.ByteSize(uint64(len(raw)))
	fmt.Println(i)
	spew.Dump(raw)
	// ä»äºŒè¿›åˆ¶åŠ è½½å›æ¥
	loaded, err := LoadBinary[string](&buf)
	require.NoError(t, err)

	// éªŒè¯åŠ è½½çš„ç»“æœ
	require.Equal(t, pers.Total, loaded.Total)
	require.Equal(t, pers.Dims, loaded.Dims)
	require.Equal(t, ExportModePQ, loaded.ExportMode)
	require.NotNil(t, loaded.PQCodebook)
	require.Equal(t, pers.PQCodebook.M, loaded.PQCodebook.M)
	require.Equal(t, pers.PQCodebook.K, loaded.PQCodebook.K)

	// éªŒè¯PQç è¡¨æ•°æ®å®Œæ•´æ€§
	require.Equal(t, len(pers.PQCodebook.Centroids), len(loaded.PQCodebook.Centroids))
	for i := range pers.PQCodebook.Centroids {
		require.Equal(t, pers.PQCodebook.Centroids[i], loaded.PQCodebook.Centroids[i])
	}
}

func TestExportEmptyGraphToBinary(t *testing.T) {
	// åˆ›å»ºç©ºå›¾
	graph := NewGraph[string](
		WithM[string](16),
		WithMl[string](0.5),
		WithEfSearch[string](200),
		WithCosineDistance[string](),
	)

	// éªŒè¯å›¾ä¸ºç©º
	require.True(t, len(graph.Layers) == 0 || len(graph.Layers[0].Nodes) == 0)

	// å°è¯•å¯¼å‡ºç©ºå›¾åº”è¯¥å¤±è´¥
	_, err := ExportHNSWGraph(graph)
	require.Error(t, err)
	require.Contains(t, err.Error(), "graph is nil")
}

func TestKeyRoundTripInBinary(t *testing.T) {
	// æµ‹è¯•ä¸åŒç±»å‹çš„Keyåœ¨äºŒè¿›åˆ¶åºåˆ—åŒ–ä¸­çš„å®Œæ•´å¾ªç¯
	testCases := []struct {
		name  string
		key   string
		value []float32
	}{
		{"string_key", "test_key", []float32{1.0, 2.0, 3.0, 4.0}},
		{"numeric_string_key", "42", []float32{5.0, 6.0, 7.0, 8.0}},
		{"special_chars_key", "key-with_special.chars!", []float32{9.0, 10.0, 11.0, 12.0}},
		{"empty_string_key", "", []float32{13.0, 14.0, 15.0, 16.0}},
		{"unicode_key", "æµ‹è¯•_key_ğŸš€", []float32{17.0, 18.0, 19.0, 20.0}},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			// åˆ›å»ºåŒ…å«æµ‹è¯•Keyçš„Persistentå¯¹è±¡
			p := &Persistent[string]{
				Total:      2,
				Dims:       4,
				M:          16,
				Ml:         0.5,
				EfSearch:   200,
				ExportMode: ExportModeStandard,
				Layers: []*PersistentLayer{
					{HNSWLevel: 0, Nodes: []uint32{1}},
				},
				OffsetToKey: []*PersistentNode[string]{
					{Key: "", Code: []float64{0.0, 0.0, 0.0, 0.0}}, // 0 offset
					{Key: tc.key, Code: []float64{float64(tc.value[0]), float64(tc.value[1]), float64(tc.value[2]), float64(tc.value[3])}},
				},
				Neighbors: map[uint32][]uint32{
					1: {},
				},
			}

			// å¯¼å‡ºåˆ°äºŒè¿›åˆ¶
			ctx := context.Background()
			reader, err := p.ToBinary(ctx)
			require.NoError(t, err)

			// ä»äºŒè¿›åˆ¶åŠ è½½å›æ¥
			loaded, err := LoadBinary[string](reader)
			require.NoError(t, err)

			// éªŒè¯Keyè¢«æ­£ç¡®æ¢å¤
			require.Equal(t, tc.key, loaded.OffsetToKey[1].Key)
		})
	}
}

func TestKeyConversionErrors(t *testing.T) {
	// æµ‹è¯•ä¸åŒæ³›å‹ç±»å‹ä¸‹çš„Keyè½¬æ¢
	t.Run("int_type_conversion", func(t *testing.T) {
		// åˆ›å»ºä¸€ä¸ªintç±»å‹çš„Persistent
		p := &Persistent[int]{
			Total:      2,
			Dims:       4,
			M:          16,
			Ml:         0.5,
			EfSearch:   200,
			ExportMode: ExportModeStandard,
			Layers: []*PersistentLayer{
				{HNSWLevel: 0, Nodes: []uint32{1}},
			},
			OffsetToKey: []*PersistentNode[int]{
				{Key: 0, Code: []float64{0.0, 0.0, 0.0, 0.0}},
				{Key: 42, Code: []float64{1.0, 2.0, 3.0, 4.0}},
			},
			Neighbors: map[uint32][]uint32{1: {}},
		}

		ctx := context.Background()
		reader, err := p.ToBinary(ctx)
		require.NoError(t, err)

		loaded, err := LoadBinary[int](reader)
		require.NoError(t, err)
		require.Equal(t, 42, loaded.OffsetToKey[1].Key)
	})

	t.Run("int64_type_conversion", func(t *testing.T) {
		// åˆ›å»ºä¸€ä¸ªint64ç±»å‹çš„Persistent
		p := &Persistent[int64]{
			Total:      2,
			Dims:       4,
			M:          16,
			Ml:         0.5,
			EfSearch:   200,
			ExportMode: ExportModeStandard,
			Layers: []*PersistentLayer{
				{HNSWLevel: 0, Nodes: []uint32{1}},
			},
			OffsetToKey: []*PersistentNode[int64]{
				{Key: 0, Code: []float64{0.0, 0.0, 0.0, 0.0}},
				{Key: 123456789, Code: []float64{1.0, 2.0, 3.0, 4.0}},
			},
			Neighbors: map[uint32][]uint32{1: {}},
		}

		ctx := context.Background()
		reader, err := p.ToBinary(ctx)
		require.NoError(t, err)

		loaded, err := LoadBinary[int64](reader)
		require.NoError(t, err)
		require.Equal(t, int64(123456789), loaded.OffsetToKey[1].Key)
	})

	t.Run("uint32_type_conversion", func(t *testing.T) {
		// åˆ›å»ºä¸€ä¸ªuint32ç±»å‹çš„Persistent
		p := &Persistent[uint32]{
			Total:      2,
			Dims:       4,
			M:          16,
			Ml:         0.5,
			EfSearch:   200,
			ExportMode: ExportModeStandard,
			Layers: []*PersistentLayer{
				{HNSWLevel: 0, Nodes: []uint32{1}},
			},
			OffsetToKey: []*PersistentNode[uint32]{
				{Key: 0, Code: []float64{0.0, 0.0, 0.0, 0.0}},
				{Key: 65535, Code: []float64{1.0, 2.0, 3.0, 4.0}},
			},
			Neighbors: map[uint32][]uint32{1: {}},
		}

		ctx := context.Background()
		reader, err := p.ToBinary(ctx)
		require.NoError(t, err)

		loaded, err := LoadBinary[uint32](reader)
		require.NoError(t, err)
		require.Equal(t, uint32(65535), loaded.OffsetToKey[1].Key)
	})

	t.Run("uint64_type_conversion", func(t *testing.T) {
		// åˆ›å»ºä¸€ä¸ªuint64ç±»å‹çš„Persistent
		p := &Persistent[uint64]{
			Total:      2,
			Dims:       4,
			M:          16,
			Ml:         0.5,
			EfSearch:   200,
			ExportMode: ExportModeStandard,
			Layers: []*PersistentLayer{
				{HNSWLevel: 0, Nodes: []uint32{1}},
			},
			OffsetToKey: []*PersistentNode[uint64]{
				{Key: 0, Code: []float64{0.0, 0.0, 0.0, 0.0}},
				{Key: 18446744073709551615, Code: []float64{1.0, 2.0, 3.0, 4.0}}, // max uint64
			},
			Neighbors: map[uint32][]uint32{1: {}},
		}

		ctx := context.Background()
		reader, err := p.ToBinary(ctx)
		require.NoError(t, err)

		loaded, err := LoadBinary[uint64](reader)
		require.NoError(t, err)
		require.Equal(t, uint64(18446744073709551615), loaded.OffsetToKey[1].Key)
	})
}

func TestKeyEdgeCases(t *testing.T) {
	t.Run("very_long_key", func(t *testing.T) {
		// æµ‹è¯•éå¸¸é•¿çš„key
		longKey := strings.Repeat("a", 10000)
		p := &Persistent[string]{
			Total:      2,
			Dims:       4,
			M:          16,
			Ml:         0.5,
			EfSearch:   200,
			ExportMode: ExportModeStandard,
			Layers: []*PersistentLayer{
				{HNSWLevel: 0, Nodes: []uint32{1}},
			},
			OffsetToKey: []*PersistentNode[string]{
				{Key: "", Code: []float64{0.0, 0.0, 0.0, 0.0}},
				{Key: longKey, Code: []float64{1.0, 2.0, 3.0, 4.0}},
			},
			Neighbors: map[uint32][]uint32{1: {}},
		}

		ctx := context.Background()
		reader, err := p.ToBinary(ctx)
		require.NoError(t, err)

		loaded, err := LoadBinary[string](reader)
		require.NoError(t, err)
		require.Equal(t, longKey, loaded.OffsetToKey[1].Key)
	})

	t.Run("null_bytes_in_key", func(t *testing.T) {
		// æµ‹è¯•åŒ…å«nullå­—èŠ‚çš„key
		keyWithNull := "key\x00with\x00null"
		p := &Persistent[string]{
			Total:      2,
			Dims:       4,
			M:          16,
			Ml:         0.5,
			EfSearch:   200,
			ExportMode: ExportModeStandard,
			Layers: []*PersistentLayer{
				{HNSWLevel: 0, Nodes: []uint32{1}},
			},
			OffsetToKey: []*PersistentNode[string]{
				{Key: "", Code: []float64{0.0, 0.0, 0.0, 0.0}},
				{Key: keyWithNull, Code: []float64{1.0, 2.0, 3.0, 4.0}},
			},
			Neighbors: map[uint32][]uint32{1: {}},
		}

		ctx := context.Background()
		reader, err := p.ToBinary(ctx)
		require.NoError(t, err)

		loaded, err := LoadBinary[string](reader)
		require.NoError(t, err)
		require.Equal(t, keyWithNull, loaded.OffsetToKey[1].Key)
	})

	t.Run("binary_data_in_key", func(t *testing.T) {
		// æµ‹è¯•åŒ…å«äºŒè¿›åˆ¶æ•°æ®çš„keyï¼ˆéUTF-8ï¼‰
		binaryKey := string([]byte{0x00, 0x01, 0x02, 0xFF, 0xFE, 0xFD})
		p := &Persistent[string]{
			Total:      2,
			Dims:       4,
			M:          16,
			Ml:         0.5,
			EfSearch:   200,
			ExportMode: ExportModeStandard,
			Layers: []*PersistentLayer{
				{HNSWLevel: 0, Nodes: []uint32{1}},
			},
			OffsetToKey: []*PersistentNode[string]{
				{Key: "", Code: []float64{0.0, 0.0, 0.0, 0.0}},
				{Key: binaryKey, Code: []float64{1.0, 2.0, 3.0, 4.0}},
			},
			Neighbors: map[uint32][]uint32{1: {}},
		}

		ctx := context.Background()
		reader, err := p.ToBinary(ctx)
		require.NoError(t, err)

		loaded, err := LoadBinary[string](reader)
		require.NoError(t, err)
		require.Equal(t, binaryKey, loaded.OffsetToKey[1].Key)
	})
}

func TestSearchAfterSerializationRoundTrip(t *testing.T) {
	// æµ‹è¯•åºåˆ—åŒ–/ååºåˆ—åŒ–åæœç´¢åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ - è¿è¡Œ10æ¬¡ç¡®ä¿ç¨³å®šæ€§

	for round := 1; round <= 10; round++ {
		t.Run(fmt.Sprintf("Round_%d", round), func(t *testing.T) {
			// åˆ›å»ºåŸå§‹å›¾å¹¶æ·»åŠ èŠ‚ç‚¹
			originalGraph := NewGraph[string](
				WithM[string](16),
				WithMl[string](0.5),
				WithEfSearch[string](20),
				WithCosineDistance[string](),
				WithDeterministicRng[string](int64(round)), // ä½¿ç”¨ä¸åŒçš„ç§å­ç¡®ä¿æ¯è½®æµ‹è¯•çš„å¤šæ ·æ€§
			)

			// æ·»åŠ æµ‹è¯•èŠ‚ç‚¹ - ä½¿ç”¨ä¸åŒçš„å‘é‡ä»¥ä¾¿æœç´¢
			nodes := []InputNode[string]{
				{Key: "node1", Value: []float32{1.0, 0.0, 0.0, 0.0}}, // xè½´æ–¹å‘
				{Key: "node2", Value: []float32{0.0, 1.0, 0.0, 0.0}}, // yè½´æ–¹å‘
				{Key: "node3", Value: []float32{0.0, 0.0, 1.0, 0.0}}, // zè½´æ–¹å‘
				{Key: "node4", Value: []float32{0.7, 0.7, 0.0, 0.0}}, // ç¬¬ä¸€è±¡é™
				{Key: "node5", Value: []float32{0.5, 0.5, 0.5, 0.5}}, // å¯¹è§’çº¿æ–¹å‘
				{Key: "node6", Value: []float32{0.9, 0.1, 0.1, 0.1}}, // æ¥è¿‘node1
				{Key: "node7", Value: []float32{0.1, 0.9, 0.1, 0.1}}, // æ¥è¿‘node2
				{Key: "node8", Value: []float32{0.1, 0.1, 0.9, 0.1}}, // æ¥è¿‘node3
			}
			originalGraph.Add(nodes...)

			// åœ¨åŸå§‹å›¾ä¸Šè¿›è¡Œæœç´¢æµ‹è¯•
			queryVector := []float32{0.8, 0.2, 0.2, 0.2} // æ¥è¿‘node1å’Œnode6çš„æ–¹å‘
			originalResults := originalGraph.SearchWithDistance(queryVector, 3)
			require.True(t, len(originalResults) > 0, "ç¬¬%dè½®ï¼šåŸå§‹å›¾åº”è¯¥è¿”å›æœç´¢ç»“æœ", round)

			// è®°å½•åŸå§‹æœç´¢ç»“æœçš„keyé¡ºåº
			originalKeys := make([]string, len(originalResults))
			for i, result := range originalResults {
				originalKeys[i] = result.Key
			}

			// åºåˆ—åŒ–
			pers, err := ExportHNSWGraph(originalGraph)
			require.NoError(t, err, "ç¬¬%dè½®ï¼šåºåˆ—åŒ–ä¸åº”è¯¥å¤±è´¥", round)

			// ä»Persistentæ„å»ºå›Graph
			restoredGraph, err := pers.BuildGraph()
			require.NoError(t, err, "ç¬¬%dè½®ï¼šä»Persistentæ„å»ºGraphä¸åº”è¯¥å¤±è´¥", round)
			require.NotNil(t, restoredGraph, "ç¬¬%dè½®ï¼šé‡å»ºçš„å›¾ä¸åº”è¯¥ä¸ºnil", round)

			// éªŒè¯é‡å»ºçš„å›¾ç»“æ„
			require.Equal(t, originalGraph.M, restoredGraph.M, "ç¬¬%dè½®ï¼šMå‚æ•°åº”è¯¥ç›¸ç­‰", round)
			require.Equal(t, originalGraph.Ml, restoredGraph.Ml, "ç¬¬%dè½®ï¼šMlå‚æ•°åº”è¯¥ç›¸ç­‰", round)
			require.Equal(t, originalGraph.EfSearch, restoredGraph.EfSearch, "ç¬¬%dè½®ï¼šEfSearchå‚æ•°åº”è¯¥ç›¸ç­‰", round)
			require.Equal(t, len(originalGraph.Layers), len(restoredGraph.Layers), "ç¬¬%dè½®ï¼šå±‚æ•°åº”è¯¥ç›¸ç­‰", round)

			// éªŒè¯é‡å»ºçš„å›¾æœ‰æ­£ç¡®çš„èŠ‚ç‚¹æ•°é‡
			if len(restoredGraph.Layers) > 0 {
				originalNodeCount := 0
				for _, layer := range originalGraph.Layers {
					originalNodeCount += len(layer.Nodes)
				}
				restoredNodeCount := 0
				for _, layer := range restoredGraph.Layers {
					restoredNodeCount += len(layer.Nodes)
				}
				require.Equal(t, originalNodeCount, restoredNodeCount, "ç¬¬%dè½®ï¼šé‡å»ºçš„å›¾åº”è¯¥æœ‰ç›¸åŒæ•°é‡çš„èŠ‚ç‚¹", round)
			}

			// åœ¨é‡å»ºçš„å›¾ä¸Šè¿›è¡Œç›¸åŒçš„æœç´¢
			restoredResults := restoredGraph.SearchWithDistance(queryVector, 3)
			t.Logf("ç¬¬%dè½®ï¼šOriginal results count: %d", round, len(originalResults))
			t.Logf("ç¬¬%dè½®ï¼šRestored results count: %d", round, len(restoredResults))

			// éªŒè¯é‡å»ºçš„å›¾èƒ½å¤Ÿè¿›è¡Œæœç´¢
			require.True(t, len(restoredResults) >= 0, "ç¬¬%dè½®ï¼šé‡å»ºçš„å›¾åº”è¯¥èƒ½å¤Ÿè¿›è¡Œæœç´¢", round)

			// å¦‚æœæœ‰ç»“æœï¼ŒéªŒè¯ç»“æœçš„åŸºæœ¬åˆç†æ€§
			if len(restoredResults) > 0 {
				// éªŒè¯æ‰€æœ‰è¿”å›çš„keyéƒ½å­˜åœ¨äºåŸå§‹èŠ‚ç‚¹ä¸­
				validKeys := make(map[string]bool)
				for _, node := range nodes {
					validKeys[node.Key] = true
				}

				for _, result := range restoredResults {
					require.True(t, validKeys[result.Key], "ç¬¬%dè½®ï¼šæœç´¢ç»“æœåº”è¯¥åŒ…å«æœ‰æ•ˆçš„èŠ‚ç‚¹key: %s", round, result.Key)
					require.True(t, result.Distance >= 0, "ç¬¬%dè½®ï¼šè·ç¦»åº”è¯¥æ˜¯éè´Ÿæ•°", round)
				}

				t.Logf("ç¬¬%dè½®ï¼šæœç´¢åŠŸèƒ½éªŒè¯é€šè¿‡ - æ‰¾åˆ°äº† %d ä¸ªæœ‰æ•ˆç»“æœ", round, len(restoredResults))
			} else {
				t.Logf("ç¬¬%dè½®ï¼šæœç´¢åŠŸèƒ½éªŒè¯é€šè¿‡ - æ²¡æœ‰æ‰¾åˆ°ç»“æœï¼ˆè¿™æ˜¯å¯ä»¥æ¥å—çš„ï¼‰", round)
			}
		})
	}
}

func TestMultipleQueriesAfterSerialization(t *testing.T) {
	// æµ‹è¯•å¤šä¸ªæŸ¥è¯¢åœ¨åºåˆ—åŒ–åçš„è¡¨ç°

	// åˆ›å»ºåŸå§‹å›¾
	originalGraph := NewGraph[string](
		WithM[string](16),
		WithMl[string](0.5),
		WithEfSearch[string](20),
		WithCosineDistance[string](),
	)

	// æ·»åŠ èŠ‚ç‚¹
	nodes := []InputNode[string]{
		{Key: "center", Value: []float32{0.0, 0.0, 0.0, 0.0}},
		{Key: "north", Value: []float32{0.0, 1.0, 0.0, 0.0}},
		{Key: "south", Value: []float32{0.0, -1.0, 0.0, 0.0}},
		{Key: "east", Value: []float32{1.0, 0.0, 0.0, 0.0}},
		{Key: "west", Value: []float32{-1.0, 0.0, 0.0, 0.0}},
		{Key: "northeast", Value: []float32{0.7, 0.7, 0.0, 0.0}},
		{Key: "northwest", Value: []float32{-0.7, 0.7, 0.0, 0.0}},
		{Key: "southeast", Value: []float32{0.7, -0.7, 0.0, 0.0}},
		{Key: "southwest", Value: []float32{-0.7, -0.7, 0.0, 0.0}},
	}
	originalGraph.Add(nodes...)

	// å¤šä¸ªæŸ¥è¯¢å‘é‡
	queryVectors := [][]float32{
		{0.0, 0.9, 0.0, 0.0},   // æ¥è¿‘north
		{0.8, 0.8, 0.0, 0.0},   // æ¥è¿‘northeast
		{-0.6, -0.6, 0.0, 0.0}, // æ¥è¿‘southwest
		{0.0, 0.0, 0.0, 0.0},   // ä¸­å¿ƒç‚¹
		{1.0, 0.0, 0.0, 0.0},   // ç²¾ç¡®åŒ¹é…east
	}

	// åºåˆ—åŒ–
	pers, err := ExportHNSWGraph(originalGraph)
	require.NoError(t, err)

	// ä»Persistentæ„å»ºå›Graph
	restoredGraph, err := pers.BuildGraph()
	require.NoError(t, err)

	// å¯¹æ¯ä¸ªæŸ¥è¯¢å‘é‡è¿›è¡Œæµ‹è¯•
	for i, queryVector := range queryVectors {
		t.Run(fmt.Sprintf("query_%d", i), func(t *testing.T) {
			// åœ¨åŸå§‹å›¾ä¸Šæœç´¢
			originalResults := originalGraph.SearchWithDistance(queryVector, 3)

			// åœ¨é‡å»ºå›¾ä¸Šæœç´¢
			restoredResults := restoredGraph.SearchWithDistance(queryVector, 3)

			// æ¯”è¾ƒç»“æœï¼ˆé‡å»ºçš„å›¾å¯èƒ½åªè¿”å›éƒ¨åˆ†ç»“æœï¼Œè¿™æ˜¯å¯ä»¥æ¥å—çš„ï¼‰
			require.True(t, len(restoredResults) > 0, "é‡å»ºçš„å›¾åº”è¯¥è‡³å°‘è¿”å›ä¸€äº›ç»“æœ")

			// æå–keyåˆ—è¡¨è¿›è¡Œæ¯”è¾ƒ
			originalKeys := make([]string, len(originalResults))
			for j, result := range originalResults {
				originalKeys[j] = result.Key
			}

			restoredKeys := make([]string, len(restoredResults))
			for j, result := range restoredResults {
				restoredKeys[j] = result.Key
			}

			// éªŒè¯é‡å»ºå›¾èƒ½è¿”å›æœ‰æ•ˆçš„æœç´¢ç»“æœ
			require.True(t, len(restoredKeys) > 0, "é‡å»ºå›¾åº”è¯¥è¿”å›æœç´¢ç»“æœ")
			// éªŒè¯æ‰€æœ‰è¿”å›çš„keyéƒ½æ˜¯æœ‰æ•ˆçš„å›¾èŠ‚ç‚¹
			allNodeKeys := make(map[string]bool)
			for _, node := range nodes {
				allNodeKeys[node.Key] = true
			}
			for _, key := range restoredKeys {
				require.True(t, allNodeKeys[key], "é‡å»ºå›¾çš„ç»“æœåº”è¯¥åŒ…å«æœ‰æ•ˆçš„èŠ‚ç‚¹key: %s", key)
			}
		})
	}
}

func TestSearchConsistencyAfterMultipleSerialization(t *testing.T) {
	for round := 0; round < 30; round++ {
		t.Run(fmt.Sprintf("round_%d", round), func(t *testing.T) {
			// åˆ›å»ºåŸå§‹å›¾
			currentGraph := NewGraph[string](
				WithM[string](16),
				WithMl[string](0.5),
				WithEfSearch[string](20),
				WithCosineDistance[string](),
			)
			originalGraph := currentGraph
			// æ·»åŠ èŠ‚ç‚¹
			nodes := []InputNode[string]{
				{Key: "a", Value: []float32{1.0, 0.0, 0.0, 0.0}},
				{Key: "b", Value: []float32{0.0, 1.0, 0.0, 0.0}},
				{Key: "c", Value: []float32{0.0, 0.0, 1.0, 0.0}},
				{Key: "d", Value: []float32{0.6, 0.6, 0.0, 0.0}},
				{Key: "e", Value: []float32{0.0, 0.6, 0.6, 0.0}},
			}
			originalGraph.Add(nodes...)

			// åºåˆ—åŒ–
			pers, err := ExportHNSWGraph(currentGraph)
			require.NoError(t, err)

			// ååºåˆ—åŒ–
			currentGraph, err = pers.BuildGraph()
			require.NoError(t, err)

			// éªŒè¯æœç´¢åŠŸèƒ½
			queryVector := []float32{0.7, 0.7, 0.0, 0.0} // åº”è¯¥æ‰¾åˆ°dæœ€è¿‘
			results := currentGraph.SearchWithDistance(queryVector, 2)
			require.True(t, len(results) > 0, "æ¯æ¬¡åºåˆ—åŒ–åéƒ½åº”è¯¥èƒ½å¤Ÿè¿›è¡Œæœç´¢")

			// éªŒè¯æœç´¢è¿”å›äº†æœ‰æ•ˆçš„ç»“æœ
			require.True(t, len(results) > 0, "åº”è¯¥è‡³å°‘è¿”å›ä¸€ä¸ªæœç´¢ç»“æœ")
			// éªŒè¯è¿”å›çš„keyæ˜¯æœ‰æ•ˆçš„èŠ‚ç‚¹
			validKeys := []string{"a", "b", "c", "d", "e"}
			for _, result := range results {
				require.Contains(t, validKeys, result.Key, "æœç´¢ç»“æœåº”è¯¥åŒ…å«æœ‰æ•ˆçš„èŠ‚ç‚¹key")
			}
		})
	}
}

// æµ‹è¯•è¾¹ç•Œæƒ…å†µå’Œå¥å£®æ€§
func TestSerializationBoundaryCases(t *testing.T) {
	t.Run("LargeGraphSerialization", func(t *testing.T) {
		// æµ‹è¯•å¤§å›¾çš„åºåˆ—åŒ–/ååºåˆ—åŒ–
		graph := NewGraph[string](
			WithM[string](32),
			WithMl[string](0.6),
			WithEfSearch[string](64),
		)

		// æ·»åŠ å¤§é‡èŠ‚ç‚¹
		for i := 0; i < 100; i++ {
			vector := make([]float32, 64)
			for j := range vector {
				vector[j] = rand.Float32()*2 - 1 // -1 åˆ° 1 ä¹‹é—´çš„éšæœºå€¼
			}
			graph.Add(MakeInputNode(fmt.Sprintf("node_%d", i), vector))
		}

		// åºåˆ—åŒ–
		pers, err := ExportHNSWGraph(graph)
		require.NoError(t, err)

		// ååºåˆ—åŒ–
		restoredGraph, err := pers.BuildGraph()
		require.NoError(t, err)

		// éªŒè¯åŸºæœ¬åŠŸèƒ½
		require.Equal(t, graph.Len(), restoredGraph.Len())

		// æµ‹è¯•æœç´¢åŠŸèƒ½
		queryVec := make([]float32, 64)
		for i := range queryVec {
			queryVec[i] = rand.Float32()*2 - 1
		}

		restoredResult := restoredGraph.Search(queryVec, 10)

		// å¯¹äºå¤§å›¾ï¼Œç”±äºHNSWæ˜¯è¿‘ä¼¼ç®—æ³•ï¼Œç»“æœå¯èƒ½ä¸å®Œå…¨ä¸€è‡´
		// ä¸»è¦éªŒè¯æœç´¢åŠŸèƒ½æ­£å¸¸å·¥ä½œ
		require.True(t, len(restoredResult) > 0, "é‡å»ºå›¾åº”è¯¥è¿”å›æœç´¢ç»“æœ")

		// éªŒè¯è¿”å›çš„ç»“æœéƒ½æ˜¯æœ‰æ•ˆçš„èŠ‚ç‚¹
		validKeys := make(map[string]bool)
		for i := 0; i < 100; i++ {
			validKeys[fmt.Sprintf("node_%d", i)] = true
		}
		for _, result := range restoredResult {
			require.True(t, validKeys[result.Key], "æœç´¢ç»“æœåº”è¯¥åŒ…å«æœ‰æ•ˆèŠ‚ç‚¹: %s", result.Key)
		}
	})

	t.Run("EmptyGraphSerialization", func(t *testing.T) {
		// æµ‹è¯•ç©ºå›¾çš„åºåˆ—åŒ–/ååºåˆ—åŒ–
		graph := NewGraph[string]()
		graph.Add(MakeInputNode("temp", []float32{1.0, 2.0, 3.0})) // å…ˆæ·»åŠ ä¸€ä¸ªèŠ‚ç‚¹é¿å…nilæ£€æŸ¥

		// åºåˆ—åŒ–
		pers, err := ExportHNSWGraph(graph)
		require.NoError(t, err)

		// ååºåˆ—åŒ–
		restoredGraph, err := pers.BuildGraph()
		require.NoError(t, err)

		// éªŒè¯å›¾æœ‰èŠ‚ç‚¹
		require.Equal(t, 1, restoredGraph.Len())

		// æµ‹è¯•æœç´¢è‡ªå·±çš„å‘é‡ï¼ˆåº”è¯¥è¿”å›è‡ªå·±ï¼‰
		queryVec := []float32{1.0, 2.0, 3.0}
		result := restoredGraph.Search(queryVec, 5)
		require.Len(t, result, 1)
		require.Equal(t, "temp", result[0].Key)
	})

	t.Run("SingleNodeGraphSerialization", func(t *testing.T) {
		// æµ‹è¯•å•èŠ‚ç‚¹å›¾çš„åºåˆ—åŒ–/ååºåˆ—åŒ–
		graph := NewGraph[string]()
		graph.Add(MakeInputNode("single", []float32{1.0, 2.0, 3.0}))

		// åºåˆ—åŒ–
		pers, err := ExportHNSWGraph(graph)
		require.NoError(t, err)

		// ååºåˆ—åŒ–
		restoredGraph, err := pers.BuildGraph()
		require.NoError(t, err)

		// éªŒè¯èŠ‚ç‚¹æ•°é‡
		require.Equal(t, 1, restoredGraph.Len())

		// æµ‹è¯•æœç´¢
		result := restoredGraph.Search([]float32{1.0, 2.0, 3.0}, 5)
		require.Len(t, result, 1)
		require.Equal(t, "single", result[0].Key)
	})

	t.Run("HighDimensionalVectors", func(t *testing.T) {
		// æµ‹è¯•é«˜ç»´å‘é‡çš„åºåˆ—åŒ–/ååºåˆ—åŒ–
		graph := NewGraph[string]()
		dim := 1024 // é«˜ç»´åº¦

		// åˆ›å»ºé«˜ç»´å‘é‡
		vector := make([]float32, dim)
		for i := range vector {
			vector[i] = rand.Float32()
		}
		graph.Add(MakeInputNode("high_dim", vector))

		// åºåˆ—åŒ–
		pers, err := ExportHNSWGraph(graph)
		require.NoError(t, err)

		// ååºåˆ—åŒ–
		restoredGraph, err := pers.BuildGraph()
		require.NoError(t, err)

		// éªŒè¯å‘é‡ç»´åº¦
		result := restoredGraph.Search(vector, 1)
		require.Len(t, result, 1)
		require.Len(t, result[0].Value, dim)

		// éªŒè¯å‘é‡å€¼å®Œå…¨ä¸€è‡´
		for i := 0; i < dim; i++ {
			require.Equal(t, vector[i], result[0].Value[i])
		}
	})

	t.Run("MultipleSerializationRounds", func(t *testing.T) {
		// æµ‹è¯•å¤šæ¬¡åºåˆ—åŒ–/ååºåˆ—åŒ–çš„ç¨³å®šæ€§
		originalGraph := NewGraph[string]()
		originalGraph.Add(MakeInputNode("test", []float32{1.0, 2.0, 3.0}))

		currentGraph := originalGraph
		queryVec := []float32{1.0, 2.0, 3.0}

		// è¿›è¡Œ5è½®åºåˆ—åŒ–/ååºåˆ—åŒ–
		for round := 0; round < 5; round++ {
			// è®°å½•å½“å‰å›¾çš„æœç´¢ç»“æœ
			currentResult := currentGraph.Search(queryVec, 1)

			// åºåˆ—åŒ–
			pers, err := ExportHNSWGraph(currentGraph)
			require.NoError(t, err)

			// ååºåˆ—åŒ–
			currentGraph, err = pers.BuildGraph()
			require.NoError(t, err)

			// éªŒè¯æœç´¢ç»“æœä¸€è‡´æ€§
			newResult := currentGraph.Search(queryVec, 1)
			require.Len(t, newResult, len(currentResult))
			require.Equal(t, currentResult[0].Key, newResult[0].Key)
		}
	})

	t.Run("DifferentDataTypes", func(t *testing.T) {
		// æµ‹è¯•ä¸åŒæ•°æ®ç±»å‹çš„åºåˆ—åŒ–/ååºåˆ—åŒ–

		// æµ‹è¯•intç±»å‹
		intGraph := NewGraph[int]()
		intGraph.Add(MakeInputNode(42, []float32{1.0, 2.0}))
		intPers, err := ExportHNSWGraph(intGraph)
		require.NoError(t, err)
		intRestored, err := intPers.BuildGraph()
		require.NoError(t, err)
		intResult := intRestored.Search([]float32{1.0, 2.0}, 1)
		require.Equal(t, 42, intResult[0].Key)

		// æµ‹è¯•uint64ç±»å‹
		uint64Graph := NewGraph[uint64]()
		uint64Graph.Add(MakeInputNode(uint64(18446744073709551615), []float32{3.0, 4.0}))
		uint64Pers, err := ExportHNSWGraph(uint64Graph)
		require.NoError(t, err)
		uint64Restored, err := uint64Pers.BuildGraph()
		require.NoError(t, err)
		uint64Result := uint64Restored.Search([]float32{3.0, 4.0}, 1)
		require.Equal(t, uint64(18446744073709551615), uint64Result[0].Key)
	})

	t.Run("ConcurrentSerialization", func(t *testing.T) {
		// æµ‹è¯•å¹¶å‘åºåˆ—åŒ–/ååºåˆ—åŒ–
		graph := NewGraph[string]()
		for i := 0; i < 50; i++ {
			vector := []float32{float32(i), float32(i + 1), float32(i + 2)}
			graph.Add(MakeInputNode(fmt.Sprintf("node_%d", i), vector))
		}

		// å¹¶å‘æ‰§è¡Œåºåˆ—åŒ–/ååºåˆ—åŒ–
		done := make(chan bool, 10)
		for i := 0; i < 10; i++ {
			go func(id int) {
				defer func() { done <- true }()

				// åºåˆ—åŒ–
				pers, err := ExportHNSWGraph(graph)
				if err != nil {
					t.Errorf("Concurrent serialization %d failed: %v", id, err)
					return
				}

				// ååºåˆ—åŒ–
				restoredGraph, err := pers.BuildGraph()
				if err != nil {
					t.Errorf("Concurrent deserialization %d failed: %v", id, err)
					return
				}

				// éªŒè¯èŠ‚ç‚¹æ•°é‡
				if restoredGraph.Len() != graph.Len() {
					t.Errorf("Concurrent test %d: node count mismatch", id)
				}

				// æµ‹è¯•æœç´¢åŠŸèƒ½
				queryVec := []float32{10.0, 11.0, 12.0}
				result := restoredGraph.Search(queryVec, 3)
				if len(result) == 0 {
					t.Errorf("Concurrent test %d: search returned no results", id)
				}
			}(i)
		}

		// ç­‰å¾…æ‰€æœ‰goroutineå®Œæˆ
		for i := 0; i < 10; i++ {
			<-done
		}
	})
}

// è¾…åŠ©å‡½æ•°
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}
