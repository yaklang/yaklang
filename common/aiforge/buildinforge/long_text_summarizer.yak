__DESC__ = "该forge接收长文本或文本文件，将其分割成片段后，利用fragment_summarizer对每个片段进行摘要，然后将摘要结果再次进行摘要，最终输出长文本的总结。"

__KEYWORDS__ = "文本摘要,长文本处理,文本总结,片段摘要,文本分割,内容提炼"

text = cli.String("text", cli.setHelp("直接输入的长文本"))
filePath = cli.String("filePath", cli.setHelp("长文本文件"))
cli.check()

forgeHandle = func(params) {
        ctx = context.Background()
        textChan = make(chan string)
        if text != "" {
            textChan = str.TextReaderSplit(ctx,str.NewReader(text))
        }elif filePath != "" {
            textChan = str.TextReaderSplit(ctx, file.Open(filePath)~)
        }else {
            return
        }
		fragmentSummarize := func(poly) {
			result, err := aiagent.ExecuteForge(
				"fragment_summarizer",
                {
                    "textSnippet": poly,
                    "limit": 100
                }
			)
			if err != nil {
				return ""
			}
			return result
		}

		textReducer := x.NewReducer(10, func(data) {
			polyData := str.Join(data, "\n")
			return fragmentSummarize(polyData)
		})

		for s := range textChan {
			textReducer.Push(fragmentSummarize(s))
		}
		reduceData := str.Join(textReducer.GetData(), "\n")
		result, err := aiagent.ExecuteForge(
			"fragment_summarizer",
            {
                "textSnippet": reduceData,
                "limit": 300
            }
		)
		if err != nil {
			return nil
		}
		return result
}