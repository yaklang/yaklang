__DESC__ = "该forge接收长文本或文本文件，将其分割成片段后，利用fragment_summarizer对每个片段进行摘要，然后将摘要结果再次进行摘要，最终输出长文本的总结。"
__VERBOSE_NAME__ = "长文本总结"
__KEYWORDS__ = "文本摘要,长文本处理,文本总结,片段摘要,文本分割,内容提炼"

text = cli.String("text", cli.setHelp("直接输入的长文本"))
filePath = cli.String("filePath", cli.setHelp("长文本文件"))
cli.check()

forgeHandle = func(params) {
        var reader
		if text != "" {
            reader = str.NewReader(text)
        }else if filePath != "" {
            reader,err = file.Open(filePath)
            if err != nil {
                return nil
            }
        }else {
            return nil
        }


        memory = aiagent.GetDefaultContextProvider()
        key = "前情提要"
        reducer, err := aireducer.NewReducerFromReader(reader, aireducer.reducerCallback(func(config,memory,chunk){
            textSnippet = string(chunk.Data())
            preData, _ := memory.GetPersistentData(key)
			if preData != "" {
				textSnippet = key + " : " + preData + "\n" + textSnippet
			}
			res, err := aiagent.ExecuteForge("fragment_summarizer",
					{
						"textSnippet":textSnippet,
						"limit": "1000",
					},
					aiagent.allowRequireForUserInteract(false),
			)
			if err != nil {
				return err
			}
			memory.SetPersistentData(key, sprint(res))
			return nil
        }),aireducer.memory(memory))
        if err != nil {
            return nil
        }
        err = reducer.Run()
		if err != nil {
			return nil
		}
		return memory.GetPersistentData(key)
}