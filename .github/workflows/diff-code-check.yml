name: Diff-Code-Check

on:
  pull_request:
    branches: [main]
    types: [ opened, synchronize, reopened, labeled, unlabeled ]
    paths:
      - "common/**"
      - ".github/workflows/diff-code-check.yml"
      - ".github/actions/security-commenter/action.yml"
      - "common/ssa_bootstrapping/ci_rule/**"
      - "scripts/ssa-risk-tools/**"

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  check-wip:
    runs-on: ubuntu-22.04
    outputs:
      should_run_tests: ${{ steps.pre_check.outputs.should_run_tests }}
    steps:
      - name: 'Check Out'
        uses: actions/checkout@v3
        with:
          ref: ${{ github.event.pull_request.head.sha }}

      - name: Run Pre-Check
        id: pre_check
        uses: ./.github/actions/pre-check
        with:
          failed-labels: 'do-not-merge,work in progress,wip,rfc'
          skip-labels: 'pass-diff-check'
          cache-key-prefix: 'diff-code-check'

  setup:
    runs-on: ubuntu-22.04
    needs: [check-wip]
    if: needs.check-wip.outputs.should_run_tests == 'true'
    permissions:
      contents: read
      pull-requests: write
      issues: write
      actions: read
    steps:
      - name: Initialize workflow context
        id: init
        run: |
          HEAD_SHA="${{ github.event.pull_request.head.sha }}"
          PR_NUMBER="${{ github.event.pull_request.number }}"
          
          echo "HEAD_SHA=$HEAD_SHA" >> $GITHUB_ENV
          echo "PR_NUMBER=$PR_NUMBER" >> $GITHUB_ENV

      - name: Set Cache Key
        id: cache_key
        run: |
          CACHE_SHA="${{ env.HEAD_SHA }}"
          echo "sha=$CACHE_SHA" >> $GITHUB_OUTPUT
          echo "Cache key will be: go-$CACHE_SHA"

      - name: Validate PR state
        id: validate
        run: |
          PR_RESPONSE=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/pulls/${{ env.PR_NUMBER }}")
          
          PR_STATE=$(echo "$PR_RESPONSE" | jq -r '.state // "unknown"')
          PR_HEAD_SHA=$(echo "$PR_RESPONSE" | jq -r '.head.sha // "unknown"')
          
          if [ "$PR_STATE" != "open" ]; then
            echo "should_skip=true" >> $GITHUB_OUTPUT
            echo "skip_reason=pr_not_open" >> $GITHUB_OUTPUT
            echo "::notice::PR is not open, skipping security check"
            exit 0
          fi
          
          if [ "$PR_HEAD_SHA" != "${{ env.HEAD_SHA }}" ]; then
            echo "should_skip=true" >> $GITHUB_OUTPUT
            echo "skip_reason=sha_mismatch" >> $GITHUB_OUTPUT
            echo "::notice::PR head SHA has changed, skipping security check"
            exit 0
          fi
          
          echo "should_skip=false" >> $GITHUB_OUTPUT
          echo "skip_reason=none" >> $GITHUB_OUTPUT
          echo "PR validation passed"

      - name: Skip if validation failed
        if: steps.validate.outputs.should_skip == 'true'
        run: |
          echo "Workflow skipped: ${{ steps.validate.outputs.skip_reason }}"
          exit 0

      - name: Check out code
        if: steps.validate.outputs.should_skip != 'true'
        uses: actions/checkout@v3
        with:
          ref: ${{ env.HEAD_SHA }}
          fetch-depth: 0
          clean: false

      - name: Fetch Main And Reset Main
        if: steps.validate.outputs.should_skip != 'true'
        run: |
          git fetch --all
          git checkout main
          git reset --hard origin/main

      - name: Install Yak
        if: steps.validate.outputs.should_skip != 'true'
        env: 
          SKIP_SYNC_EMBED_RULE_IN_GITHUB: "true"
        run: |
          echo "::group::Downloading Yak installation script"
          if ! curl -sS -L http://oss.yaklang.io/install-latest-yak.sh -o install-latest-yak.sh; then
            echo "::error::Failed to download Yak installation script"
            exit 1
          fi
          echo "::endgroup::"
          
          echo "::group::Installing Yak"
          chmod +x install-latest-yak.sh
          if ! ./install-latest-yak.sh; then
            echo "::error::Failed to install Yak"
            exit 1
          fi
          echo "::endgroup::"
          
          echo "::group::Verifying Yak installation"
          if ! yak version; then
            echo "::error::Yak installation verification failed"
            exit 1
          fi
          echo "::endgroup::"

      - name: Generate Prog
        if: steps.validate.outputs.should_skip != 'true'
        run: |
          echo "::group::Checking out target commit"
          if ! git checkout ${{ env.HEAD_SHA }}; then
            echo "::error::Failed to checkout commit ${{ env.HEAD_SHA }}"
            exit 1
          fi
          echo "::endgroup::"
          
          echo "::group::Importing SyntaxFlow rules"
          if ! yak sf-import --file common/ssa_bootstrapping/ci_rule/ --format raw; then
            echo "::error::Failed to import SyntaxFlow rules"
            exit 1
          fi
          echo "::endgroup::"
          
          echo "::group::Generating file system snapshot"
          MERGE_BASE=$(git merge-base main ${{ env.HEAD_SHA }})
          if [ -z "$MERGE_BASE" ]; then
            echo "::error::Failed to find merge base between main and ${{ env.HEAD_SHA }}"
            exit 1
          fi
          echo "Merge base: $MERGE_BASE"
          
          if ! yak gitefs --start $MERGE_BASE --end ${{ env.HEAD_SHA }} --output ./fs.zip; then
            echo "::error::Failed to generate file system snapshot"
            exit 1
          fi
          
          if [ ! -f "./fs.zip" ]; then
            echo "::error::fs.zip was not created"
            exit 1
          fi
          echo "::endgroup::" 

      - name: Upload fs.zip
        if: steps.validate.outputs.should_skip != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: fs.zip
          path: fs.zip

      - name: Check With SyntaxFlow
        if: steps.validate.outputs.should_skip != 'true'
        id: scan
        run: |
          echo "::group::Running security scan"
          yak sync-rule
          
          # è¿è¡Œæ‰«æå¹¶æ•è·è¾“å‡º
          SCAN_LOG="scan_output.log"
          rm -f "$SCAN_LOG"
          set -o pipefail
          if ! yak code-scan -t ./fs.zip -l golang --rule-keyword golang --format irify -o risk --memory --log-level debug --file-perf-log --rule-perf-log --rule-instr-log --exclude-file **/vendor/**,vendor/**,**/classes/**,**/target/**,**include/**,**caches/**,**cache/**,**tmp/**,**alipay/**,**includes/**,**temp/**,**zh_cn/**,**zh_en/**,**plugins/**,**PHPExcel/**,*.pb.go,*_test.go 2>&1 | tee "$SCAN_LOG"; then
            SCAN_EXIT_CODE=$?
          fi
          SCAN_OUTPUT=$(cat "$SCAN_LOG")
          
          if [ ! -z "$SCAN_EXIT_CODE" ] && [ "$SCAN_EXIT_CODE" != "0" ]; then
            echo "$SCAN_OUTPUT"
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç¼–è¯‘å¤±è´¥é”™è¯¯
            if echo "$SCAN_OUTPUT" | grep -q "record not found\|have err\|get program failed\|parse project.*failed"; then
              echo "::warning::Project compilation failed, skipping security scan"
              echo "::notice::This is usually caused by empty diff or compilation errors"
              echo "scan_result=skipped_compilation_error" >> $GITHUB_OUTPUT
              echo "risk_count=0" >> $GITHUB_OUTPUT
              echo "::endgroup::"
              exit 0
            else
              echo "::error::Security scan failed with unexpected error"
              exit 1
            fi
          fi
          
          echo "$SCAN_OUTPUT"
          echo "::endgroup::"
          
          echo "::group::Processing scan results"
          if [ ! -f "./risk.json" ]; then
            echo "::error::risk.json was not generated"
            exit 1
          fi
          
          NUM=$(cat risk.json | jq .RiskNums)
          if [ -z "$NUM" ]; then
            echo "::error::Failed to extract risk count from risk.json"
            exit 1
          fi
          
          echo "Found $NUM security risks"
          echo "risk_count=$NUM" >> $GITHUB_OUTPUT
          
          if [ $NUM == 0 ]; then
            echo "scan_result=success" >> $GITHUB_OUTPUT
            echo "::notice::No security risks found"
          else
            echo "scan_result=failure" >> $GITHUB_OUTPUT
            echo "::warning::Found $NUM security risks"
          fi
          echo "::endgroup::"

      - name: Verify GitHub token permissions
        if: steps.validate.outputs.should_skip != 'true'
        id: test_token
        run: |
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/pulls/${{ env.PR_NUMBER }}")
          
          if [ "$HTTP_CODE" = "200" ]; then
            echo "has_permissions=true" >> $GITHUB_OUTPUT
          else
            echo "has_permissions=false" >> $GITHUB_OUTPUT
          fi

      - name: Skip Security Comment (Insufficient Permissions)
        if: steps.validate.outputs.should_skip != 'true' && steps.scan.outputs.scan_result == 'failure' && steps.test_token.outputs.has_permissions == 'false'
        run: |
          echo "::warning::Insufficient token permissions, skipping security comments"
      
      - name: Generate security report
        if: steps.validate.outputs.should_skip != 'true' && steps.scan.outputs.scan_result == 'failure'
        id: generate_report
        run: |
          echo "::group::Preparing report generation"
          rm -rf results
          
          if [ ! -f "./risk.json" ]; then
            echo "::error::Risk file not found: ./risk.json"
            exit 1
          fi
          
          if [ ! -f "./scripts/ssa-risk-tools/extract-risks-deserializer.awk" ]; then
            echo "::error::AWK script not found: ./scripts/ssa-risk-tools/extract-risks-deserializer.awk"
            exit 1
          fi
          echo "::endgroup::"
          
          echo "::group::Generating security report"
          if ! awk -f scripts/ssa-risk-tools/extract-risks-deserializer.awk ./risk.json; then
            echo "::error::Failed to generate security report with AWK script"
            exit 1
          fi
          echo "::endgroup::"
          
          echo "::group::Analyzing report results"
          if [ ! -d "results" ]; then
            echo "::error::Results directory was not created"
            exit 1
          fi
          
          RISK_COUNT=0
          if [ -f "results/scan_summary.txt" ]; then
            echo "Scan summary generated successfully"
            SUMMARY_COUNT=$(grep -E "^æ€»é£é™©æ•°:" results/scan_summary.txt | tail -n1 | awk -F':' '{gsub(/^[ \t]+|[ \t]+$/, "", $2); print $2}')
            if [[ "$SUMMARY_COUNT" =~ ^[0-9]+$ ]]; then
              RISK_COUNT=$SUMMARY_COUNT
            else
              echo "::warning::Failed to parse total risk count from scan_summary.txt"
              if ls results/risk_details_*.txt 1> /dev/null 2>&1; then
                FILE_COUNT=$(ls results/risk_details_*.txt | wc -l | tr -d ' ')
                if [[ "$FILE_COUNT" =~ ^[0-9]+$ ]]; then
                  RISK_COUNT=$FILE_COUNT
                else
                  echo "::warning::Failed to derive risk count from detail files"
                  RISK_COUNT=0
                fi
              else
                echo "::notice::No risk detail files found"
                RISK_COUNT=0
              fi
            fi
          else
            echo "::warning::Scan summary file not found"
            RISK_COUNT=0
          fi
          
          echo "Total risks found: $RISK_COUNT"
          echo "RISK_COUNT=$RISK_COUNT" >> $GITHUB_OUTPUT
          if [ "$RISK_COUNT" -eq 0 ]; then
            echo "::notice::Risk count is 0. Skipping remaining risk processing steps."
            echo "::endgroup::"
          fi
          echo "::endgroup::"

      - name: Clean up old security comments (No vulnerabilities found)
        if: steps.validate.outputs.should_skip != 'true' && (steps.scan.outputs.scan_result == 'success' || steps.scan.outputs.scan_result == 'skipped_compilation_error') && steps.test_token.outputs.has_permissions == 'true'
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            try {
              // å®šä¹‰å®‰å…¨æ‰«æè¯„è®ºçš„å”¯ä¸€æ ‡è¯†ç¬¦
              const commentIdentifier = '<!-- security-scan-report:main -->';
              
              // æŸ¥è¯¢æ‰€æœ‰è¯„è®º
              const comments = await github.rest.issues.listComments({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: Number(process.env.PR_NUMBER),
                per_page: 100
              });
              
              let deletedCount = 0;
              
              // åˆ é™¤æ‰€æœ‰æœºå™¨äººè‡ªå·±çš„å®‰å…¨ç›¸å…³è¯„è®º
              for (const comment of comments.data) {
                const isBotComment = comment.user.type === 'Bot' || 
                                   comment.user.login === 'github-actions[bot]' ||
                                   comment.user.login.endsWith('[bot]') ||
                                   comment.body.includes('æ­¤è¯„è®ºç”±ä»£ç å®‰å…¨æ£€æŸ¥å·¥å…·è‡ªåŠ¨ç”Ÿæˆ') ||
                                   comment.body.includes('æ­¤æŠ¥å‘Šç”±ä»£ç å®‰å…¨æ‰«æå·¥å…·è‡ªåŠ¨ç”Ÿæˆ');
                
                if (isBotComment && (comment.body.includes(commentIdentifier) || comment.body.includes('<!-- security-line-comment:'))) {
                  await github.rest.issues.deleteComment({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    comment_id: comment.id
                  });
                  deletedCount++;
                  console.log(`Cleaned up old security comment: ${comment.id}`);
                }
              }
              
              if (deletedCount > 0) {
                console.log(`Cleaned up ${deletedCount} old security comments (no vulnerabilities found)`);
              } else {
                console.log('No old security comments found to clean up');
              }
              
            } catch (error) {
              console.error('Failed to clean up old security comments:', error);
              // ä¸æŠ›å‡ºé”™è¯¯ï¼Œé¿å…å½±å“ä¸»æµç¨‹
            }

      - name: Notify compilation skip
        if: steps.validate.outputs.should_skip != 'true' && steps.scan.outputs.scan_result == 'skipped_compilation_error'
        run: |
          echo "::notice::âœ… Security scan was skipped due to compilation failure"
          echo "::notice::This is usually caused by:"
          echo "::notice::  - Empty diff (no Go files changed)"
          echo "::notice::  - Compilation errors in the code"
          echo "::notice::  - Missing dependencies or broken imports"
          echo "::notice::This does not block the CI pipeline."

      - name: Upload risk log
        if: steps.validate.outputs.should_skip != 'true' && steps.scan.outputs.scan_result == 'failure'
        uses: actions/upload-artifact@v4
        with:
          name: risk.json
          path: risk.json
          if-no-files-found: ignore

      - name: Upload risk results
        if: steps.validate.outputs.should_skip != 'true' && steps.scan.outputs.scan_result == 'failure'
        uses: actions/upload-artifact@v4
        with:
          name: risk-results
          path: results/
          if-no-files-found: ignore

      - name: Highlight performance logs
        if: steps.validate.outputs.should_skip != 'true'
        run: |
          if [ ! -f "scan_output.log" ]; then
            echo "::notice::scan_output.log not found, skip performance summary"
            exit 0
          fi
          echo "::group::Performance logs (grep view)"
          if ! grep -nE "Profile Summary|SyntaxFlow Instruction Performance" scan_output.log; then
            echo "::notice::No performance logs detected in scan_output.log"
          fi
          echo "::endgroup::"

      - name: Comment PR with security findings
        if: steps.validate.outputs.should_skip != 'true' && steps.scan.outputs.scan_result == 'failure' && steps.test_token.outputs.has_permissions == 'true' && steps.generate_report.outputs.RISK_COUNT != '0'
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            
            try {
              console.log('::group::Reading security report');
              const path = require('path');
              const resultsDir = path.join(process.cwd(), 'results');
              console.log(`Results directory: ${resultsDir}`);
              
              let report = '';
              const summaryFile = path.join(resultsDir, 'scan_summary.txt');
              
              if (!fs.existsSync(resultsDir)) {
                core.error('Results directory does not exist');
                throw new Error('Results directory not found');
              }
              
              if (fs.existsSync(summaryFile)) {
                report = fs.readFileSync(summaryFile, 'utf8');
                console.log(`Successfully read summary file (${report.length} characters)`);
              } else {
                core.error(`Summary file not found: ${summaryFile}`);
                report = 'âš ï¸ æŠ¥å‘Šæ–‡ä»¶æœªæ‰¾åˆ°';
              }
              console.log('::endgroup::');
              
              console.log('::group::Fetching existing PR comments');
              const commentIdentifier = '<!-- security-scan-report:main -->';
              
              const comments = await github.rest.issues.listComments({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: Number(process.env.PR_NUMBER),
                per_page: 100
              });
              console.log(`Found ${comments.data.length} total comments on PR`);
              
              let existingMainComment = null;
              for (const comment of comments.data) {
                if (comment.user.type === 'Bot' && comment.body.includes(commentIdentifier)) {
                  existingMainComment = comment;
                  console.log(`Found existing main security comment (ID: ${comment.id})`);
                  break;
                }
              }
              
              if (!existingMainComment) {
                console.log('No existing main security comment found');
              }
              console.log('::endgroup::');
              
              console.log('::group::Posting/Updating main security report');
              const reportWithIdentifier = commentIdentifier + '\n\n' + report;
              
              let riskSummary = [];
              if (fs.existsSync(resultsDir)) {
                const detailFiles = fs.readdirSync(resultsDir).filter(file => file.startsWith('risk_details_') && file.endsWith('.txt'));
                for (const detailFile of detailFiles) {
                  const detailPath = path.join(resultsDir, detailFile);
                  const content = fs.readFileSync(detailPath, 'utf8');
                  const lines = content.split('\n');
                  let title = '';
                  let filePath = '';
                  let lineNum = '';
                  for (const line of lines) {
                    if (line.startsWith('ä¸­æ–‡æ ‡é¢˜:')) {
                      title = line.replace('ä¸­æ–‡æ ‡é¢˜:', '').trim();
                    } else if (line.startsWith('æ ‡é¢˜:') && !title) {
                      title = line.replace('æ ‡é¢˜:', '').trim();
                    } else if (line.startsWith('æ–‡ä»¶è·¯å¾„:')) {
                      filePath = line.replace('æ–‡ä»¶è·¯å¾„:', '').trim();
                    } else if (line.startsWith('è¡Œå·:')) {
                      lineNum = line.replace('è¡Œå·:', '').trim();
                    }
                  }
                  if (title && filePath && lineNum) {
                    const commitSha = process.env.HEAD_SHA || context.sha;
                    const normalizedPath = filePath.replace(/^\.\//, '');
                    const lineAnchor = `#L${lineNum}`;
                    const codeLink = `https://github.com/${context.repo.owner}/${context.repo.repo}/blob/${commitSha}/${normalizedPath}${lineAnchor}`;
                    const linkText = `${normalizedPath}:${lineNum}`;
                    riskSummary.push(`${riskSummary.length + 1}. ${title}: [${linkText}](${codeLink})`);
                  }
                }
              }

              const summarySection = riskSummary.length > 0
                ? `\n\n${riskSummary.join('\n')}`
                : '';
              const artifactsUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}#artifacts`;
              const artifactsSection = `\n\n[ä¸‹è½½ risk.json](${artifactsUrl})`;
              const finalReport = reportWithIdentifier + summarySection + artifactsSection;

              if (existingMainComment) {
                await github.rest.issues.updateComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  comment_id: existingMainComment.id,
                  body: finalReport
                });
                console.log(`âœ… Security report comment updated (ID: ${existingMainComment.id})`);
              } else {
                const newComment = await github.rest.issues.createComment({
                  issue_number: Number(process.env.PR_NUMBER),
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  body: finalReport
                });
                console.log(`âœ… Security report comment created (ID: ${newComment.data.id})`);
              }
              console.log('::endgroup::');
              
              // console.log('::group::Processing detailed risk files');
              // é€æ¡é£é™©è¯„è®ºé€»è¾‘å·²æŒ‰è¦æ±‚æ³¨é‡Šï¼Œè‹¥éœ€æ¢å¤ï¼Œè¯·å–æ¶ˆä»¥ä¸‹æ•´æ®µæ³¨é‡Š
              // try {
              //   if (fs.existsSync(resultsDir)) {
              //     const files = fs.readdirSync(resultsDir);
              //     const detailFiles = files.filter(file => file.startsWith('risk_details_') && file.endsWith('.txt'));
              //     console.log(`Found ${detailFiles.length} risk detail files`);
              //     
              //     let processedCount = 0;
              //     let skippedCount = 0;
              //     let commentedCount = 0;
              //     
              //     for (const detailFile of detailFiles) {
              //       const detailPath = path.join(resultsDir, detailFile);
              //       const content = fs.readFileSync(detailPath, 'utf8');
              //       processedCount++;
              //       
              //       // è§£ææ–‡ä»¶å†…å®¹...
              //     }
              //   }
              // } catch (resultsError) {
              //   core.error(`Failed to process results directory: ${resultsError.message}`);
              // }
              // console.log('::endgroup::');
              
              console.log('::group::Cleaning up outdated comments');
              try {
                const activeRisks = new Set();
                if (fs.existsSync(resultsDir)) {
                  const files = fs.readdirSync(resultsDir);
                  const detailFiles = files.filter(file => file.startsWith('risk_details_') && file.endsWith('.txt'));
                  
                  for (const detailFile of detailFiles) {
                    const detailPath = path.join(resultsDir, detailFile);
                    const content = fs.readFileSync(detailPath, 'utf8');
                    const lines = content.split('\n');
                    let filePath = '';
                    let lineNum = '';
                    let severity = '';
                    
                    for (const line of lines) {
                      if (line.startsWith('æ–‡ä»¶è·¯å¾„:')) filePath = line.replace('æ–‡ä»¶è·¯å¾„:', '').trim();
                      else if (line.startsWith('è¡Œå·:')) lineNum = line.replace('è¡Œå·:', '').trim();
                      else if (line.startsWith('ä¸¥é‡ç¨‹åº¦:')) severity = line.replace('ä¸¥é‡ç¨‹åº¦:', '').trim();
                      else if (line.startsWith('=== æ‰«æç»Ÿè®¡ ===')) break;
                    }
                    
                    if (filePath && lineNum && severity) {
                      activeRisks.add(`${filePath}:${lineNum}`);
                    }
                  }
                  console.log(`Found ${activeRisks.size} active risks`);
                } else {
                  core.warning('Results directory not found for cleanup');
                }
                
                let deletedCount = 0;
                for (const comment of comments.data) {
                  if (comment.user.type === 'Bot' && comment.body.includes('<!-- security-line-comment:')) {
                    const match = comment.body.match(/<!-- security-line-comment:([^:]+:\d+) -->/);
                    if (match && !activeRisks.has(match[1])) {
                      await github.rest.issues.deleteComment({
                        owner: context.repo.owner,
                        repo: context.repo.repo,
                        comment_id: comment.id
                      });
                      console.log(`  ğŸ—‘ï¸  Deleted outdated comment for ${match[1]}`);
                      deletedCount++;
                    }
                  }
                }
                
                if (deletedCount > 0) {
                  console.log(`âœ… Cleaned up ${deletedCount} outdated security comments`);
                } else {
                  console.log('No outdated comments to clean up');
                }
              } catch (cleanupError) {
                core.warning(`Failed to cleanup outdated comments: ${cleanupError.message}`);
                console.error(cleanupError);
              }
              console.log('::endgroup::');
              
              process.exit(1);
              
            } catch (error) {
              console.error('Failed to post security comments:', error);
              throw error;
            }

      - name: Display all risks
        if: steps.validate.outputs.should_skip != 'true' && steps.scan.outputs.scan_result == 'failure'
        run: yak ssa-risk --input ./risk.json --with-code

  post-check:
    name: Save Scan Results to Cache
    needs: setup
    if: success()
    runs-on: ubuntu-22.04
    steps:
      # checkout code for this ./.github/actions/post-check/action.yml to work
      - name: 'Check Out'
        uses: actions/checkout@v3
        with:
          ref: ${{ github.event.pull_request.head.sha }}

      - name: Run Post-Check (Save Scan Results)
        uses: ./.github/actions/post-check
        with:
          cache-key-prefix: 'diff-code-check'